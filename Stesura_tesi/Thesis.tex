\documentclass[a4paper,10 pt,titlepage,twoside]{book}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{geometry}
\geometry{a4paper,top=3cm,bottom=3cm,left=3.5cm,right=3.5cm,heightrounded,bindingoffset=5mm}
\usepackage{booktabs}
\usepackage{color}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{statrep}
\usepackage{setspace}
\usepackage{emptypage}
\usepackage{newlfont}
\usepackage{algpseudocode} 
\usepackage{verbatim}
\usepackage[]{algorithm2e}
\usepackage[Algorithm]{algorithm}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{lmodern}
\usepackage{fullpage}
% for algorithm description
\usepackage{alltt}
\usepackage{multirow}
\usepackage{boxedminipage2e}
% for algorithm description in a box
\usepackage{boxedminipage}
% for colorful comment
\usepackage{color}

\newcommand{\numberset}{\mathbb}
\newcommand{\N}{\numberset{N}}\usepackage{amsmath}
\newcommand{\Z}{\numberset{Z}}
\newcommand{\R}{\numberset{R}}
\newcommand{\Q}{\numberset{Q}}
\newcommand{\K}{\numberset{K}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\n}{\mathcal{N}}

\DeclareMathOperator{\ord}{ord}

%aggiunto da me
\theoremstyle{plain} 
\newtheorem{thm}{Theorem}[chapter] 
\newtheorem{cor}[thm]{Corollario} 
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposizione} 
\newtheorem*{theorem*}{Theorem}


\theoremstyle{definition} 
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Example}
\newtheorem{propr}{Propriet�}

\theoremstyle{remark} 
\newtheorem{oss}[thm]{Osservazione} 


%per gli spazi:
\usepackage{setspace}
\singlespacing


%\renewcommand{\rmdefault}{phv} % Arial
%\renewcommand{\sfdefault}{phv} % Arial
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\theoremstyle{definition}
%\newtheorem{definizione}{Definizione}

%\theoremstyle{plain}
%\newtheorem{teorema}{Teorema}

%\linespread{1.525}\selectfont

\begin{document}
\thispagestyle{empty}

\centerline {\huge{\textsc{Università degli Studi di Torino}}}
\vskip 27 pt

\centerline {\Large{\textsc{Dipartimento di Matematica Giuseppe Peano}}}

\vskip 20 pt

\centerline {\Large{\textsc{Scuola di Scienze della Natura}}}

\vskip 20 pt

\centerline {\Large{\textsc{Corso di Laurea Magistrale in Matematica}}}


\vskip 60 pt





%\begin{tabular}{ccc}
\centerline {\includegraphics[width=7cm]{logo.jpg}}
%\end{tabular}
\vskip 1.2cm
\centerline {\normalsize {Tesi Magistrale}} 

\vskip 0.7cm

\centerline {\Large {\bf A predictor-corrector LPF Method}}

\vskip 1.7cm

\noindent Relatore: Prof.ssa Paola Lamberti
\hfill  {Candidato: Elena Scotto }\\





\vskip 2.7cm


\centerline{Anno accademico 2018/2019}

\tableofcontents

% 
%
% CAPITOLO 0
\chapter*{Abstract}
The concept of optimization is now well rooted as a principle underlying the analysis
of many complex decisions or allocation problems: Linear Programming (LP) is one of the simplest ways to perform optimization.
This thesis discusses the Simplex method and the Interior-Point methods (IPM).
The aim is to show that the significant difference between them is reflected not only on the theoretical background but also in the practical implementation and to point out the powerful of the IPMs, owing to their vast applicability.\\
The research addresses the role of the combined predictor-corrector step in Mehrotra's IPM method and apply this correcting technique to the Long-Path Following methods (LPF), which displays an extensive theoretical complexity and uses the nested neighborhood $\mathcal{N}_{-\infty}(\gamma)$.\\
First, it is given a brief description of these methods,
%: the simplex method, that is known to be very efficient practically, and the primal-dual %interior-point
then we outline a comprehensive convergence analysis of three important IPM: the primal-dual affine scaling, the LPF and the Mehrotra's method. \\
After introducing the basic theoretical framework, we exhibit a comparison of these competitors, testing them on some real models. We show that the corrector approach of the LPF presented in this work, improves the efficiency of the algorithm but the 
neighborhood restricts the progress achived in Mehrotra's method.

%\addcontentsline{toc}{chapter}{Abstract}  % se non si vuole numerare l'introduzione, ma farla comparire nell'indice


\chapter{Introduction to the linear programming}
Optimization is a fundamental tool for understanding nature, science, engineering, economics and mathematics: a large number of real world problems can be treated as optimization problems, in which the goal is to select values that maximize or minimize a given \textit{objective function}, subject to certain \textit{constraints}.\\ The process of identifying objective, variables and constraints for a given problem is knows as \textit{modeling}. Construction of an appropriate model is the first step and, once it is formulated, an optimization algorithm can be used to find its solution. There is a collection of algorithms, each of them is tailored to a particular type of optimization problem. Linear programming problem remains one of the most well-studied optimization problems: it consists in maximizing or minimizing a linear function over a certain domain, defined by a set of linear constraints.\\
Linear programming has been dominant paradigm in optimization since Dantzig's development of the simplex method in the 1940s. Regarding the theoretical complexity of this method, it has proved that the expected number of iterations in the solution of a linear problem is polynomial. Furthermore, the worst case complexity has exponential behavior. It has been observed that the simplex algorithm performs sufficiently well in practice, especially on small or medium sized LPs, but its performance is not satisfactory in large-scale LPs. This weakness of simplex algorithm due to the stalling and cycling problem but many anti-cycling pivoting rules have been introduced in the past.\\
Since Dantzig's initial contribution, researchers have made many efforts in order to enhance the performance of simplex algorithm. In the 1980s the monopoly of the simplex algorithm in the solution of the LP has been challenged. Interior point methods were the result of subsequent research and their performance has been more than satisfactory compared to the simplex algorithm. The main idea of IPMs is that the computation of the optimal solution can be achieved by moving inside the feasible region, defined by the constraints. \\
The thesis is organized as follow:
an introductory section summarizes the basic theory of the linear programming. In the chapter 2 we delineate the simplex method. The chapter 3 is dedicated to the primal-dual interior point methods, taking particular attention to the affine-scaling and the long-path following methods. It is also examined the Mehrotra's predictor-corrector algorithm, which is the basis of much of the current generation of software, even if no convergence theory is available for this algorithm.\\After a theoretical convergence analysis, the implementation illustrates the numerical results that we obtained for the considered physical problems and a comparison is performed.
Concluding, in the last chapter we give an overview of the work realized in this thesis and suggest possible next steps. 

%
% CAPITOLO 1
\chapter{Basic theory}
The variables in optimization models represent the decisions to be taken and the constraints specify the restrictions and the interactions that limit the variable values.
To complete the model, we need the objective functions that quantify the decision consquences to be maximezd or minimized. This chapter introduces notations, terminologies and formulations of a general linear programming problem .

\section{Linear programming: basic notions}

Since 1950, generations of workers in management, economics, finance and engineerng have been trained in the techniques of formulating linear models that,
as the name implies, are characterized by linear objective function and constraints formulated with linear equalities or linear inequalities.
Then, the feasible set satisfying the constraints is a polytope, i.e. a convex and connected set with polygonal faces. We say that the LP is \textit{infeasible} if the feasible set is empty and \textit{unbounded} if the objective function, minimization function for istance, is unbounded below on the feasible region.\\
Weconsider the LP in the following \textit{standard form}:
\begin{alignat*}{1}\label{eq:stdform}
\text{minimize\;}\; &c_1 x_1 + c_2 x_2+ ... c_m x_m\\[2mm]
\text{subject\;to\;} &a_{11} x_1 + a_{12} x_2+ ... +a_{1m}x_m = b_1\\
&a_{21} x_1 + a_{22} x_2 + ... + a_{2m} x_m= b_2\\
&\vdots\\
&a_{n1} x_1 + a_{n2} x_2 + ... + a_{nm} x_m= b_n\\
\text{and}\; & x_1 \geq 0 , x_2 \geq 0, ... , x_m \geq 0
 \end{alignat*}

where the $b_{j}$, $c_{i}$ \text{and} $a_{ij}$ are fixed real costants, with $i \in\{1,...,m\}$ and $j\in\{1,...,m\}$.\\ In a compact notation, using vectors, the standard problem can be written as
\begin{equation}\label{(Prim)}
 \begin{split}
\min\;&c^{T}x\\
\text{subject\;to\;}&Ax= b\;\\\text{and\;}&x\geq0
 \end{split}
\end{equation}

with $x$ an \textit{m}-dimensional column  of decision variables, $c^
{T}$ a \textit{m}-dimensional vector, \textit{A} a $n \times m$ matrix, and \textit{b} a \textit{n}-dimensional column vector (Kantorovich L., 1939).\\
If $x$ satisfies the constraints $Ax = b$, $x\geq0$, we call it a \textit{feasible point}; the set of all feasible points is the \textit{feasible set}, indicated by $\mathcal{P}=\lbrace x\; |\; Ax = b , x \geq0\rbrace$.\\
In the case the constraints set is determined entirely by linear inequalites $Ax \leq b$, which in the literature (see \cite{W}) is said to be a \textit{canonical form}, the problem may be alternatively expressed as:
\begin{alignat*}{3}
\text{minimize\;}&c_1 x_1 + c_2 x_2+ ...+c_m x_m&&&\\[2mm]
\text{subject\;to\;}&a_{11} x_1 +a_{12}x_2 + ... +a_{1m}x_m +y_{1}&&&= b_1\\
		   	&a_{21}x_1+a_{22}x_2+ ... +a_{2m}x_m&+y_{2}&&= b_2\\
&&\;\;\;\vdots&&\\
&a_{n1}x_1+a_{n2}x_2+ ... +a_{nm}x_m+&&&y_{n}=b_n\\
\text{and} \;& x_{i} \geq 0;\;\; y_{j} \geq 0; \text{\;\;for }i = 1,...,m&\text{ and }j&=&1,...,n.
\end{alignat*}
The new positive variables $\mathit{y_{i}}$, $i \in {1, ..., n}$ introduced to convert the inequalities into identities, are called \textit{slack variables} and the problem has the standard form with $n+m$ unknowns variables \begin{itshape}$x_{i}, y_{j},i \in {1, ..., m}$ and $j \in {1, ..., n}.$\end{itshape}\\ The new matrix, that now describes the linear equality constraints, assumes the form $\left[\begin{matrix}A\;\vert\; I\;\end{matrix}\right]$, with $A$ the $n \times m$ matrix of the original canonical LP and the identity matrix $I$ associated to the slack variables, that has dimension $n \times (n + m)$.\\
Considering the system of equalities \ref{(Prim)}, we can identify a set of \textit{n} linearly independent columns from the \textit{m} columns of  $A$ and create a $n \times n$ submatrix called \textit{basis matrix} ($A_{B}$) with the index set of the columns ($B$) called \textit{basis} of matrix $A$ .\\
$A_{B}$ is nonsingular and we may uniquely solve the equation $A_{B}x_{B} = b$. For simplicity, if we assume $B = \{1, \dots, n\}$, then the point $x =\left(x_{B},0_{[m-n]}\right)$ is a solution of the original equality system. This leads to the following definition:
\begin{defn}

	We define the solution $x$ above as \textit{basic point} with respect to the basis B, the basic point is \textit{feasible} if $x_{B}\geq 0$. \\The components of $x$ associated with columns of $A_{B}$ are called \textit{basic variables} and components associated to $N  = \left\lbrace 1...m\right\rbrace  \backslash B$ are \textit{nonbasic variables}.\\
	A basis B is \textit{degenerate} if $x_{i}= 0$ for some $i\in B$.\\
	A LP is said to be \textit{degenerate} if has at least one degenerate basis.
\end{defn}
For the standard formulation, we will assume throughout that $n < m$.
Then, the $n$ rows are linear indipendent, then there is at least one basic solution and, accordingly, one solution of the standard problem. Certainly, when we have a canonical form problem, then the extended $n \times (n+m)$ matrix [A | I ] with slack variables satisfies this property. When $n \geq m$, the feasible region is empty or consists in a single point.\\
Now we outline the importance of basic feasible solutions in solving LP with the simplex method.
Throw the following theorem we state that it is necessary only to consider basic feasible
variables when seeking an optimal solution because the optimal
value is always achieved at such a solution.\\ (The method to prove the theorem is in many respects as important as the result itself, since it represents the beginning of the development of the simplex
method.)
\begin{thm}[\textbf{Fundamental theorem of liner programming}] \ \\
\begin{enumerate}
\item If there is a feasible point for \ref{(Prim)}, then there is a basic feasible point.
\item If \ref{(Prim)} has solutions, then at least one such solution is a basic optimal point.
\item If \ref{(Prim)} is feasible and bounded, then it has an optimal solution.
\end{enumerate}
\end{thm}
\begin{proof}
	See \cite{LP}
\end{proof}
Thus, it describes a peculiar feature of the linear programming: reducing the task of solving a linear problem to searching over basic feasible solutions. Since for a problem having $m$ variables and $n$ constraints there are at most ${m}\choose{n}$ basic solutions (corresponding to the number of ways of selecting m of n columns), there are only a finite number of possibilities. 

\subsection*{A geometric approach}
The linear programming problem is simple to state and visualize. In fact, very simple graphic techniques have enough power to tiny models [such as Two Crude formulation- da sviluppare]. They also yield helpful intuition about properties and soultion methods for model of more realistic size.\\ The set of the linear constraints in \ref{(Prim)} defines a \textit{polytope}, that constitutes the \textit{feasible region} and the \textit{vertices} are the points that do not lie on a stright line between two other points in the set. Algebraically, the vertices of the feasible set $\mathcal{P}$ are exactly the basic feasible points.\\ According to the Fundamental theorem, we can restrict our attention to the vertices of this polytope and it implies that we can explore only at most  ${m}\choose{n}$ points. 
%\begin{ex}
%The feasible set of a standard form linear programming problem is defined by the following constraints:
%\begin{alignat*}{3}
%-x_{1}+&x_{2}-x_{3}&\;&\;&= 0\\
%x_{1}+&\;&+x_{4}\;&\;&= 2\\
%&x_{2}&\;&+x_{5}&= 3\\
%x \geq 0&\;&\;&\;&\\
%\end{alignat*}
%\end{ex}
%[\textit{con una illustrazione grafica del poliedro si mostra l'insieme dei vertici presi in considerazione e candidati punti ottimali}]

\section{Optimality and duality in LP}
In this section we introduce the optimality and duality theory and investigate the important relationship between primal and dual LP, that provide LP algorithm strategies.\\ 
Optimality conditions for the LP can be derived from the theory of the constrained optimization related to a general non linear problem (NLP), defined as follow:

\begin{equation}\label{NLP}
\min f(x)\text{\;subject\;to\;}\begin{cases} c_{i}(x) = 0 &i \in \mathcal{E}\\ c_{i}(x)\leq 0 &i\in \mathcal{I}\end{cases}
\end{equation}
\\
where $f$ and $c_{i}$ are smooth, real-valued functions defined on subset of $\mathbb{R}^{n}$ and $\mathcal{E}$ and $\mathcal{I}$ are two finite sets of indices in $\mathbb{N}$.\\Let us recall only the first-order conditions, that are essential to explain the duality results for the linear case.\\
In order to state the necessary conditions, the points should satisfy specific regular conditions, defined below:
\begin{defn}
	Given a point x, $\mathcal{A}(x)= \mathcal{E}\cup\left\lbrace i\in\mathcal{I}\;|\;c_{i}(x) =0\right\rbrace$ is called active set and we say that the linear independence constraint qualification, $LICQ$, holds if the set of active constraint gradients $\left\lbrace \nabla c_{i}(x),,i\in\mathcal{A}(x)\right\rbrace$ is linear indipendent.
\end{defn}
We define the \textit{Lagrangian function} for the general problem \ref{NLP} 
\begin{equation*}
\mathcal{L}\left(x,\lambda\right)=f(x)-\sum_{i\in\mathcal{E}\cup\mathcal{I}}\lambda_{i}c_{i}(x)
\end{equation*}
The necessary conditions, defined in the following theorem, are called \textit{first-order conditions} because they are concerned with properties of the gradients of the objective and constraint functions.
\begin{thm}
Suppose that $x^{*}$ is a local solution of (1.1), that f and $c_{i}$ are continuously differentiable, and the LICQ holds at $x^{*}$. Then there is a Lagrange multiplier vector $\lambda^{*}$, such that 
\begin{alignat*}{2}
\mathcal{L}(x^{*},\lambda^{*})&=0&\\
c_{i}(x^{*})&=0, &\forall i\in\mathcal{E}\\
c_{i}(x^{*})&\geq 0, &\forall i\in\mathcal{I}\\
\lambda&\geq 0, &\forall i\in\mathcal{I}\\
\lambda^{*} &\geq 0 & \forall \in\mathcal{I}\\
\lambda^{*}c_{i}(x^{*})&= 0,\;\forall i&\in\mathcal{E}\cup\mathcal{I}.\\
\end{alignat*} 
\end{thm}

These equalites are called \textit{Karush-Kuhn-Tucker} conditions, or \textit{KKT} conditions for short and the last condition is the \textit{complementary condition}.\\ Though this theorem requires LICQ, the result continues to hold for \textit{dependent} constraints provided they are linear, as in the case of the standard LP \cite{W}. The LP Lagrangian function is:\\
\begin{equation}
\mathcal{L}(x,\lambda,s)=c^{T}x-\lambda^{T}\left(Ax-b\right)-s^{T}x.
\end{equation}
Now we illustrate the first-order necessary conditions: let us assume that the matrix $A\in\mathbb{R}^{n,m}$, the vectors $b\in\mathbb{R}^{n}$ and $c\in\mathbb{R}^{m}$ construct a standard LP. A vector $x^{*}$ is a solution if and only if exist Lagrange multipliers $\lambda^{*},\;s^{*}$ such that the primal-dual solution $\left( x^{*},\lambda^{*},s^{*}\right)\in\mathbb{R}^{n}\times\mathbb{R}^{m}\times\mathbb{R}^{n}$ satisfies these conditions, 
\begin{align}
A^{T}\lambda+s&=c,\\ \label{DF}
Ax&=b,\\ \label{PF}
x&\geq 0,\\
s&\geq 0,\\
x_{i}s_{i}&=0,\; for\;i= 1,2,...,m. \label{CC}
\end{align} 
The complementary conditions show that at least one of the components $x_{i}$ and $s_{i}$ must be zero for each $i=0,1,2,...,n$.\\
 Convexity of the problem ensures that these conditions are also sufficient for a global minimum, hence the KKT conditions are also \textit{sufficient}: if we have a primal feasible vector $x$, and another vector $(\lambda, s)$ such that the equations are satisfied, then $x$ is the solution of \ref{(Prim)}. We can prove this claim directly by taking an arbitrary primal feasible vector $\bar{x}$ and showing that its objective value is no smaller than $c^{T}x$:
\begin{equation*}
c^{T}\bar{x}=(A^{T}\lambda+s)^{T}\bar{x}=b^{T}\lambda+s^{T}\bar{x}\geq b^{T}\lambda= c^{T}x.
\end{equation*}
We conclude that the KKT conditions are both necessary and sufficient for optimality in the LP. Besides, we find that
\begin{equation*}
	c^{T}x^{*}=\left(A^{T}\lambda^{*}+s^{*}\right)^{T}x^{*}=\left(Ax^{*}\right)^{T}\lambda^{*}=b^{T}\lambda^{*}.
\end{equation*}
With this equality, we can formulate the \textit{dual problem} of \ref{(Prim)}
\begin{equation}\label{Dual}
\begin{split}
&\text{maximize\;} b^{T}\lambda\\
&\text{subject\;to\;}A^{T}\lambda \leq c
\end{split}
\end{equation} 
We can restate this problem in a standard form introducing the slack variables as following:
\begin{equation}\tag{D}
\begin{split}
&\text{maximize\;}b^{T}\lambda\\
&\text{subject\; to\;}A^{T}\lambda+s=c\\ &\text{and\;} s\geq0
\end{split}
\end{equation}
The primal-dual relationship is symmetric: by taking the dual of the dual problem, we recover the original problem \ref{(Prim)} that we briefly call \textit{primal} problem (P).\\
Let us define the \textit{dual feasible set} $\mathcal{D}=\{(\lambda,s)\in\mathbb{R}^{m+n}| A^{T}\lambda+s= c,s>0\}$, than for every $x\in\mathcal{P}$ and $\left(\lambda,s\right)\in\mathcal{D}$, we have that $c^{T}x-b^{T}\lambda=\left(c-A^{T}\lambda\right)^{T}x=s^{T}x \geq0$.\\
Therefore we have $c^{T}x\geq b^{T}\lambda$ when both primal and dual variables are feasible, and this result is known as \textit{dual gap}.\\

\begin{thm}[\textbf{Strong duality}] \
\begin{itemize}
\item If either the primal or the dual problem has a finite solution, then so does the other, and the objective values are equal.
\item If either the primal or the dual problem is unbounded, the the other problem is infeasible.
\end{itemize}
\end{thm}
(\textit{le dimostrazioni ancora da scrivere. Riferimento: in [1] capitolo 12}).\\
Hence, for every solution $(x^{*}, \lambda^{*}, s^{*})$ we have $x_{j}^{*}= 0$ and/or $s_{j}^{*}= 0$ for all $j=0,1,\dots,m$.\\
We can define two index sets $\mathcal{B}$ and $\mathcal{N}$ as follows:
\begin{equation}
\mathcal{B} =\{j\in\{1,\dots,m\}|\; x^{*} \not= 0\}, \;
\mathcal{N} =\{j\in\{1,\dots,m\}|\; s^{*} \not= 0\}
\end{equation}  
Obviously, $\mathcal{B}$ and $\mathcal{N}$ are disjoint and form a partition of the indices. Now we state an important theorem:
\begin{thm}[Goldman-Tucker]
	There is at least one solution $(x^{*}, \lambda^{*}, x^{*})$ such that $x^{*}+s^{*}\geq0$.
\end{thm}
The set $\mathcal{B}$ does not necessarily contain $n$ elements, that is the number of the rows of the matrix $A$. This set must not be confused with the set of the basic variables $B$, by the definition (2.1). In the following example, for istance, we have $|\mathcal{B}|= 2$ and three basis sets $B = \{1\}, \{2\}, \{3\}$.
\begin{ex}
Consider
\begin{center} $\min\limits_{x\in\mathbb{R}^{3}} x_{1} \text{\;subject to\;} x_{1}+x_{2}+x_{3} = 1, x\geq 0$.\end{center}
The primal solution is $x^{*}=(0, t, 1-t)$, for $t\in(0,1)$. 	
\end{ex} 

The multipliers $(\lambda,s)$ indicate the sensitivity of the optimal objective value  to perturbations in the constraints and the process of finding them is called \textit{sensitivity analysis}. \\ In fact, let we assume a small perturbation of input data, for example $b + \Delta b$. If $\Delta x$ and $\Delta s$ have zero in the same entries as $x$ and $s$ respectively, then
\begin{equation*}
0=x^{T}s=x^{T}\Delta s= \left( \Delta x\right)^{T}s=\left( \Delta x\right)^{T}\Delta s
\end{equation*}
and by the theorem we have that the optimal objectives of the primal and dual problems are equal, for both the original and perturbated problems, so

\begin{align*}
&c^{T}x=b^{T}\lambda  &c^{T}(x + \Delta x)=\left(b+\Delta b\right)^{T}\left(\lambda+\Delta \lambda\right).
\end{align*}
with, by the feasibility of $x + \Delta x$ and $\lambda+\Delta \lambda$:
\begin{align*}
&A(x + \Delta x)=b+\Delta b
&A^{T}\Delta\lambda=-\Delta s.
\end{align*}
Hence, the change in optimal objective due to the perturbation is as follows:
\begin{align*}
c^{T}\Delta x&=\left(b+\Delta b\right)^{T}\left(\lambda+\Delta \lambda\right) - b^{T}\lambda\\
&=\left(b+\Delta b\right)^{T}\Delta \lambda+\left(\Delta b\right)^{T}\lambda\\
&=\left(x+\Delta x\right)^{T}A^{T}\Delta \lambda+\left(\Delta b\right)^{T}\lambda\\
&=\left(x+\Delta x\right)^{T}\Delta s+\left(\Delta b\right)^{T}\lambda\\
&=\left(\Delta b\right)^{T}\lambda.\\
\end{align*} 
In particular, if $\Delta b = \epsilon e_{j}$, we have that $c^{T}\Delta x+\epsilon \lambda_{j}$ and it shows that the change in optimal objective is $\lambda_{j}$ times the perturbation to $b_{j}$.
\begin{thm}[\textbf{Complementary slackness}] \ \\
	Let $x^{*},(\lambda^{*},s^{*})$ be feasible for the primal and the dual problems. The following are equivalent:
	\begin{itemize}
		\item $x^{*}$ is an optimal solution to (P) and $(\lambda^{*},s^{*})$ is an optimal solution to (D).
		\item $(x^{*})^{T}s^{*}=0$
		\item $x^{*}_{j}s^{*}_{j}=0,\;\forall\; j=0,...,m$
		\item If $s^{*}_{j} > 0$ then $x^{*}_{j}= 0$.
	\end{itemize}
\end{thm}

After having delineated the basic tools of the multipliers in terms of sensitivity, the sensitivity analysis is developed later, examining the optimal results obtained by the methods designed.\\

[\textit{Ci sono altri due teoremi che completano il capitolo sulla dualita', ma non utilizzati nella ricerca. Capitolo da perfezionare. L'analisi di sensitività verrà svolta dopo aver introdotto i metodi.}]
%
%  CAPITOLO 2
%
\chapter{The simplex method}
The simplex method was introduced in 1947 by George Dantzig \cite{MUR}. The discover of this method happened simultaneously with the realization of linear programming as an efficient modeling tool for practical decision making.\\
The method exploits the insight provided by the fundamental theorem
of linear programming, which states that if it exists an optimal solution of the LP, it is at one of the vertices of the feasible polytope. \\
The idea of the simplex method is to proceed from one basic feasible point of the constraint set $\mathcal{F}$ to another, in such a way as to continually decrease the value of the objective
function until a minimum is reached.\\ Consider the general linear programming problem presented in standard form as in \ref{(Prim)}.
We assume for the remainder of the chapter that the matrix $A$ has full row rank: in practice, a preprocessing phase is applied to the user-supplied data to remove some
redundancies from the given constraints and eliminate some of the variables.\\Given an index sets $B$ and $N$, we can identify a partition of the $m$-elements vectors $x$, $c$ and the matrix $A$ and formulate the LP as following:
\begin{equation}
\begin{split}
\text{minimize\;} &c^{T}_{B}x_{B}+c^{T}_{N}x_{N}\\
\text{subject\;to\;}&A_{B}x_{B}+A_{N}x_{N} = b\text{\;and\;}x_{B}, x_{N}\geq0
\end{split}
\end{equation}
 %with \textit{n} elements corresponding to the basic feasible point we are starting from.
 \\Note that for any $x$, the basic variables $x_{B}$ can be written as a function of the nonbasic variables $x_{N}$ and hence, $x_{B}=A_{B}^{-1}b-A_{B}^{-1}A_{N}x_{N}$. \\Similarly, the objective function can be written as $c^{T}x=c_{B}^{T}A_{B}^{-1}b+(c_{N}-A_{N}^{T}A_{B}^{-T}c_{B})^{T}x_{N}$, denoting the \textit{reduced cost} by \begin{center}
 	$\widetilde{c}=c_{N}-A_{N}^{T}A_{B}^{-T}c_{B}$.
 \end{center}Since we are dealing only with basic feasible points, we consider the relative basic feasible point $x$ with $x_{N}= 0$ and the cost value it is exactly $\widetilde{c}$.\\
 We can choose the dual points $(\lambda,s)$ such that $(x, \lambda, s)$ satisfies the KKT condition as well: from \ref{DF} we set $s_{B}= 0$ for the complementary condition, therefore we get $s_{N}= c_{N}- A_{N}^{T}\lambda$. Besides, since $A_{B}$ is not singular, \ref{DF} uniquely defines $\lambda$ as $\lambda = A_{B}^{-T}c_{B}$, then, we can state that the reduced cost is identical to $s_{N}$.\\  
 
 If there exists a $j \in N$ such that $\widetilde{c}_{j} \leq 0$, then by increasing $x_{j}$ up from zero, we will decrease the value of the objective function.\\
So, in a step of the simplex method we find an index $s \in N$ such that $\widetilde{c}_{s} \leq 0$ and increase $x_{s}$ it as much as possible while keeping $x_{B} \geq 0$. We enforce that this non-basic variable is now positive and we include the index $s$ in the basis $B$.\\
In the next step we keep increasing $x_{s}$ until one of the components of $x_{B}$, for istance $x_{r}$, is driven to zero: the index $r$ is removed from $B$ and replaced it with $s$. This process of selecting entering and leaving indices is called \textit{pivoting rule}. \\
On the other hand, if there is no $j \in N$ such that $\widetilde{c}_{j} \leq 0$, then we stop and the current basic feasible solution is an optimal solution. \\
Formalizing the pivoting rule in algebraic terms, we have the current $x$ feasible basic point w.r.t. $B$ and the new iterate $\bar{x}$ such that $\bar{x}_{i} = 0$ for $i \in N\backslash\{s\}$.\\
Hence we have: 
\begin{align*}
	A\bar{x} = A_{B}\bar{x}_{B} +A_{s}\bar{x}_{s} = A_{B}x_{B} = Ax \text{;  then }
	\bar{x}_{B} = x_{B} - A_{B}^{-1}A_{s}\bar{x}_{s}.
\end{align*}
Geometrically speaking, $\bar{x}_{B}$ is a move along an edge of the polytope that decreases $c^{T}x$. We continue to move along the edge until a new vertex is encountered. At this vertex, we have $\bar{x}_{s}\geq0$ and one of the components $\bar{x}_{r}\in B$ decreased to zero: we obtain a new basis denoted by $\bar{B} = B \cup \{s\} \backslash \{r\}$.\\
It is possible that we can increase $x_{s}$ to $\infty$ without encountering a suitable $x_{r}$: that means that the contraint $\bar{x}_{\bar{B}} = x_{B} - A_{B}^{-1}A_{s}\bar{x}_{s}>0$ holds for all positive values of $\bar{x}_{s}$. When it happens, the LP is \textit{unbounded}: the cost value $c^{T}x$ decreases to $-\infty$.\\
We have covered most of the mechanics of taking a single step of the simplex method. The computational procedure is the following:\\ 
\\
\textbf{Simplex algorithm}
\begin{tabbing}
	\textbf{Given} \=$B, N, x_{B} = A_{B}^{-1}b\geq 0$ with $x_{N}=0$;\\
	%\>Solve $A_{B}^{T}\lambda = c_{B}, \text{ for }\lambda$;\\
	%\>Compute $\widetilde{c}_{N}=c_{N}-A_{N}^{T}\lambda$;\\
	%\>\textbf{If} {$\widetilde{c}_{N}\geq 0$} optimal solution found \textbf{stop};\\
	%\>\textbf{Else}\\
	\> Select $s\in N\;|\;\widetilde{c}_{s}\leq 0$ as the entering index;\\
	\> Solve $A_{B}d = A_{s}$ for $d$;\\
	\>\textbf{If} {$d \leq 0$} unbounded problem: \textbf{stop};\\
	\>\textbf{Else} \=\\
	\>\>Calculate the ratio test $\bar{x}_{r} = \min_{i | d_{i} > 0}(x_{B})_{i}/d_{i}$, and\\
	\>\>use $t$ to denote the minimizing $r = B[t]$;\\
	\>\>Update \=$\bar{x}_{B} = x_{B}-d\bar{x}_{r}$;\\
	\>\>\>$\bar{x}_{N} = (0,...,0_{[s-1]},\bar{x}_{r},0_{[s+1]},...,0)$;\\
	\>\> Update sets: $\bar{B} = B \backslash \{r\} + \{s\}$ and $\bar{N} = N \backslash \{s\} + \{r\}$;\\
	\textbf{end}
\end{tabbing}

Summarizing, the simplex algorithm moves from basic feasible solution to another one and it moves from one vertex to an adjacent one, for which the basis $B$ differs inexactly one component. Each iteration begins by checking the sign of the coefficients of the objective function $\widetilde{c}$ on non-basic variables: if none is negative, then the current basic solution is optimal. \\
As we see, it is required a basic feasible staring point $x$ and a corresponding initial basis $B \in \left\{ 1,2,..., m \right\}$ with $|B|=n$ such that $A_{B}$ is non singular, $A_{B}^{-1}b=x_{B} \geq 0$ and $x_{N}=0$.\\
A basic feasible solution is immediately available for some LP.\\ For example, in problems with constraints in canonical form and with $b > 0$, a basic feasible point corresponding to the standard form is provided by the slack variables: $x =\left(0_{[m]},b\right)$, that satisfies .\\Sometimes the problem of finding an initial point and a basis may itself nontrivial but the \textit{two-phase} method deals with this difficulty. The idea is to add artificial variables in order to give a basic feasible initial point for a second phase in which we can extract easily the solution of the original problem.\\
In \textit{phase I} we solve the following problem:
\begin{equation}
\begin{split}
\min &\;1^{T}u\\
\text{subject\;to\;}&A_{B}x_{B}+A_{N}x_{N} + \textbf{Eu} = b\;\text{and\;} u\geq 0\\
\text{with\;} E_{jj}& =\begin{cases} -1\;\text{if\;} b_{j} \leq 0\\
0\;\; \text{otherwise}
\end{cases}   
\end{split}
\end{equation} \\
Using artificial variables in each violated constraint, it is easier to complete a starting feasible point. Since they are restricted to be nonnegative, the objective value is as well. If this last one is zero, then the \textit{phase I} terminates and we compute a second linear program (\textit{Phase II}).\\
The point $(x,z)$, defined by $x = 0$ and $z_{j} = |b_{j}| \text{\;with\;}j =\{1,2,...,n\}$, is a basic initial feasible point, corresponding to the basis $B = \{m-n,...,m\}$. At any feasible point for (3.2), the artificial variable $u$ represents the amounts by which the constraints $Ax = b$ are violated by the $x$ component and the objective function is the sum of these violations. \\
The \textit{phase I} minimizes this sum and it has an optimal objective value of zero if and only if the original LP is feasible. In fact we have two cases at the optimal solution $\bar{u}$: 
\begin{itemize}
	\item[-]$1^{T}\bar{u}$ is zero: the simplex method finds a solution $(\bar{x},\bar{u})$ with $\bar{u}=0$ and it starts the \textit{phase II} step with initial point $\bar{x}$.
	\item[-]$1^{T}\bar{u}$ is positive and the original problem is unfeasible.
\end{itemize}
If we get in the first case, after dropped all the artificial variables $\bar{u}$, we proceed with the second phase: it consists on an implementation of the simplex method, with starting feasible point $\bar{x}$.\\ 
While two-phases method deals with feasibility and optimality separately, the \textit{Big-M} method combines these activities in a single search and the key is a composite objective function: the original one added the artificial variable sum times  large positive multiplier M:\\
\begin{equation}
\text{minimize\;}\mathbf{c^{T}x+M \sum_{i}{u}_{i}}\\
\end{equation}  
 \section{Degenerate steps}
The simplex method may encounter situations in which $-d_{r} = \left( A_{B}^{-1}A_{s}\right)_{r} < 0$ but $(A_{B}^{-1}b)_{s}= 0$. At this step, called \textit{degenerate step}, the objective function $c^{T}x$ may not decrease and, after a number of successive degenerate steps, we may return to the original basis $B$. \\
A. Charnes \cite{Lexico2} developed a technique of perturbation, that resulted in a finite simplex algorithm. This algorithm turned out to be equivalent to the lexicographic rule. The \textit{perturbation strategy} avoids this cycling: it consists on adding a small perturbation to the right-hand side of constraints, as follows:
\begin{equation*}
b(\epsilon) \vcentcolon= b + A_{B}
\begin{bmatrix}
\epsilon\\\epsilon^{2}\\\vdots\\\epsilon^{m}
\end{bmatrix}
\end{equation*}
where $\epsilon$ is a very small positive number. This perturbation in the components of the basic solution vector; we have
\begin{equation*}x_{B}(\epsilon) \vcentcolon= x_{B} + A_{B}
\begin{bmatrix}
\epsilon\\\epsilon^{2}\\\vdots\\\epsilon^{m}
\end{bmatrix}
\end{equation*}
Hence, we have that for all $\epsilon$ sufficiently small, $(x_{B^{+}})>0$. The basis is nondegenerate for the perturbed problem, and we can perform a step of the simplex method that produces a nonzero decrease of the object value.\\
The question remains of how to choose $\epsilon$ small enough at the point at which the original degenerate basis B is encountered. The \textit{lexicographic strategy} finesses this issue by not making an explicit choice of $\epsilon$, but rather keeping track of the dependence of each basic variable on each power of $\epsilon$. When it comes to selecting the leaving variable, it chooses the index $s$ that minimizes $x_{B}(\epsilon)_{i}/d_{i}$ over all variables in the basis, for a sufficient small $\epsilon$.\\
Another method that avoids this cycling is the \textit{Bland's rule}. In the algorithm it selects:
\begin{itemize}
	\item the index that leaves the nonbasis $s$ such that $\min\limits_{i}\{c_{i}\leq0\}$
\item the index that leaves the basis $r$ such that $\bar{x}_{r} = \min\limits_{q}\{\bar{x}_{q}\;|\;\bar{x}_{q}^{+} \text{\;satisfies the ratio test} \}$ \end{itemize} 
\begin{theorem*}
	The simplex method always terminates provided that both the entering and the leaving variable are chosen according to the Bland's rule.
\end{theorem*}
\begin{proof}
to write ~\cite{LP} pagg. 36-37	
\end{proof}
In the implementation of the simplex method it is implemented the Bland's rule and in the following example is illustrated the results:
\begin{ex}
	We apply the method to the Beale's problem (1955): %~\cite{}:
	\begin{alignat*}{4}
	\min -\frac{3}{4}x_{1}&+150x_{2}&-\frac{1}{50}x_{3}&+6x_{4}&\\
	\text{such that\;}\frac{1}{4}x_{1}&-60x_{2}&-\frac{1}{25}x_{3}&+9x_{4}&\leq 0\\
	\frac{1}{2}x_{1}&-90x_{2}&-\frac{1}{50}x_{3}&+3x_{4}&\leq 0\\
	&\;&x_{3}&\;&\leq 1\\
	x&\;&\;&\;&\geq 0\\
	\end{alignat*}
	
Applying Bland's rule, we find optimal solution at $x^{*} = [0.04, 0,  1,   0,  0.03, 0,   0  ]$ in the basis $B = [0, 2, 4]$ after 7 iterations: the optimal cost value is $c^{T}x^{*} = -0.5$.\\
\begin{center}
\begin{array}{ | l | l | l | l | }
	\hline
	\text{Iteration} & \text{Current Basis} & \text{Current x} & \text{Current cost value} \\ \hline
	1 & [4, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	2 & [0, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	3 & [0, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	4 & [2, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	5 & [2, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	6 & [2, 3, 0] & [0.016 0.    1.    0.004 0.    0.    0.   ] & -0.008 \\ \hline
	7 & [2, 4, 0] & [0.04 0.   1.   0.   0.03 0.   0.  ] & -0.050 \\ \hline
\end{array}

\end{center}
Instead without the rule, after 18 iterations the simplex method returns to the same basis sequence, entering in a cycle: the original simplex method repeats the same sequence of six pivotis indefinitely, making no progress toward the solution.
\begin{center}
\begin{array}{ | l | l | l | l | }
	\hline
	\text{Iteration} & \text{Current Basis} & \text{Current x} &\text{Current cost value} \\ \hline
	1 & [4, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	2 & [0, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	3 & [0, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	4 & [2, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	5 & [2, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	6 & [4, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	7 & [4, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	8 & [0, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	9 & [0, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	10 & [2, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	11 & [2, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	12 & [4, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	13 & [4, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	14 & [0, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	15 & [0, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	16 & [2, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	17 & [2, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	18 & [4, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
\end{array}
\end{center}
\end{ex} 
\newpage
 \section{Analysis of the simplex method}

The simplex method, with ever-evolving improvements, has for five decades provided an efficient general
method. \\
 Since the method operates by moving from one basic feasible point
to another without ever returning to a previously visited point, an upper bound
on the number of iterations is the number of basic feasible points.\\Hence, given a LP in standard form with
coefficient matrix and vectors $A\in\mathbb{R}^{n,m}, b\in\mathbb{R}^{n}$ and $c\in\mathbb{R}^{m}$, it computes at most $m\choose n$ iterations.\\
The number of pivot steps to solve
the problem starting from a basic feasible solution is typically a small multiple of
$m$: usually between $2m$ and $3m$. At one time researchers believed (and attempted to prove) that the simplex
algorithm always requires a number of iterations that is
bounded by a polynomial expression in the problem size. In fact, Dantzig observed that for problems with
$m \leq 50$ and $n \leq 200$ the number of iterations is ordinarily less than $\frac{3}{2}m$ \cite{DAN}.
\\ However, in 1972, Victor Klee and George Minty exhibited a class of linear programs each of which requires an
exponential number in the size of the problem of iterations when solved by the simplex method.\\
One form of the Klee–Minty example is the following whose feasible polytope has $2^{n}$
vertices:
\begin{alignat*}{2}
\max &\sum_{j=1}^{n}10^{n-j}x_{j}&&&\\
\text{subject to\;}&2\sum_{j=1}^{i-1}10^{i-j}x_{j}+&x_{i}&\leq 100^{i-1}, \, &i = 1,\dots, n;\\
&&x_{j}&\geq 0, \,&j = 1,\dots, n.\\
\end{alignat*}
A specific case is that for $n = 3$, giving:
\begin{alignat*}{2}
\text{minimize\;}\; 100& x_1+10x_2+ x_3&&\\[2mm]
\text{subject\;to\;\;\;\;} &x_1+&&\leq 1\\
						20& x_1+x_2&&\leq 100\\
200 &x_1 +20x_2 +x_{3}&&\leq 10000\\
\text{and}\;& x_1\geq 0,x_2\geq 0,x_3&&\geq 0.
\end{alignat*}
with 3 constraints and 3 variables (along with their nonnegativity constraints).\\
The Python implementation solves the problem in $2^{3} - 1 = 7$ pivot steps without the Bland's rule: this confirms that the general problem requires $2^{n}- 1$ iterations and this is in fact
the number of vertices minus $1$.\cite{MINTY}\\ It is illustrated also the result obtained applying the simplex method with the Bland's rule, in this case the number of iterations is only $5$.  \\
\begin{center}
\begin{array}{ | l | l | l | l | }
	\hline
	\text{Iteration} & \text{Current Basis} & \text{Current x} & \text{Current cost value} \\ \hline
	0 & [3, 4, 5] & [    0.     0.     0.     1.   100. 10000.] & 0 \\ \hline
	1 & [0, 4, 5] & [   1.    0.    0.    0.   80. 9800.] & -100 \\ \hline
	2 & [0, 1, 5] & [   1.   80.    0.    0.    0. 8200.] & -900 \\ \hline
	3 & [3, 1, 5] & [   0.  100.    0.    1.    0. 8000.] & -1000 \\ \hline
	4 & [3, 1, 2] & [   0.  100. 8000.    1.    0.    0.] & -9000 \\ \hline
	5 & [0, 1, 2] & [   1.   80. 8200.    0.    0.    0.] & -9100 \\ \hline
	6 & [0, 4, 2] & [   1.    0. 9800.    0.   80.    0.] & -9900 \\ \hline
	7 & [3, 4, 2] & [    0.     0. 10000.     1.   100.     0.] & -10000 \\ \hline
\end{array}
\end{center}

\begin{center}
\begin{array}{ | l | l | l | l | }
	\hline
	\text{Iteration} & \text{Current Basis} & \text{Current x} & \text{Current cost value} \\ \hline
	0 & [3, 4, 5] & [    0.     0.     0.     1.   100. 10000.] & 0 \\ \hline
	1 & [0, 4, 5] & [   1.    0.    0.    0.   80. 9800.] & -100 \\ \hline
	2 & [0, 1, 5] & [   1.   80.    0.    0.    0. 8200.] & -900 \\ \hline
	3 & [0, 1, 2] & [   1.   80. 8200.    0.    0.    0.] & -9100 \\ \hline
	4 & [0, 4, 2] & [   1.    0. 9800.    0.   80.    0.] & -9900 \\ \hline
	5 & [3, 4, 2] & [    0.     0. 10000.     1.   100.     0.] & -10000 \\ \hline
\end{array}
\end{center}
It has to be said, however, that it is only a theoretical drawback and in practice it is rather exceptional for the simplex method to perform more than $m + n$ iterations on its way to an optimal solution \cite{ComTeq}.
%Leke~\cite{Lem} developed the dual simplex method in 1954 but it was not found to be an alternative to the primal simplex method for nearly 40 years. This changed in due to the contributions of Forrest and Goldfarb.After discussing the Karush-Kuhn-Tucker optimalityconditions for linear programming, we derive the \textit{dual simplex method} by applying the simplex method to the dual formulation of the standard 
%form LP. 
\\


\chapter{Interior point methods}
In the 60 years of research since the introduction of the simplex method, this algorithm has been carefully optimized to perform extremely well in practice. However, a problem arose in the 1970s: it turns out that we cannot guarantee that it will work well on all possible linear programs ~\cite{3}.
This problem led to the introduction of the interior point methods for solving LP, which is the argument of this chapter.\\The interior point methods is a family of algorithms solving linear programs which come along with an efficient performance guarantee. They share common features that distinguish them from the simplex method. Each interior point iteration is expensive to compute but can make significant progress toward the solution, while the simplex method usually requires a larger number of inexpensive iterations. Geometrically, the simplex method works around the boundary of the feasible polytope, testing a sequence of vertices in turn until it finds the optimal one. Instead, interior point methods approach the boundary of the feasible set only in the region, but they never actually lie on the boundary of the feasible set.\\
The first commercial interior point method for linear programming was N. Karmarkar's  \textit{projective transformation} procedure \cite{Kar} and developments have continued to these days. 
%The new algorithms can be divided in two main classes, \textit{affine-scaling} and \textit{projective-scaling} algorithms.
%The first ones are easy to describe but hard to analyze, in fact they have very simple, geometrically descriptions, but they don't have a strong convergence theory behind.
%Instead, the second class, that includes the original algorithm studied by Karmakar, involves technicalities such as logarithmic barrier functions and the analysis proceeds to a proof of polynomial-time convergence~\cite{4}.
By the early 1990s, a subclass of IPMs called \textit{primal-dual methods} had distinguished themselves as the most efficient practical approaches. The primal-dual interior point algorithm was introduced by Megiddo \cite{meg}  who used logarithmic barrier methods to solve
the primal and dual problems simultaneously. An efficient
high-order method was proposed by Mehrotra: his second-order predictor-corrector
strategy, that has been incorporated in all primal-dual type implementations \cite{MER} .\\ 
After a brief introduction of the primal-dual methods, we study three important algorithms: the \textit{primal-dual affine scaling}, the \textit{long-path following} and the \textit{Mehrotra predictor-corrector} method.\\
An overview of the details of the first two interior-point algorithms are given in the following chapter, instead no convergence thoery is availabe for the third one. \\
In this research a new long-path following algorithm is proposed, based on a new centering parameter computation. With practical implementations a comparison will be discussed.
%The lack of theoretical analysis of the Mehrotra's algorithm leads to a study  their reliability both in theory and in practice will be shown 

\newpage
\section{Introduction to primal-dual methods}
We consider the linear programming problem formulated in a standard form. \\
Following a fundamentally different approach from the simplex method, the interior-point methods avoid the boundary of the polytope until optimality and focus on the KKT conditions, solving the primal and dual LP currently.\\
\\
\\
The primal-dual methods find primal-dual solutions $(x^{*},\lambda^{*},s^{*})$ by applying variants of Newton's method to the three optimatility conditions \ref{DF}, \ref{PF}, \ref{CC}, and modifying the search directions and the step lengths so that the inequality $(x,s)>0$ is satisfied.\\
The fact that primal and dual variables $x^{k}$ and $s^{k}$ are required to be nonnegative at the solution and are kept strictly positive at each iteration is the origin of the term \textit{interior point}.\\
 Let restate the optimality conditions by a mapping $\mathit{F}$ from $\mathbb{R}^{2n+m}$ to $\mathbb{R}^{2n+m}$:
\begin{center}\label{F}
	$\mathit{F}(x,\lambda,s)= \begin{bmatrix}
	A^{T}\lambda+s-c \\Ax-b \\XSe
	\end{bmatrix}=0$, with $(x,s)\geq0.$
\end{center}
where $X = diag(x_{1}, x_{2},...,)$ and $S = diag(s_{1}, s_{2},...,)$.\\ Note that $\mathit{F}$ is linear in the first two equations and mildly nonlinear in the last equation. \\ All primal-dual methods generate iterates $(x^{k},\lambda^{k},s^{k})$ with $x^{k}$ and $s^{k}$ strictly positive.\\
If we define the primal-dual \textit{feasible set} $\mathcal{F}$ and \textit{strictly feasible set} $\mathcal{F}^{o}$ by
\begin{align*}
\mathcal{F} = \left\lbrace(x,\lambda,s)\;|\;Ax = b, A^{T}\lambda+s =c,\;(x,s)\geq0\right\rbrace, \\
\mathcal{F}^{o} = \left\lbrace(x,\lambda,s)\;|\;Ax = b, A^{T}\lambda+s =c,\;(x,s)>0\right\rbrace, 
\end{align*}
the strict feasibility condition can be written concisely as $(x,\lambda,s)\in\mathcal{F}^{o}$.\\
However, some LP have \textit{no} strictly feasible points, that is $\mathcal{F}^{o}=\emptyset$, although hey still may be feasible $(\mathcal{F}=0)$ and still may have finite optimal solutions.
\begin{ex}
	\begin{equation*}
	\min\limits_{x\in\mathbb{R}^{3}} x_{1} \text{ subject to }x_{1} + x_{3} = 0, x\geq0
	\end{equation*}

and its dual is 
	\begin{equation*}
\max\limits_{\lambda\in\mathbb{R}^{3}, s\in\mathbb{R}^{3}} 0 \text{ subject to } \begin{bmatrix}1\\0\\1\end{bmatrix}\lambda+\begin{bmatrix}
s_{1}\\s_{2}\\s_{3}
\end{bmatrix}=\begin{bmatrix}1\\0\\0\end{bmatrix}, s\geq0 
\end{equation*}
Any feasible primal-dual vector $(x, \lambda, s)\in\mathcal{F}$ has $x_{1}= x_{2}= s_{2}= 0$, so $\mathcal{F}^{o}=\emptyset$. The optimal objective function value for this problem is 0, and the primal-dual solutionn set is defined by
\begin{center}
$x^{*} = \begin{bmatrix}
0\\x^{*}_{2}\\ 0
\end{bmatrix}$ and $s^{*}=\begin{bmatrix}
1-\lambda^{*}\\0\\-\lambda^{*}
\end{bmatrix}$,  
\end{center}
where $x^{*}$ and $\lambda^{*}$ are any numberes for which $x_{2}^{*}\geq0$ and $\lambda^{*}\leq0$.
\end{ex}
\\
The Newton's method (see Appendix) forms a linear model for $\mathit{F}$ around the current point and obtains the search direction $(\Delta x,\Delta \lambda,\Delta s)$ by solving the following system of linear equations:
\begin{center}
	$\mathit{J}(x,\lambda,s)\begin{bmatrix}
	\Delta x\\\Delta\lambda \\\Delta s
	\end{bmatrix}=-\mathit{F}(x,\lambda,s)$,
\end{center}
where $\mathit{J}$ is the Jacobian of the linear $\mathit{F}$. If the current point $(x, \lambda, s)\notin\mathcal{F}$, the Newton step equations becomes

\begin{equation}\label{(5.1)}
	\begin{bmatrix}
0&A^{T}&I \\A&0&0\\S&0&X
	\end{bmatrix}\begin{bmatrix}
	\Delta x\\\Delta\lambda \\\Delta s
	\end{bmatrix}=\begin{bmatrix}
	c-A^{T}\lambda-s\\b-Ax\\XSe
	\end{bmatrix}.
\end{equation}

A full step along this direction usually is not permissible, since it would violate the bound $(x,s)>0$. To avoid this difficulty, we perform a line search along the Newton direction so that the new iterate is
\begin{equation*}
	(x,\lambda,s) +\alpha (\Delta x,\Delta \lambda,\Delta s)
\end{equation*} 
for some line search parameter $\alpha \in (0,1]$. \\We maintain positivity conditions of $(x,s)$ at all iterates for two reasons. First, vectors that solve $\mathit{F}$ that have negative components are of no interest in terms of solving the primal and dual problems \ref{Prim} and \ref{Dual}. Second, when the matrix $A$ has linearly indipendent rows, the Jacobian $J$ is guaranteed to be nonsingular whenever $x>0$ and $s>0$ hold, and so the solution is guaranteed.

\section{Primal-dual affine-scaling method}

The simplest primal-dual approach is to apply Newton's method directly to the function $F$, using in the $k^{th}$ iteration a step length $\alpha_{k}$ of less than one in order to have $(x^{k+1},\lambda^{k+1},s^{k+1})\in \mathcal{F}^{o}$. There are different ways to do this and the resulting algorithms are called \textit{Primal-dual affine-scaling methods}, for short Affine-scaling methods, which were proposed for linear programming by Monteiro,
Adler and Resende \cite{MARE}.\\ 
 The general primal-dual affine-scaling algorithm takes the following form:\\
\begin{algorithm}[H]
\begin{tabbing}
	\textbf{Given} $(x^{o}, \lambda^{o}, s^{o})$ with $(x^{o}, s^{o})>0$;\\
	\textbf{for} \= $k = 0, 1, 2,...$ \\
	\> Solve
\end{tabbing}
\begin{equation}\label{(AS)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
\end{bmatrix}\begin{bmatrix}
\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
\end{bmatrix}=-\begin{bmatrix};
0\\0\\X^{k}S^{k}e
\end{bmatrix}
\end{equation}
\begin{tabbing}
	\\
	\textbf{Set} \=$(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$
	\\
	\> chose $\alpha_{k}$ so that $(x^{k+1},\lambda^{k+1}, s^{k+1})\in\mathcal{F}^{o}$ \\
	\textbf{end}
\end{tabbing}
\caption{Primal dual affine scaling  algorithm}
\end{algorithm}

The solution of this system $\left(\Delta x^{k},\Delta\lambda^{k},\Delta s^{k}\right)$ has either $\Delta x_{i}^{k}<0$ or $\Delta s_{i}^{k}<0$, or both because $x^{k}>0$ and $s^{k}>0$ and $s^{k}_{i}\Delta x^{k}_{i} + x^{k}_{i}\Delta s^{k}_{i} = - x^{k}_{i}s^{k}_{i}$, by the last block row of this system.
Then, we need to choose $\alpha_{k}$ such that
\begin{align*}
x^{k}_{i} + \alpha_{k} \Delta x^{k}_{i} >0 \\
s^{k}_{i} + \alpha_{k} \Delta s^{k}_{i} >0 \\	\text{for\;} i = 1,...,n.
\end{align*}
and the largest value of $\alpha_{k}$ that satisfies these inequalities is computed by the following formula, which is similar to the ratio test used by the simplex method. 
\begin{align*}
\alpha_{\max} = \min\bigg(\min_{i|\Delta x^{k}_{i}<0}\frac{x^{k}_{i}}{\Delta x^{k}_{i}}, \min_{i|\Delta s^{k}_{i}<0}\frac{s^{k}_{i}}{\Delta s^{k}_{i}}\bigg)
\end{align*} 

We can step back from this maximum value, and prevent each $x_{i}$ and $s_{i}$ from being too close to zero, by defining $\alpha_{k} = min\left(1,\eta_{k}*\alpha_{max}\right)$, with $\eta_{k}$ usually $0.999$.\\
We then define the new iterate $(x^{k},\lambda^{k},s^{k}) +\alpha^{k} (\Delta x^{k},\Delta \lambda^{k},\Delta s^{k})$.\\
This approach is called \textit{primal-dual affine scaling} and often does not allow us to make much progress toward a solution. Even though, the search direction steps are used to find the predictor directions in the predictor-corrector algorithms, explained in the next pages. 
Most primal-dual methods use less aggressive Newton search direction, making a perturbation of the system $F$ and they are presented in the next section.

\section{Long path-following methods}

Another strategy for solving a linear program is to follow a central path from a given initial primal-dual solution point.\\ Assuming $\mathcal{F}^{o}\neq \varnothing$, the \textit{central path} $\mathcal{C}$ is an arc of strictly feasible points that play an important role in the following primal-dual algorithm. It is parametrized by a scalar $\tau  > 0$ and each point $(x_{\tau}, \lambda_{\tau}, s_{\tau})\in \mathcal{C}$ satisfies the following equations:
\begin{align}
A^{T}\lambda+s&=c\\
Ax&=b\\\label{KKT2}
x&\geq 0\\
s&\geq 0\\
x_{i}s_{i}&= \tau,\; \text{for}\;i= 1,2,...,n.\label{(Tao)}
\end{align} 
The conditions above are also the optimality conditions for the following logarithmic-barrier formulation (P$_{\tau}$) of the original problem (P):
\begin{equation}\label{log}
\begin{split}
\text{minimize\;} &c^{T}x + \tau\sum_{i=0}^{n}\ln{x_{i}}\\
\text{subject\; to\;}&Ax = b\;\text{and\;} x\geq0
\end{split}
\end{equation}
In fact, the KKT conditions for this problem, with Lagrange multiplier $\lambda$ for the equality constraint, are
\begin{equation*}
c_{i} - \dfrac{\tau}{x_{i}} - A^{T}_{i}\lambda,\; \text{for}\;i = 1,2,...,n.
\end{equation*}  
Since the objective function is strictly convex, these conditions are sufficient as well as necessary for optimality. Besides, defining $s_{i} = \dfrac{\tau}{x_{i}}$, we recover the last KKT equation: it requires that the pairwise products $x_{i}s_{i}$ have the same value for all indices $i$.\\
Now we see the relation between the (P$_{\tau}$) and (P) with the following result.
\begin{prop}
	Assume that the set $\mathcal{P}^{o} = \mathcal{P}\cap\{x\in\mathbb{R}^{n}| x> 0\}$ is non-empty and let $\tau>0$ be given. Then problem (P$_{\tau}$) has an optimal solution if and only if the set of optimal solutions of (P) is non-empty and bounded.
\end{prop}
A proof of the proposition can be found in \cite{meg}. From this result, we immediately conclude that if (P$_{\tau}$) has a solution for some $\tau>0$ then it has a solution for all $\tau>0$.
\begin{prop}
	Assume that problem (P) is feasible. Then the set of optimal solutions of (P) is non-empty and bounded if and only if $\mathcal{D}^{o} = \mathcal{D}\cap\{x\in\mathbb{R}^{n}| s> 0\}$  is non-empty.
\end{prop}
The proof is an application of duality theory fo linear programming. As a consequence of the two previous propositions, we have the following corollary.
\begin{cor}
If the sets $\mathcal{P}^{o}$ and $\mathcal{D}^{o}$ are non-empty, the problem (P$_{\tau}$) (and consequently the relative KKT conditions) has a unique solution $(x(\tau),\lambda(\tau),s(\tau))$, for all $\tau>0$. 
\end{cor}
Let $(x(\tau), \lambda(\tau), s(\tau))$ be on the primal-dual path $\mathcal{C}$, then the non negative dual gap assumes this value: $c^{T}x-b^{T}\lambda=\left(c-A^{T}\lambda\right)^{T}x=s^{T}x=\tau$.\\
It means that the dual gap provides a measure of closeness to optimality. It is clear that as $\tau\to0$ the duality gap goes to zero, and hence both $x(\tau)$ and
 $(\lambda(\tau), s(\tau))$ approach to the common optimal values of the roblems (P) and (D) respectively. The central path guides us to a solution along a route that maintains positivity of the $x$ and $s$ components and decreases the pairwise products $x_{i}s_{i},\;i = 1,2,...,n$ to zero at the same rate.\\
 
 
 Defining $\mathcal{C}$ with the notation introduced in the first section, we have the following mapping $\mathit{F}$:
 \begin{center}
 	$\mathit{F}(x,\lambda,s)= \begin{bmatrix}
 	A^{T}\lambda+s-c \\Ax-b \\XSe
 	\end{bmatrix}=\begin{bmatrix} 0\\0\\ \tau e \end{bmatrix}$, with $(x,s)\geq0$.
 \end{center}
Then, Newton steps toward points on $\mathcal{C}$ are computed as following:
 \begin{equation}\label{new}
 \begin{bmatrix}
 0&A^{T}&I \\A&0&0\\S&0&X
 \end{bmatrix}\begin{bmatrix}
 \Delta x\\\Delta\lambda \\\Delta s
 \end{bmatrix}=\begin{bmatrix}
 0\\0\\-XSe + \tau e
 \end{bmatrix}.
 \end{equation}
 Path-following methods follow $\mathcal{C}$ in the direction of decreasing $\tau$ to the solution set but they do not necessarily stay exactly on $\mathcal{C}$ or even particularly close to it. In fact they compute the target value $\tau = \sigma \mu$, where $\sigma = [0,1]$ is called \textit{centering parameter} and $\mu$ the \textit{duality measure}, defined by
 \begin{equation*}
 \mu = \frac{1}{n}\sum_{i=1}^{n} x_{i}s_{i} = \frac{x^{T}s}{n}.
 \end{equation*}\\
 The perturbation $\sigma\mu$ guarantees progress in reducing the duality gap $x^{T}s$,
 in this way path-following interior point algorithms attempt to reduce the term from
 its current value $\mu$ to a new one $\sigma\mu$. In fact, if we state the last equation of \ref{new} in vectorial form, we have:
 \begin{equation}
 S\Delta x + X\Delta s = s^{T}\Delta x + x^{T}\Delta s = - XSe + \sigma \mu e = (-1 + \sigma)x^{T}s
 \end{equation}
 and provides the necessary term to estimate the progress of the
 algorithm.\\  
 \\
 A path-following algorithm explicity restricts the iterates to a neighborhood of the central path $\mathcal{C}$: if $\sigma = 1$, the equations define a \textit{centering direction}, a Newton step toward the point $(x_{\sigma\mu},\lambda_{\sigma\mu}, s_{\sigma\mu})\in\mathcal{C}$, if $\sigma = 0$ then we have the \textit{affine-scaling method}.\\  
 Many algorithms use intermediate values of $\sigma$ in $(0,1)$ to trade off between the twin goals of reducing $\mu$ and improving centrality. The neighborhood excludes points $(x, s) $ that are too close to the boundary of the nonegative orthant. Therefore, search directions calculated from any point in the neighborhood make at least minimal progress toward the solution set.
 We define the two most interesting neighborhoods of the central path as given
by Mizuno et al~\cite{5}:\\
\begin{equation*}
\mathcal{N}_{2}(\theta) =\{(x, \lambda,s)\in\mathcal{F}^{o} \;|\;\lVert XSe - \mu e \rVert \leq \theta \mu \}, \text{\;for some\;} \theta \in [0,1),
\end{equation*} 
\begin{equation*}
\mathcal{N}_{-\infty}(\gamma) =\{ (x, \lambda,s)\in\mathcal{F}^{o} \;|\; x_{i}s_{i} \geq \gamma \mu \}, \text{\;for some\;} \gamma \in [0,1).
\end{equation*} 
A disadvantage of the $\mathcal{N}_{2}(\theta)$ neighborhood is its restrictive nature \cite{W}: from the definition above, we have for $(x, \lambda,s)\in\mathcal{N}_{2}(\theta)$ that
\begin{center}
	$\sum\limits_{i=1}^{n}\big(\frac{x_{i}s_{i}}{\mu}-1\big)^{2}\leq \theta^{2}<1$
\end{center} 
so that the sum of squares of all relative deviations of $x_{i}s_{i}$ from their average value $\mu$ cannot exceed 1. Even if $\theta$ is close to its upper bound of 1, the neighborhood $\mathcal{N}_{2}(\theta)$ contains only a small fraction of the points in the strictly feasible set $\mathcal{F}^{o}$. The neighborhood $\mathcal{N}_{-\infty}(\gamma)$, on the other hand, is much more expansive: when $\gamma$ is small, it takes up almost the entire strictly positive feasible set $\mathcal{F}^{o}$. 
\newpage
\subsection{LPF algorithms}
In this research we discuss the \textit{long-step path-following algorithms}, that are based on the second neighborhood. Since  $\mathcal{N}_{-\infty}(\gamma)$ is a larger central path neighborhood, it allows for more flexibility in the choice of the next iterate and hence larger  step length (hence, the name long-step method). It depends on two parameters $\sigma_{min}$, $\sigma_{max}$, which are lower and upper bounds on the centering parameter $\sigma_{k}$. After computed the search direction with the Newton method, the step length $\alpha_{k}$ is chosed as the maximum value subject to staying inside $\mathcal{N}_{-\infty}(\gamma)$.
The general path-following algorithm is:
\begin{algorithm}[H]
	\begin{tabbing}
		\textbf{Given  }\= $\gamma\in(0,1)$, $\sigma_{\text{min}}$, $\sigma_{\text{max}}$, with $0<\sigma_{\text{min}}< \sigma_{\text{max}}<1$,\\
		\> and $(x^{o}, \lambda^{o}, s^{o})\in\mathcal{N}_{-\infty}(\gamma)$;\\
		\textbf{for} \= $k = 0, 1, 2,...$ \\
		\> Choose $\sigma_{k}\in[\sigma_{\text{min}},\sigma_{\text{max}}]$ and solve
	\end{tabbing}
	\begin{equation}\label{P}
	\begin{bmatrix}\label{P}
	0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
	\end{bmatrix}\begin{bmatrix}
	\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
	\end{bmatrix}=-\begin{bmatrix}
	A^{T}y^{k}+s^{k}-c\\Ax^{k}-b\\-X^{k}S^{k}e + \sigma_{k}\mu_{k}e
	\end{bmatrix};
	\end{equation}
	\begin{tabbing}
		\\
		$\;\;\;\;\;$\=choose the largest $\alpha_{k}\in[0,1]$ so that $(x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})\in\mathcal{N}_{-\infty}(\gamma)$ \\
		\>set $(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$;\\
		
		\textbf{end}
	\end{tabbing}
	\caption{General LPF algorithm}
\end{algorithm}
%\begin{tabbing}
%	\textbf{Given} $\gamma, \sigma_{min}, \sigma_{max}$ and $(x^{o}, \lambda^{o}, s^{o})\in\mathcal{N}_{-\infty}(\gamma)$ with $(x^{o}, s^{o})>0$;\\
%	\textbf{for} \= $k = 0, 1, 2,...$ \\
%	\> Choose $\sigma_{k}\in[\sigma_{min},\sigma_{max}]$ and solve
%\end{tabbing}
%\begin{equation}\label{(5.9)}
%\begin{bmatrix}
%0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
%\end{bmatrix}\begin{bmatrix}
%\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
%\end{bmatrix}=-\begin{bmatrix}
%0\\0\\-X^{k}S^{k}e + \sigma_{k}\mu_{k}e
%\end{bmatrix}
%\end{equation}
%\begin{tabbing}
%	\textbf{Set} \=$(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$\\
%	\> Choosing the largest value in $\alpha_{k}\in[0,1]$ so that $(x^{k+1}, \lambda^{k+1}, s^{k+1})\in\mathcal{N}_{-\infty}(\gamma)$\\
%	\textbf{end}
%\end{tabbing}

The following lemma shows properties of the points in $\mathcal{N}_{-\infty}(\gamma)$ that are used in the analysis section.
\begin{lem}
	Let $\mu_{0}\geq 0$ and $\gamma\in(0,1)$. Then for all points $(x,\lambda,s)$ with
	\begin{equation*}
	(x,\lambda,s)\in\mathcal{N}_{-\infty}(\gamma)\subset\mathcal{F}^{o}, \;\; \mu \leq \mu_{0}
	\end{equation*}
	there are constants $C_{0}$ and $C_{1}$ such that
\begin{align*}
\lVert(x,s) \rVert&\leq C_{0}\\0< x_{i}&\leq \mu/C_{1}\;\; (i \in\mathcal{N}),\\
0< s_{i}&\leq \mu/C_{1}\;\; (i \in\mathcal{B}),\\ 
s_{i}&\geq C_{1}\gamma \;\; (i \in\mathcal{N}),\\
x_{i}&\geq C_{1}\gamma \;\; (i \in\mathcal{B}).\\
\end{align*}
\end{lem}
\begin{proof}
~\cite{Wright} pag. 101
\end{proof}
In the general framework \textbf{Algorithm 1} we have not specified how the centering parameter is choosen: different interior-point algorithms use a peculiar method to select $\sigma_{k}$.\\
Now we see two heuristic choices of $\sigma_{k}$ at the $k^{th}$ iteration of the algorithm; the first one decreases at each iteration and the second one is fixed: 
\begin{align}
\sigma^{1}_{k} &= \min\{0.1, 100\mu_{k} \},\label{LPF1}\\
\sigma^{2}_{k} &= 1 -\frac{0.5}{\sqrt{n}}\\\label{LPF2}
\end{align}
with $\mu_{k}$ the duality measure of the current primal-dual point and $n$ is the number of entries of $x$ and $s$. 
Analyzing the graphic \ref{fig:float} we state that the \textbf{Algorithm 1} with the centering parameter \ref{LPF1} requires a less number of iterations and less time storage to find a LP solution.\\
In the research we present a predictor-corrector LPF algorithm based on Mehrotra's method, in which the centering parameter is choosen adaptively.\\
\begin{figure}
\begin{center}
\includegraphics[width=9 cm]{timeLPF12}\caption{Log plot time storage} \label{fig:float}
\end{center}
\end{figure}
\newpage
\section{Predictor-corrector algorithms}
Most interior-point software written since 1990s have been based on Mehrotra's predictor-corrector algorithm (MPC).\\
Since Karmarkar's landmark paper \cite{Kar}, IPMs became one of the most active research area that produced a large amount of research results. Moreover, several powerful methods have been developed: predictor-corrector methods are among the most efficient and most implementations are based on a variant of Mehrotra's algorithm. \\
The Mehrotra's contribution was to combine the work developed by Montiero, Adles and Resende \cite{MARE} and the infeasible-interior-point path-following approach implemented by Lustig, Marsten and Shanno \cite{LMS}.\\ 
The method incorporates these algorithmic devices that contribute to its practical success, including the use of different step lengths for the primal and dual variables and a heuristic choice of the step lengths that is designed to speed the asymptotic convergence.\\
It generates sequence of infeasible iterates $(x^{k},\lambda^{k},s^{k})$ for which $(x^{k},s^{k})>0$. The search direction at each iteration consists of three components:
\begin{enumerate}
	\item an affine-scaling "predictor" direction,
	\item a centering term whose size is governed by the adaptively chosen centering parameter $\sigma$,
	\item a "corrector" direction that attempts to compensate for some of the nonlinearity in the affine-scaling direction.
	\end{enumerate}
The first two components, the affine-scaling step and the centering term, combine to generate the standard infeasible-interior-point step from the generic equations. However, the affine-scaling component is calculated before the centering component. By arranging the computations in this way, we gain a key advantage: the ability to choose the centering parameter $\sigma$ adaptively rather then a priori, as in the algorithm LPF.\\
If the affine-scaling direction makes good progress in reducing the duality measure $\mu$ while remaining inside the positive orthant defined by $(x,s)>0$, we conclude that little centering is needed, so we choose $\sigma$ close to 1.
\subsection*{Mehrotra's algorithm}
Given a point $(x, \lambda, s)$ with $(x, s)> 0$, we compute the affine-scaling direction:
\begin{equation}\label{(A)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{aff}}\\\Delta\lambda^{\text{aff}}\\\Delta s^{\text{aff}}
\end{bmatrix}=-\begin{bmatrix}
A^{T}\lambda+s-c\\Ax-b\\XSe
\end{bmatrix}.
\end{equation}
Now we find the step lengths to the boundary along this direction, performing separate calculations for the primal and dual components as follow:
\begin{align}\label{Qw}
\alpha_{\text{aff}}^{\text{pri}}=\arg\max\{\alpha\in[0,1]\;|\;x +\alpha\Delta x^{\text{aff}}\geq 0\} \\
\alpha_{\text{aff}}^{\text{dual}}=\arg\max\{\alpha\in[0,1]\;|\;s +\alpha\Delta s^{\text{aff}}\geq 0\}
\end{align}
To measure the efficacy of the affine-scaling direction, we define $\mu_{\text{aff}}$ as the hypothetical value of $\mu$ resulting from a full step to the boundary, that is,
\begin{equation*}
	\mu_{\text{aff}}= (x+\alpha_{\text{aff}}^{\text{pri}}\Delta x^{\text{aff}})^{T}(s+\alpha_{\text{aff}}^{\text{dual}}\Delta s^{\text{aff}})/n
\end{equation*}
If $\mu_{\text{aff}}\ll\mu$, the affine-scaling direction is a good search direction that permits significant progress to be made in reducing $\mu$, so we choose the centering parameter $\sigma$ close to 0. If $\mu_{\text{aff}}$ is just a little smaller than $\mu$, we choose $\sigma$ closer to 1. This choice has the effect of moving us closer  to the central path $\mathcal{C}$, so that the algorithm is in a better position to achieve a substantial decrease in $\mu$ on the next iteration.\\
Mehrotra \cite{MER} suggests the following heuristic, which has proved to be effective in exhaustive computational testing:
\begin{equation}\label{CP}
\sigma = \bigg(\frac{\mu_{\text{aff}}}{\mu}\bigg)^{3}.
\end{equation}
The centering step component is computed solving a linear system with the same coefficient matrix as in \ref{(A)} but the right-hand side equal to $[0, 0,\sigma\mu e]$: actually it is combined with the corrector step, as we see later.\\
To motivate the corrector step, we see how the $i$th pairwise product $x_{i}s_{i}$ is affected by a full step in the affine-scaling direction:
\begin{equation*}
(x_{i}+\Delta x_{i}^{\text{aff}})(s_{i}+\Delta s_{i}^{\text{aff}})= x_{i}s_{i}+ x_{i}\Delta s_{i}^{\text{aff}}+s_{i}\Delta x_{i}^{\text{aff}}+\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}} =\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}}.
\end{equation*}
When a full step is taken, the pairwise product $x_{i}s_{i}$ transforms to $\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}}$, instead of 0. The corrector component $(\Delta x^{\text{cor}}, \Delta \lambda^{\text{cor}}, \Delta s^{\text{cor}})$ tries to compensate for this deviation from linearity, modifying the search direction so that the pairwise products come closer to their target value to 0. This step satisfies the following system:
\begin{equation}\label{(B)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{cor}}\\\Delta\lambda^{\text{cor}} \\\Delta s^{\text{cor}}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\\Delta X^{\text{aff}}\Delta S^{\text{aff}}e
\end{bmatrix}.
\end{equation}
where
\begin{align*}
\Delta X^{\text{cor}}& = \text{diag}(\Delta x_{1}^{\text{aff}}, \Delta x_{2}^{\text{aff}},\dots,\Delta x_{n}^{\text{aff}})\\
\Delta S^{\text{cor}}& = \text{diag}(\Delta s_{1}^{\text{aff}}, \Delta s_{2}^{\text{aff}},\dots,\Delta s_{n}^{\text{aff}}).
\end{align*}
To assess the effect of the corrector component, we examine the pairwise product obtained from a full step along the combined affine-scaling/corrector direction. From \ref{(B)}:
\begin{equation*}
(x_{i}+\Delta x_{i}^{\text{aff}}+\Delta x_{i}^{\text{cor}})(s_{i}+\Delta s_{i}^{\text{aff}}+\Delta s_{i}^{\text{cor}})= \Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{cor}}+\Delta x_{i}^{\text{cor}}\Delta s_{i}^{\text{aff}}+\Delta x_{i}^{\text{cor}}\Delta s_{i}^{\text{cor}}.
\end{equation*}
This result yelds to a better reduction of the duality measure: in fact we have \\$\lVert(\Delta x^{\text{aff}},\Delta s^{\text{aff}}) \rVert = \mathcal{O}(\mu)$ and $\lVert(\Delta x^{\text{cor}},\Delta s^{\text{cor}}) \rVert = \mathcal{O}(\mu^{2})$.
\\
When the limiting matrix is singular, the corrector step may no longer be smaller in norm than the affine-scaling step, ideed, it is often larger. Even in this situation, the use of the corrector component usually enhances the overall efficiency of the algorithm in practice.\\
Since the centering and corrector components are obtained by solving linear system with the same coefficient matrix and they are indipendent each other, we can merge them into a single direction by adding their corresponding right-hand sides and compute the combined direction. 
We obtain the combined centering-corrector step $(\Delta x^{\text{cc}}, \Delta \lambda^{\text{cc}}, \Delta s^{\text{cc}})$ solving the following system:
\begin{equation}\label{(C)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{cc}}\\\Delta\lambda^{\text{cc}} \\\Delta s^{\text{cc}}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\\Delta X^{\text{aff}}\Delta S^{\text{aff}}e - \sigma\mu e
\end{bmatrix}.
\end{equation}
Although we need to solve at each iteration two linear systems instead of one, the marginal cost is not great because the systems have the same coeffifient matrix and then we need only modify the right-hand side. \\
 Having described the essential elements of Mehrotra'a approach, the algorithm is structured as following:
\\
\textbf{Mehrotra's algorithm}
\begin{tabbing}
	\textbf{Given} $(x^{o}, \lambda^{o}, s^{o})> 0$; \\
	\textbf{for} \= $k = 0, 1, 2,...$ \\
	\> solve \ref{(A)} for $(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})$;\\
	\> calculate $\alpha_{\text{aff}}^{\text{pri}}$, $\alpha_{\text{aff}}^{\text{dual}}$ and $\mu_{\text{aff}}$ as in \ref{Qw};\\
	\> set centering parameter to $\sigma = (\mu_{\text{aff}}/\mu)^{3}$; \\
	\> solve \ref{(C)} for $(x^{cc},\lambda^{cc},s^{cc})$;\\
	\> compute the search direction and step to boundary from: \\
	\> \\
	\> $\;\;\;\;\;\;\;(\Delta x^{k},\Delta \lambda^{k},\Delta s^{k})=(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+(\Delta x^{cc},\Delta  \lambda^{cc},\Delta s^{cc})$;\\
	\> $\;\;\;\;\;\;\;\alpha_{\text{max}}^{\text{pri}}=\arg\max\{\alpha\geq0\;|\;x^{k} +\alpha\Delta x^{k}\geq 0\}$,\\
	\> $\;\;\;\;\;\;\;\alpha_{\text{max}}^{\text{dual}}=\arg\max\{\alpha\geq0\;|\;s^{k} +\alpha\Delta s^{k}\geq 0\}$,\\
	\>\\
	\> set $\alpha_{k}^{\text{pri}}=\min(0.99\ast\alpha_{\text{max}}^{\text{pri}},1)$ and $\alpha_{k}^{\text{dual}}=\min(0.99\ast\alpha_{\text{max}}^{\text{dual}},1)$;\\
	\> set\\
	\> $\;\;\;\;\;\;\;x^{k+1} = x^{k} + \alpha_{k}^{\text{pri}}\Delta x^{k}$;\\
	\>$\;\;\;\;\;\;\;(\lambda^{k+1},s^{k+1}) = (\lambda^{k},s^{k}) + \alpha_{k}^{\text{dual}}\Delta (\lambda^{k},\Delta s^{k})$;\\
\textbf{end}
\end{tabbing}
\subsection*{A predictor-corrector LPF method}
In this research it is proposed a predictor-corrector long-path following method (PC-LPF) in which the centering parameter $\sigma$ is computed adaptively, equal to \ref{CP}.\\
This predictor-corrector algorithm below is a definite improvement over the long-path following algorithm because of the adaptivity that is buil into the choice of the predictor step.
The values of the step lengths and the centering parameter are performed in order to guarantee that the next iteration $(x^{k}, \lambda^{k}, s^{k})$ is in $\mathcal{N}_{-\infty}(\gamma)$:
\begin{align}\label{QWw}
\alpha_{\text{aff}}^{\text{pri}}=\arg\max\{\alpha\in[0,1]\;|\;(x^{k}, \lambda^{k}, s^{k})+ \alpha(\Delta x^{\text{aff}}, \Delta\lambda^{\text{aff}}, \Delta s^{\text{aff}})\in\mathcal{N}_{-\infty}(\gamma)\}
\end{align}
To measure the efficacy of the affine-scaling direction, we define $\mu_{\text{aff}}$ as the hypothetical value of $\mu$ resulting from a full step to the boundary, that is,
\begin{equation*}
\mu_{\text{aff}}= (x+\alpha_{\text{aff}}^{\text{pri}}\Delta x^{\text{aff}})^{T}(s+\alpha_{\text{aff}}^{\text{dual}}\Delta s^{\text{aff}})/n
\end{equation*}
\\
\textbf{PC-LPF algorithm}
\begin{tabbing}
	\textbf{Given} $(x^{o}, \lambda^{o}, s^{o})> 0$; \\
	\textbf{for} \= $k = 0, 1, 2,...$ \\
	\> solve \ref{(A)} for $(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})$;\\
	\> calculate $\alpha_{\text{pre}}^{\text{pri}}$ and $\mu_{\text{aff}}$ as in \ref{QWw};\\
	\> set centering parameter to $\sigma_{k} = (\mu_{\text{aff}}/\mu)^{3}$; \\
	\> solve \ref{P} for $(\Delta x^{k},\Delta \lambda^{k},\Delta s^{k})$;\\
	\> choose the largest value in $\alpha_{k}\in[0,1]$ so that $(x^{k+1}, \lambda^{k+1}, s^{k+1})\in\mathcal{N}_{-\infty}(\gamma)$;\\
	\textbf{end}
\end{tabbing}
We can notice that in the two algorithms the starting point is not necessarily feasible, this approach is elaborated in the next chapter.
\section{IPM algorithms performance}
In this section we develop an empirical study of the IPM algorithms performace. \\
We introduce a model that allow us to summirize the results obtained in this fashion: we ralte the number of iterations $T$ required to solve a LP to number of constraints $m$ and/or the number of variables $n$ in the problem. We may assume that $T$ can be approximated by a function of the form \begin{equation}
	T = 2^{\alpha}(m+n)^{\beta}
\end{equation}
for a pair of real numbers $\alpha$ and $\beta$. This multiplicative representation of the numbers of iterations can be converted into an additive representation by taking logarithms. Introducing an $\epsilon$ to value the difference between the model's prediction and the true number of iterations, we see that the model can be written as
\begin{equation}
\log T = \alpha \log 2 +\beta \log (m+n) +\epsilon.
\end{equation}
\\For each empirical observation we find the two parameters $\alpha$ and $\beta$ and compute $T$ related to the IPM methods proposed: long-path following algorithms with centering parameter $\sigma_{k}^{1}$ and with $\sigma_{k}^{2}$, LPF PC and Mehrotra's algorithms. \\
The figure \ref{figure:T} shows a log-log plot of iterations versus $m + n$.
\begin{figure}\label{figure:T}
	\begin{center}
		\includegraphics[width= 15 cm]{numberiterations}\caption{number of iterations} \label{fig:float}
	\end{center}
\end{figure}
%\lstinputlisting[language=py,caption=applicationContext.py]{Forest.py}
\chapter{Convergence analysis}
In this section it is delineated a complete convergence analysis important theoretical results. 
\section{Affine-scaling method convergence}
We examine the asymptotic behavior of this method, that is of significant theoretical interest.  For $(x, \lambda, s)\in\mathcal{F}^{o}$ the affine-scaling direction $(\Delta x, \Delta \lambda, \Delta s)$ satisfies the following matricial system:\\
\begin{equation}\label{5.1}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\S&0&X
\end{bmatrix}\begin{bmatrix}
\Delta x\\\Delta\lambda \\\Delta s
\end{bmatrix}=-\begin{bmatrix}
0\\0\\XSe
\end{bmatrix}.
\end{equation}\\
	
 We first obtain a bound of the direction vector $(\Delta x,\Delta \lambda, \Delta s)$ for the feasibility case: more precisely we assume that $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$.
\begin{lem}
Suppose that $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$ and that the affine-scaling direction $(\Delta x,\Delta \lambda, \Delta s)$ is calculated. Then there is a costant $C$ such that
\begin{equation*}
	\lVert \Delta x_{\mathcal{B}} \rVert \leq C \mu \text{\;and\;} \lVert \Delta s_\mathcal{B} \rVert \leq C \mu,
\end{equation*}
with the set $\mathcal{B}$ defined previously. 
\end{lem}
\begin{proof}
	Let us define the positive diagonal matrix $D = X^{1/2}S^{-1/2}$. Multiplying the last block row of \ref{5.1} by $(XS)^{-1/2}$, we obtain 
	\begin{equation*}
	D^{-1}\Delta x + D \Delta s = -(XS)^{1/2}e.
	\end{equation*}
	Taking inner products of both sides of this expression, we have
		\begin{equation*}
	\lVert D^{-1}\Delta x \rVert^{2} + 2\Delta x^{T}\Delta s+ \lVert D\Delta s \rVert^{2}= \lVert(XS)^{1/2}e\rVert^{2}= x^{T}s= n\mu.
	\end{equation*}
	Because $\Delta x^{T}\Delta s= 0$ and the other two terms are positive, we can write
	\begin{equation*}
	\lVert D^{-1}\Delta x\rVert^{2}\leq n\mu, \;\;\lVert D\Delta s\rVert^{2}\leq n\mu.
	\end{equation*}
	Since $D_{i,i}= \sqrt{x_{i}/s_{i}}$, we have for any $i$ that
	\begin{equation*}
	\frac{s_{i}}{x_{i}}(\Delta x_{i})^{2}\leq\lVert D^{-1}\Delta x\rVert^{2}\leq n\mu.
	\end{equation*}
	Hence, choosing $i\in\mathcal{N}$ and using $x_{i}s_{i}\geq\gamma\mu$, we find that
	\begin{equation*}
	(\Delta x_{i})^{2}\leq\frac{n\mu x_{i}}{s_{i}}=\frac{n\mu x_{i}^{2}}{x_{i}s_{i}}\leq\frac{n\mu^{3}}{\gamma\mu C^{2}}\mu^{2}.
	\end{equation*}
	Therefore, we have 
	\begin{equation*}
	\lVert \Delta x_{\mathcal{N}}\rVert \leq \sqrt{n}\max\limits_{i \in \mathcal{N}}|\Delta x_{i}|\leq\frac{n}{\gamma^{1/2}C}\mu.
	\end{equation*}
	To argument for $\lVert \Delta s_{\mathcal{B}}\rVert$ is identical.
\end{proof}
Now we show that $\lVert \Delta x_{\mathcal{B}}\rVert$ and $\lVert \Delta s_{\mathcal{N}}\rVert$ are also $\mathcal{O}(\mu)$ with the following two technical lemmas and an important theorem.
\begin{lem} \label{(T)}
	Let the matrix $H\in\mathbb{R}^{p,q}$ be given. Then there exists a nonnegative constant $\bar{C}$ depending only on $H$ with the following property: for any vector $h\in Range(H)$ and any nonsingular diagonal matrix $\Sigma$, the unique solution $\bar{w}$ of the problem
	\begin{align*}
	\min\limits_{w}\frac{1}{2}\lVert\Sigma w\rVert^{2} \text{\;subject to\;} Hw = h\\\text{satisfies\;} \lVert\bar{w}\rVert\leq \bar{C}\lVert h\rVert.
	\end{align*}
\end{lem}
The next lemma is due essentially to Adler and Montiero \cite{ADL}. $A_{\mathcal{B}}$,  Let us denote $A_{\mathcal{N}}$, $D_{\mathcal{B}}$ and $D_{\mathcal{N}}$ a column partition of the matrices respectively $A$ and $D$, according to the sets $\mathcal{B}$ and $\mathcal{N}$.
\begin{lem}
	Suppose that the assumption of the lemma \ref{(T)} hold. Then
	\begin{enumerate}
		\item $u = \Delta x_{B}$ is the unique solution of the following convex quadratic problem
		\begin{align} \label{(U)}
			\min\limits_{u}\frac{1}{2}\lVert D_{\mathcal{B}}^{-1}u\rVert^{2} \text{subject to }A_{\mathcal{B}}u = -A_{\mathcal{N}}\Delta x_{\mathcal{N}}
		\end{align}
			\item $(v, \pi) = (\Delta s_{N}, \Delta \lambda)$ is a solution of the convex quadratic problem
	\begin{align}
		\min\limits_{(v, \pi)}\frac{1}{2}\lVert D_{\mathcal{N}}v\rVert^{2} \text{ subject to } &A_{\mathcal{B}u} = -A_{\mathcal{N}}\Delta x_{\mathcal{N}}\\
		&A_{\mathcal{N}^{T}\pi}+ v =0		 
	\end{align}
		The $\Delta s_{\mathcal{N}}$ component is unique.
	\end{enumerate} 
\end{lem} 
\begin{proof}
	\textit{1}. From KKT conditions, we say that $\Delta x_{\mathcal{B}}$ is a solution if there exists a vector $\hat{\pi}$ such that
	\begin{align*}
	D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}}-A_{\mathcal{B}}^{T}\hat{\pi}&= 0\\
	A_{\mathcal{B}}\Delta x_{B}&= -A_{\mathcal{N}}\Delta x_{\mathcal{N}}
	\end{align*}
	The second equation is satisfied from (5.11). Combining the first and the third block rows in (5.11), we have for the indices $\mathcal{B}$:
	\begin{equation*}
	-D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}} + A_{\mathcal{B}}^{T}\Delta \lambda = s_{\mathcal{B}}
	\end{equation*}
	Since $(x, \lambda, s)$ is feasible, we have $s_{\mathcal{B}}= -A_{\mathcal{B}}^{T}\lambda+ c_{\mathcal{B}}$, whereas for any solution $(x^{*}, \lambda^{*}, s^{*})$, we have $c_{\mathcal{B}}= A_{\mathcal{B}^{T}\lambda^{*}}$. Then, we have
	\begin{equation*}
	-D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}} + A_{\mathcal{B}}^{T}\Delta \lambda = -A_{\mathcal{B}}^{T}\lambda+ c_{\mathcal{B}} = -A_{\mathcal{B}}^{T}(\lambda - \lambda^{*}) 
	\end{equation*}
	If we set $\hat{\pi} = \lambda + \Delta\lambda + \lambda^{*}$, then also the first KKT condition holds.\newline
	 \textit{2.} We recall again the KKT conditions and $(v,\pi)=(\Delta s_{N},\Delta\lambda)$ is a solution if there exist vectors $\hat{u}_{\mathcal{B}}$ and $\hat{u}_{\mathcal{N}}$ such that
	 \begin{align*}
	 D_{\mathcal{N}}^{2}\Delta s_{N}-\hat{u}_{N}&=0\\
	 -A_{\mathcal{B}}^{T}\hat{u}_{\mathcal{B}}-A_{\mathcal{N}}^{T}\hat{u}_{N}&=0\\
	 A_{\mathcal{B}}^{T}\Delta \lambda &= -\Delta s_{\mathcal{B}}\\
	 A_{\mathcal{N}}^{T}\Delta\lambda + \Delta s_{\mathcal{N}} &=0 
	 \end{align*}
	 The last two equations follow immediately from the first block row of (5.11).\\
	 Then, it is easy to show that the choices $\hat{u}_{N}= x_{\mathcal{N}}+\Delta x_{\mathcal{N}}$ and $\hat{u}_{\mathcal{B}}=x_{\mathcal{B}}+\Delta x_{\mathcal{B}}-x_{\mathcal{B}}^{*}$, satisfy the first and the second equations, where $x^{*}$ is the primal solution.\\
	 Now we prove the uniqueness of the $\Delta s_{\mathcal{B}}$.\\
	 If we multiply (5.12) by $A_{\mathcal{B}}$ and (5.13) by $A_{\mathcal{N}}$ and add, we obtain
	 \begin{equation*}
	 (A_{\mathcal{B}}A_{\mathcal{B}}^{T}+A_{\mathcal{N}}A_{\mathcal{N}}^{T})\pi+A_{\mathcal{N}}v = AA^{T}\pi+A_{\mathcal{N}}v = -A_{\mathcal{B}}\Delta s_{\mathcal{B}}
	 \end{equation*} 
	 Since A has full rank for hypothesis, we can write
	 \begin{equation*}
	 \pi = -(AA^{T})^{-1}(A_{\mathcal{N}}v +A_{\mathcal{B}}\Delta s_{\mathcal{B}})
	 \end{equation*}
	 so the minimization problem can be formulated as
	 	\begin{equation}\label{(V)}
	 \min\limits_{v}\frac{1}{2}\lVert D_{\mathcal{N}}v\rVert^{2} \text{ subject to }
	 (I-A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{N}})v =A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\Delta s_{\mathcal{B}}.		 
	 \end{equation}
	 Since this problem  has strictly convex objective, unqueness of its solution $v=\Delta s_{\mathcal{N}}$ is guaranteed. To conclude, we can recover $\Delta \lambda=\pi$ as defined above. 
\end{proof}
\begin{thm}\label{(Z)}
	Given $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$ and $(\Delta x,\Delta \lambda, \Delta s)$ computed in ~\ref{(Q)}, there is a constant K such that
	\begin{equation*}
	\lVert (\Delta x, \Delta s)\rVert \leq K \mu.
	\end{equation*}
\end{thm}
\begin{proof}
	Since the diagonal of $D_{\mathcal{B}}$ is strictly positive, we can apply the lemma~\ref{(T)} directly to the convex quadratic problem~\ref{(U)}. Hence, there is a constant $\bar{C}$ depending on $A_{\mathcal{B}}$ such that
	\begin{equation}
	\lVert \Delta x_{\mathcal{B}}\rVert \leq \bar{C}\lVert A_{\mathcal{N}}\Delta x_{\mathcal{N}}\rVert\leq \bar{C}\lVert A_{\mathcal{N}}\rVert C\mu,
	\end{equation}
	Similarly, from~\ref{(V)}, there is a constant $\bar{K}$ depending on $A$ such that
		\begin{equation}
	\lVert \Delta s_{\mathcal{N}}\rVert \leq \bar{K}\lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert\lVert \Delta s_{\mathcal{B}}\rVert \leq\bar{K} \lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert C\mu,
	\end{equation}
	The result follows when we define K$\;=\bar{K} \lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert C$.
\end{proof}
This result applies specifically to the algorithm \textbf{Primal dual affine scaling  algorithm} defined in chapter 4, but a result similar to the Theorem~\ref{(Z)} holds for steps of an infeasible interior-point algorithm \cite{Wright}.\\ The implementation realized in this research computes the starting point, which is infeasible, with an heuristic technique \cite{MER}: hence we estimate $(\Delta x, \Delta s)$ in the infeasible case.
\begin{table}[]
\begin{center}
	\begin{tabular}{|l|l|}
		\hline
		{Example} & {\color[HTML]{333333} Convergence rate: K} \\ \hline
		0 & 2.006 \\
		1 & 5.537 \\
		2 & 0.736 \\
		3 & 3.152 \\
		5 & 4.025 \\
		6 & 7.115 \\
		7 & 3.358 \\
		8 & 7.208 \\
		9 & 3.246 \\
		10 & 1805.964 \\
		11 & 5.712 \\
		12 & 9.208 \\
		13 & 14.010 \\
		14 & 1.532 \\
		16 & 3.146 \\
		17 & 6.714 \\
		19 & 36.431 \\
		21 & 24.663 \\
		22 & 1237.766 \\
		23 & 4.223  \\ \hline
	\end{tabular}
\end{center}
\end{table}

\section{LPF method convergence}

\begin{lem}\label{lem1}
	Let u and v be any two vectors in $\mathbb{R}^{n}$ with $u^{T}v \geq 0$. Then, 
\begin{align*}
\lVert UVe \rVert_{2}\leq 2^{-3/2}\lVert u + v \rVert^{2}_{2},\\
\end{align*}
with $U = diag(u_{1}, u_{2}, ..., u_{n})$ and $V = diag(v_{1}, v_{2}, ..., v_{n})$. 
\end{lem}
\begin{proof}
	We can formulate $0 \leq u^{T}v = \sum\limits_{u_{i}v_{i} \geq 0}u_{i}v_{i} + \sum\limits_{u_{i}v_{i} \leq 0}u_{i}v_{i} = \sum\limits_{i \in \mathcal{P}}|u_{i}v_{i}| - \sum\limits_{i \in \mathcal{M}}|u_{i}v_{i}| $, with $\mathcal{P}= \{i | u_{i}v_{i} \geq 0\}$ and $\mathcal{M}= \{i | u_{i}v_{i} \leq 0\}$.

\begin{align*}
\lVert UVe \rVert_{2} &= ( \lVert[u_{i}v_{i}]_{i \in \mathcal{P}} \rVert^{2} +  \lVert[u_{i}v_{i}]_{i \in \mathcal{M}} \rVert^{2})^{1/2}\\
&\leq ( \lVert[u_{i}v_{i}]_{i \in \mathcal{P}} \rVert^{2}_{1} +  \lVert[u_{i}v_{i}]_{i \in \mathcal{M}} \rVert^{2}_{1})^{1/2},\; \text{since\;} \lVert\dot\rVert_{2} \leq \lVert\dot\rVert_{1}\\
&\leq\sqrt{2}\;\bigg\lVert\bigg[\frac{1}{4}(u_{i} + v_{i})^{2}\bigg]_{i\in \mathcal{P}}\bigg\rVert_{1}, \text{\;since\;} \sqrt{ab} \leq \frac{1}{2}|a+b|\\
& = 2^{-3/2} \sum\limits_{i \in \mathcal{P}}(u_{i} + v_{i})^{2}\\
& \leq 2^{-3/2} \sum\limits_{i = 0}^{n}(u_{i} + v_{i})^{2}\\
& \leq 2^{-3/2} \lVert u + v \rVert^{2}_{2}.
\end{align*}
\end{proof}	
This lemma is an important tool to proof the next statement.
\begin{lem}
	If $(x, \lambda, s) \in \mathcal{N}_{-\infty}(\gamma)$, then
	\begin{align*}
	\lVert\Delta X\Delta S e \rVert \leq 2^{-3/2}(1 + 1/ \gamma)n\mu.\\
	\end{align*}
\end{lem}
\begin{proof}
	$(x + \Delta x)^{T}(s +\Delta s) = SX + x \Delta s + s \Delta x + \Delta x \Delta s$ and $S \Delta x + X \Delta s + XS = 0$, by the last row of \ref{(5.1)}. These two equations show that $\Delta x\Delta s = 0$.\\
	Now, by multiplying the last block row by $(XS)^{-1/2}$ and recalling the definition of $D = X^{1/2}S^{-1/2}$, we obtain 
	\begin{equation}
	D^{-1}\Delta x + D \Delta s = (XS)^{-1/2}(-XSe + \sigma \mu e)
	\end{equation}
	Since $(D^{-1}\Delta x)^{T}(D \Delta s) = \Delta x^{T} \Delta{s} = 0$, applying the Lemma \ref{lem1} with $u= D^{-1}\Delta x$ and $v = D \Delta s$, we obtain
	\begin{align*}
		\lVert \Delta X \Delta S e\rVert &= \lVert(D^{-1}\Delta X)(D\Delta S)e \rVert \\
		&\leq 2^{-3/2}\lVert D^{-1}\Delta x + D \Delta s\rVert^{2}, \text{\;from the Lemma}\\
		&= 2^{-3/2}\lVert (XS)^{-1/2}(-XSe + \sigma \mu e)\rVert ^{2} \text{\; from (5.8)}\\
	\end{align*}
	Expanding the squared Euclidean norm and using such relationships as $x^{T}s = n\mu$ and $e^{T}e = n$, we obtain
	\begin{align*}
	\lVert \Delta X \Delta S e\rVert_{2} &\leq 2^{-3/2}\bigg[x^{T}s - 2\sigma \mu e^{T}e + \sigma^{2}\mu^{2}\sum\limits_{i = 1}^{n}\frac{1}{x_{i}s_{i}}\bigg]\\
	 &\leq s^{-3/2}\bigg[x^{T}s - 2\sigma \mu e^{T}e + \sigma^{2}\mu^{2}\frac{n}{\gamma \mu}\bigg], \text{\; since\;} s_{i}x_{i} \geq \gamma \mu\\
	  &\leq 2^{-3/2}\bigg[1 - 2\sigma + \frac{\sigma^{2}}{\mu}\bigg]n \mu\\
	  &\leq 2^{-3/2}(1 + 1/\gamma)n \mu.
	\end{align*}
\end{proof}

\begin{thm}
	Given the parameters $\gamma$, $\sigma_{min}$ and $\sigma_{max}$ in the long-step path following algorithm, there is a constant $\delta$ indipendent of n such that
	\begin{equation}\label{(5.10)}
	\mu_{k+1} \leq \bigg(1 - \frac{\delta}{n}\bigg)\mu_{k}\\
	\end{equation} 
\end{thm}
\begin{proof}
	First of all we prove that $(x_{k}, \lambda_{k}, s_{k})+\alpha(\Delta x_{k},\Delta \lambda_{k},\Delta s_{k})\in\mathcal{N}_{-\infty}(\gamma)$ for all \\$\sigma \in \bigg[0,2^{3/2}\gamma \frac{1 - \gamma}{1 +\ \gamma}\frac{\sigma_{k}}{n}\bigg]$.\\
	
	From the last $n$ equalities of \ref{(5.9)}, we have that 
	\begin{align}(x_{i}^{k}, \lambda_{i}^{k}, s_{i}^{k})+\alpha(\Delta x_{i}^{k},\Delta \lambda_{i}^{k},\Delta s_{i}^{k}) &=\\ 
	x_{i}^{k}s_{i}^{k} + \alpha(x_{i}^{k} \Delta s_{i}^{k} + s_{i}^{k} \Delta x_{i}^{k})+\alpha^{2}\Delta x_{i}^{k} \Delta s_{i}^{k} &=\\
	x_{i}^{k}s_{i}^{k}(1 - \alpha) + \alpha \sigma_{k}\mu_{k}-\alpha^{2}|\Delta x_{i}^{k} \Delta s_{i}^{k}| &\geq\label{(5.11)}\\
	\gamma(1 - \alpha)\mu_{k} + \alpha \sigma_{k}\mu_{k}-\alpha^{2}2^{-3/2}(1 + 1/\gamma)n\mu_{k} &\label{(5.12)}.
	\end{align}
	In the equation \ref{(5.11)} is added $\alpha x_{i}^{k}s_{i}$ in order to use the last equations of the matrix system 
	In the step \ref{(5.12)} it is used the inequality proved above $|\Delta x_{i}^{k}\Delta s_{i}^{k}|\leq2^{-3/2}(1 + 1/\gamma)n\mu_{k}$, for any $i = 1,2,...,n$. \\
	By summing the $n$ components of the equation $S^{k}\Delta x^{k} + X^{k} \Delta s^{k} = -X^{k}S^{k}e + \sigma_{k} \mu_{k}e$ and using the null product $\Delta x \Delta s$, we have
	\begin{align*}\mu_{k}(\alpha)\vcentcolon=(x_{i}^{k} + \alpha\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha\Delta s_{i}^{k})/n&=\\ 
	x_{i}^{k}s_{i}^{k}/n - \alpha \mu_{k}+\alpha \sigma_{k} \mu_{k} &=\\
	(1-\alpha(1-\sigma_{k}))\mu_{k}
	\end{align*}
	From these last two formulas, we can see that proximity condition:\\$(x_{i}^{k} + \alpha\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha\Delta s_{i}^{k}) \geq \gamma\mu_{k}(\alpha)$ is satisfied if \begin{equation*}
		\gamma(1-\alpha)\mu_{k} + \alpha\sigma_{k}\mu_{k} - \alpha^{2}2^{-3/2}(1 + 1/\gamma)n\mu_{k}\geq \gamma(1 - \alpha +\alpha\sigma_{k})\mu_{k}
		\end{equation*}
		Rearranging the expression in further two steps, we assert the upper bound of the interval of the parameter $\alpha$:
		\begin{align*}
		\alpha\sigma_{k}\mu_{k}(1-\gamma)\geq\alpha^{2}2^{-3/2}(1+1/\gamma)\\
		\alpha \leq \frac{2^{3/2}}{n} \sigma_{k}\gamma\frac{1-\gamma}{1+\gamma}.\\		
		\end{align*}
Now, we complete the prof of the theorem by estimating the reduction in $\mu$ on the $k$th step. Using the inequality above:
\begin{align*}
\mu_{k+1}& = (x_{i}^{k} + \alpha_{k}\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha_{k}\Delta s_{i}^{k})/n\\
		 & = [(x^{k})^{T}s^{k} + \alpha_{k}\big((x^{k})^{T}\Delta s^{k} + (s^{k})^{T}\Delta x^{k}\big) +\alpha^{2}_{k}(\Delta x^{k})^{T}\Delta s^{k}]/n\\
		 & = (1 - \alpha_{k}(1-\sigma_{k}))\mu_{k}\\
		 & \leq \Big(1 - \frac{2^{3/2}}{n}\gamma\frac{1-\gamma}{1+\gamma}\sigma_{k}(1-\sigma_{k})\Big)\mu_{k}.\\
\end{align*}
Since the function $\sigma(1 - \sigma)$ is a concave quadratic function of $\sigma$, we have:
\begin{equation*}
\sigma_{k}(1-\sigma_{k})\geq \text{min}\{\sigma_{\text{min}}(1-\sigma_{\text{min}}),\sigma_{\text{max}}(1-\sigma_{\text{max}})\}, \text{\;for all\;}\sigma_{k}\in[\sigma_{\text{min}},\sigma_{\text{max}}].
\end{equation*}
We can use this estimate in the last inequality and setting
\begin{equation*}
\delta \vcentcolon=2^{3/2}\gamma\frac{1-\gamma}{1+\gamma}\text{min}\{\sigma_{min}(1-\sigma_{min}),\sigma_{max}(1-\sigma_{max})\}, \text{\;for all\;}\sigma_{k}\in[\sigma_{min},\sigma_{max}].
\end{equation*}
\end{proof}
We complete the analysis theory with the following theorem which shows that a reduction of a factor of $\epsilon$ in the duality measure $\mu$ can be obtained in $\mathcal{O}(n\log{1/\epsilon})$ iterations.
\begin{thm}
	Given $\epsilon\in(0,1)$ and $\gamma\in(0,1)$, suppose the starting point in the algorithm satisfies $(x^{o},\lambda^{o},s^{o})\in\mathcal{N}(\gamma)$. Then there is an index $\mathcal{K}$ with $\mathcal{K}=\mathcal{O}(n\log1/\epsilon)$ such hat $\mu_{k}\leq\epsilon\mu_{o}$.
\end{thm}
\begin{proof}
	By taking the logarithms of both sides in \ref{(5.10)},we obtain
	\begin{equation*}
	\log\mu_{k+1}\leq \log \bigg(1-\frac{\delta}{n}\bigg)+\log\mu_{k}\end{equation*}
	By applying this formula repeatedly
	\begin{equation*}
	\log\mu_{k+1}\leq \log \bigg(1-\frac{\delta}{n}\bigg)+\log\mu_{o}
	\end{equation*}
	\text{Using the log estimate} $\log(1+\beta)\leq\beta$, with $\beta>-1$.\\
	\begin{equation*}
	\log(\mu_{k}/\mu_{o})\leq k\bigg(-\frac{\delta}{n}\bigg)
	\end{equation*}.	
For every $k$ that satisfy
\begin{equation*}
k\geq\mathcal{K}:= \frac{\delta}{n}\log\frac{1}{\epsilon} = \frac{\delta}{n}|\log(\epsilon)|
\end{equation*}
we have 
\begin{equation*}
k\bigg(-\frac{\delta}{n}\bigg)\leq\log\epsilon
\end{equation*}	
that guarantees
\begin{equation*}
\mu_{k}/\mu_{o}\leq\epsilon.
\end{equation*}	
\end{proof}

\section{Analysis of MPC}
In order to study the perform of the Mehrotra's algorithm, we introduce the trajectory-following methods from ODEs. These one define a trajectory from the current point, we say $(x,\lambda,s)$, to the solution set $\Omega$. There are infinitely many trajectories to choose from, but in this casse is obtained from a linear scaling of the function \ref{F}.\\ Denoting this trajectory by $\mathcal{H}$ and parametrizing it by $\tau\in[0,1)$, we find that each point $(x_{\tau},\lambda_{\tau},s_{\tau})\in\mathcal{H}$ is a solution of the following nonlinear system:
\begin{equation}\label{T}
	\begin{bmatrix}
	A^{T}\lambda+s-c \\Ax-b \\XSe
	\end{bmatrix}=\begin{bmatrix}
	(1-\tau)(A^{T}\lambda-c)\\(1-\tau)(Ax-b)\\(1-\tau)XSe
	\end{bmatrix}, (x,s)\geq0.
\end{equation}
We see that $(x_{\tau},\lambda_{\tau},s_{\tau})$ with $\tau = 0$ is exactly the initial point and that, if the limit exists, then $\lim\limits_{\tau\to\infty}(x_{\tau},\lambda_{\tau},s_{\tau}) = (x^{*},\lambda^{*},s^{*})$.\\
To move along the trajectory $\mathcal{H}$, we can form a Taylor series approximation to $(x_{\tau},\lambda_{\tau},s_{\tau})$ by expanding about the initial point  $(x,\lambda,s)$ as follows:
\begin{equation*}
(x_{\tau},\lambda_{\tau},s_{\tau})=(x_{0},\lambda_{0},s_{0})+\tau(x_{0}^{'},\lambda_{0}^{'},s_{0}^{'})+\frac{1}{2}\tau^{2}(x_{0}^{"},\lambda_{0}^{"},s_{0}^{"})+\dots = \sum_{j=0}^{\infty}\frac{\tau^{j}}{j!}(x_{0}^{j},\lambda_{0}^{j},s_{0}^{j})
\end{equation*}
Here, $(x_{0}^{j},\lambda_{0}^{j},s_{0}^{j})$ is the derivative of $(x_{\tau},\lambda_{\tau},s_{\tau})$ with respect to $\tau$, evaluated in $\tau = 0$. We can find these derivatives by implicity differenziating the equation \ref{T}. Setting $\tau=0$ we have:
\begin{equation}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
x_{0}^{'}\\\lambda_{0}^{'}\\s_{0}^{'}
\end{bmatrix}=-\begin{bmatrix}
A^{T}\lambda-c\\Ax-b\\XSe
\end{bmatrix},
\end{equation}
which is exactly the same system as affine-scaling step equation.\\
Hence, we can make the identification $(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})=(x^{'}_{0},\lambda^{'}_{0},s^{'}_{0})$. Differentiating again with respect to $\tau$, we obtain the second derivative solving
\begin{equation}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
x_{0}^{''}\\\lambda_{0}^{''}\\s_{0}^{''}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\2X^{'}_{0}S^{'}_{0}e
\end{bmatrix}
\end{equation}
and we see that $(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})=\frac{1}{2}(x^{''}_{0},\lambda^{''}_{0},s^{''}_{0})$. Now we truncate the Taylor series at two terms and use the last two results, in order to gìhave the following approximation:
\begin{equation}
(x_{\tau},\lambda_{\tau}, s_{\tau})\approx(x, \lambda, s)+ \tau(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+\tau^{2}(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})
\end{equation}
If we ignore the centering term  by setting $\sigma =0$ and, hence, constrain the primal and dual step lengths to be identical, then the algorithm searches the successive point along the line
\begin{equation}
(x_{\tau},\lambda_{\tau}, s_{\tau})\approx(x, \lambda, s)+ \tau(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+\tau(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})
\end{equation} 
that is, the $\tau^{2}$ coefficient in the òast term is replaced by $\tau$. Instead when we account for the centering parameter, the correspondence between the derivatives of the trajectory and the MPC search direction no longer holds. \\
Then we introduce the modified trajectory $\mathcal{H}_{\sigma}$ for which the correspondence continues to hold even in the presence of $\sigma$. Also $\mathcal{H}_{\sigma}$ starts at $(x, \lambda, s)$ and aims at the solution set $\Omega$. All $(x_{\tau},\lambda_{\tau},s_{\tau})$ in this trajectory satisfy:
\begin{equation}\label{T}
\begin{bmatrix}
A^{T}\lambda+s-c \\Ax-b \\XSe
\end{bmatrix}=\begin{bmatrix}
(1-\tau)(A^{T}\lambda-c)\\(1-\tau)(Ax-b)\\(1-\tau)XSe+\tau^{2}(1-\tau)\sigma\mu e
\end{bmatrix},(x,s)\geq0.
\end{equation}
The tangent to this trajectory is the affine-scaling direction, as for $\mathcal{H}$, but the curvature can be identified with the combined centering-corrector step rather than the corrector component alone. The trajectory $\mathcal{H}_{\sigma}$ tends to bulge more toward the central path than $\mathcal{H}$. Despite the closer relationship between $\mathcal{H}_{\sigma}$  and MPC algorithm, we can not qualify it as a second-order trajectory-following algorithm because it still searches along a linear direction rather than a quadratic path.  
\section{Asymptotic convergence}
The algorithms studied generate a sequence of improving primal-dual points $(x^{k},\lambda^{k}, s^{k})$ to the exact solution and in this section we describe the convergence rate of each of them. \\
The codes implemented in this research solve linear programming problems with a starting infeasible point, as we will delineate in the chapter 7. Then, we can determine the order of convergence checking the convergence to the feasible set $\mathcal{F}$, hence to the exact solution.\\
We define the residual function $r$ that converts the vector sequence into a real number sequence.
\chapter{Implementation issues}
There are several important issues concerning interior-point algorithms
for linear programs.\\
\section*{Initialization and termination}
In the discussion of the interior point methods, it is assumed the starting point $(x^{0}, \lambda^{0}, s^{0})$ is feasible respect to the linear equations \ref{DF} and \ref{PF}, instead in the predictor-corrector alforithms it is required only $(x^{0},s^{0})>0$.\\
IPMs are sensitive to the choice of an initial primal-dual point. In fact, the choice of "poor" starting points may drastically reduce the steps toward the solutiona, giving significant effect on the robustness of the algorithm. Therefore, the choice of good initial values is an important issue in the implementation of the methods. A common way to deal with this issue is to use heuristic-based strategies that try to keep the infeasibility small while ensuring that nonnegative variables are far enough from zero.\\
Since most of IPM explicity or implicity attempt to follow the central path $\mathcal{C}$, a very simple choice for the starting point would be to set the nonnegative variables to one and the others to zero. This choice guarantees that the point is perfectly centered, i.e. all pairwise complementarity products are equal to $\mu$ and the nonnegative variables are sufficiently bounded away from zero. However, this point be far from satisfying the constraints \cite{VAN}.\\
Another strategy aimed to satisfy the requirement that the starting point is both well centerd and not to infeasible is presented \cite{MER} by Mehrotra; we will briefly call it as Mehrotra's initial point method (MIP). This popular heuristic approach for finding $(x^{0}, \lambda^{0}, s^{0})$ consists on computing least squares solutions to the equations corresponding to the linear constraints of the LP and then shifting the values of the variables to ensure that they are kept away from the boundary of the orthant. \\
The construction starts by calculating $(\tilde{x}, \tilde{\lambda}, \tilde{s})$ as solution of two least-squares problems:
\begin{align*}
\min\limits_{x} \lVert x \rVert ^{2} &\text{ subject to }Ax = b,\\
\min\limits_{(\lambda,s)} \lVert s \rVert ^{2} &\text{ subject to } A^{T}\lambda +s = c.
\end{align*}
That is, $\tilde{x}$ and $\tilde{s}$ are the vectors of least norm that are in the feasible set and they are computed using the following formulas:
\begin{equation}\label{71}
\tilde{x} = A^{T}(AA^{T})^{-1}b,\;\;\;\tilde{\lambda}=(AA^{T})^{-1}Ac,\;\;\; \tilde{s} = c- A^{T}\tilde{\lambda}.
\end{equation}
In general, $\tilde{x}$ and $\tilde{s}$ are not positive, so we we define
\begin{equation*}
\delta_{x} = \max(-(3/2)\min\limits_{i}\tilde{x}_{i},0),\;\;\; \delta_{s} = \max(-(3/2)\min\limits_{i}\tilde{s}_{i},0),
\end{equation*}
and compute the positive vectors $\hat{x}= \tilde{x}+\delta_{x}e$ and $\hat{s}= \tilde{s}+\delta_{s}e$ where e is the unit vector. To ensure that the initial points $x^{0}$ and $s^{0}$ are not too close to zero, we add two more scalars defined as follow:
\begin{align}\label{72}
2\tilde{\delta}_{x}= \frac{\hat{x}^{T}\hat{s}}{e^{T}\hat{s}},\;\;\;2\tilde{\delta}_{s} = \frac{\hat{x}^{T}\hat{s}}{e^{T}\hat{x}}.
\end{align}
The starting point is then defined as 
\begin{align*}
(x^{0}, \lambda^{0}, s^{0}) = (\tilde{x}+\tilde{\delta}_{x} e,\;\tilde{\lambda},\;\tilde{s}+\tilde{\delta}_{s} e).
\end{align*}
\\
The logical basis of this strategy (outlined in \ref{fig:STP2}) is that many path-following methods are able to perform long steps toward the solution and to drive the infeasibility to zero at least at the same rate as the duality gap, by keeping the iterates in the central path neighbourhood \begin{equation*}
\mathcal{N}(\gamma,\beta) =\Bigg\{(x, \lambda, s) | \frac{\lVert(r_{b}, r_{c})\rVert_{2}}{\mu} \leq \beta\frac{\lVert(r_{b}^{0}, r_{c}^{0})\rVert_{2}}{\mu^{0}},\; (x, s)>0,\; x_{i}s_{i} \geq \gamma\mu,\;i = 1,\dots, n \Bigg\}
\end{equation*}
where $\gamma\in(0,1)$ and $\beta \geq 1$ are given parameters and $(r_{b}^{0}, r_{c}^{0})$ and $\mu_{0}$ are evaluated at the starting point; notice that we must have $\beta \geq 1$ to ensure that the initial point $(x^{0}, \lambda^{0}, s^{0})\in\mathcal{N}(\gamma,\beta)$. \cite{SPS}
\\
\begin{figure}[t]
	\begin{center}
		\noindent\begin{boxedminipage}{1\linewidth}
			\begin{tabbing}
				compute $(\tilde{x},\tilde{\lambda},\tilde{s})$ as in \ref{71}\\
				\>\\
				$\bar{x} = \min\{x_{i}\}$\\
				$\bar{s} = \min\{s_{i}\}$\\
				\textbf{if} \= $\bar{x}<0$ then\\
				\> $\hat{x}= \tilde{x} -(3/2)\bar{x}e$\\
				\textbf{else} \=\\
				\> $\hat{x} = \tilde{x}$\\
				\textbf{if} \= $\bar{s}<0$ then\\
				\> $\hat{s}= \tilde{s} -(3/2)\bar{s}e$\\
				\textbf{else} \=\\
				\> $\hat{s} = \tilde{s}$\\
				compute \=\ref{72} with $\hat{x}$ and $\hat{s}$\\
				\>$(x^{0}, \lambda^{0}, s^{0}) = (\tilde{x}+\tilde{\delta}_{x} e,\;\tilde{\lambda},\;\tilde{s}+\tilde{\delta}_{s} e)$\\
				\textbf{end}
			\end{tabbing}
		\end{boxedminipage}\caption{\label{fig:STP2} starting-point Mehrotra's strategy}	
	\end{center}
\end{figure}
The second starting-point strategy is suggested by the convergence theory of the Potential Reduction (PR) method.\\
The starting point can be chosen as \begin{equation*}
(x^{0}, \lambda^{0}, s^{0}) = \eta \tilde{w}
\end{equation*}where $\tilde{w} = (e,0,e)$ and $\eta$ such that 
\begin{equation}\label{su}
\frac{\lVert(r^{0}_{b},r^{0}_{c})\rVert_{2}}{\mu^{0}}\leq \tau<1. 
\end{equation}
It easy to verify that, since $\mu^{0}$ increases quadratically with $\eta$ and $\lVert(r^{0}_{b},r^{0}_{c})\rVert_{2}$ incrreases linearly, inequality \ref{su} approximately holds if $\eta$ satisfies
\begin{equation*}
\eta\geq \frac{\lVert(\tilde{r}_{b},\tilde{r}_{c})\rVert_{2}}{\tau\tilde{\mu}},
\end{equation*}
where $\lVert\tilde{r}_{b},\tilde{r}_{c})\rVert_{2}$ and $\tilde{\mu}$ are respectively the infeasibility and the duality measure associated with $\tilde{w}$ (in this case $\tilde{\mu} = n$). \\
We note that $(x^{0},\lambda^{0},s^{0})$ is perfectly centered and all its components with lower bound 0 are "sufficient" positive, but even if the ratio in \ref{su} is small, the duality gap and the infeasibility may very large, slowing the progress toward the solution.\\
This method strategy, labeled with STP1 (\cite{SPS}), is summarized in the Figure \ref{fig:STP1}.\\
\begin{figure}[t]
	\begin{center}
\noindent\begin{boxedminipage}{1\linewidth}
\begin{tabbing}
	choose $\tau < 1$ \\
	$\tilde{w}=(e,0,e)$\\
	$\tilde{\sigma}= \lVert\tilde{r}_{b},\tilde{r}_{c})\rVert_{2}$\\
	$\tilde{\mu}= n$\\
	\textbf{If} \= $\tilde{\sigma}/n\leq \tau$ then\\
	\> $(x^{0}, \lambda^{0}, s^{0}) = \tilde{w}$\\
	\textbf{else}\>\\
	\> $\tilde{\mu}=\tilde{\sigma}/(\tau n)$ \\
	\> $(x^{0}, \lambda^{0}, s^{0}) = \eta \tilde{w}$\\
	\textbf{end}
\end{tabbing}
\end{boxedminipage}\caption{\label{fig:STP1} starting-point strategy STP1}	
\end{center}
\end{figure}
Now we analyze the infeability measures and the duality gaps corresponding to the starting points computed with MIP and STP1.\\
\begin{table}[h]
	\begin{tabular}{llllllllll}
		\hline
		\textbf{Size} &  &  & \textbf{MIP}&&  &  & \multicolumn{3}{l}{\textbf{      STP1}} \\ \cline{1-2} \cline{4-6} \cline{8-10} 
		n & m &  & infeasibility & duality gap & ratio &  & infeasibility & duality gap & ratio \\ \hline
		1 & 2 &  & 2.07e+01 & -1.98e-01 & -104.65 &  & 2.73e+01 & -1.12e+00 & -2.43e+01 \\
%		2 & 2 &  & 8.05e+00 & 6.25e-01 & 12.87 &  & 9.17e+00 & 9.71e-01 & 9.45e+00 \\
		4 & 2 &  & 5.39e+03 & 2.32e+03 & 2.32 &  & 1.65e+04 & 8.90e+03 & 1.85e+00 \\
%		2 & 2 &  & 5.19e+01 & 1.62e+01 & 3.21 &  & 9.20e+01 & 4.33e+01 & 2.12e+00 \\
%		2 & 2 &  & 6.04e+01 & 4.41e+00 & 13.70 &  & 1.20e+01 & 9.62e-01 & 1.25e+01 \\
		3 & 3 &  & 4.30e+01 & 6.72e+00 & 6.40 &  & 1.93e+02 & 3.05e+01 & 6.32e+00 \\
		2 & 5 &  & 4.73e+01 & 1.46e+00 & 32.31 &  & 9.88e+00 & 1.64e+00 & 6.02e+00 \\
		2 & 5 &  & 3.60e+01 & -3.93e+01 & -0.92 &  & 1.34e+02 & -1.53e+02 & -8.73e-01 \\
		3 & 2 &  & 5.66e+00 & 4.41e-01 & 12.82 &  & 3.61e+00 & 4.00e-01 & 9.01e+00 \\
		2 & 4 &  & 1.11e+02 & -2.14e+01 & -5.20 &  & 1.16e+02 & -4.26e+01 & -2.73e+00 \\
%		3 & 4 &  & 3.11e+01 & -5.69e+00 & -5.46 &  & 1.28e+04 & -2.86e+03 & -4.46e+00 \\
		3 & 2 &  & 1.09e+01 & 1.05e+00 & 10.36 &  & 1.02e+02 & 1.02e+01 & 9.97e+00 \\
		3 & 3 &  & 1.86e+01 & 2.52e+00 & 7.38 &  & 2.90e+01 & 5.44e+00 & 5.33e+00 \\
		3 & 2 &  & 5.09e+01 & 1.07e+01 & 4.74 &  & 1.10e+01 & 3.33e+00 & 3.30e+00 \\
		2 & 3 &  & 3.25e+01 & -2.11e+00 & -15.37 &  & 9.92e+00 & -1.95e+00 & -5.09e+00 \\
%		3 & 3 &  & 2.74e+01 & -2.78e+00 & -9.83 &  & 5.82e+00 & -1.58e+00 & -3.69e+00 \\
		3 & 3 &  & 5.90e+01 & 6.51e+00 & 9.07 &  & 3.21e+01 & 4.16e+00 & 7.72e+00 \\
		3 & 2 &  & 1.44e+01 & 3.38e+00 & 4.25 &  & 3.55e+01 & 1.18e+01 & 3.01e+00 \\
		10 & 6 &  & 9.23e+03 & 1.08e+04 & 0.86 &  & 6.43e+04 & 9.45e+04 & 6.80e-01 \\
		2 & 2 &  & 3.33e+01 & 5.88e-01 & 56.57 &  & 3.97e+01 & 8.77e-01 & 4.53e+01 \\
%		2 & 2 &  & 3.49e+01 & 2.42e+01 & 1.44 &  & 3.13e+01 & 3.22e+01 & 9.71e-01 \\
		20 & 10 &  & 7.46e+04 & 1.65e+04 & 4.51 &  & 8.09e+05 & 1.80e+05 & 4.50e+00 \\
		55 & 50 &  & 1.15e+04 & 2.07e+02 & 55.81 &  & 6.71e+05 & 6.24e+04 & 1.08e+01 \\
		4 & 8 &  & 6.14e+01 & -2.72e+00 & -22.57 &  & 1.50e+01 & -5.48e+00 & -2.74e+00 \\
		6 & 5 &  & 1.81e+01 & -5.88e-01 & -30.79 &  & 4.06e+00 & -2.73e-01 & -1.49e+01 \\
		13 & 6 &  & 1.18e+04 & 1.41e+05 & 0.08 &  & 5.20e+03 & 1.05e+05 & 4.94e-02 \\
		7 & 7 &  & 5.86e+01 & -2.77e+00 & -21.17 &  & 1.05e+01 & -5.00e-01 & -2.11e+01 \\
		8 & 2 &  & 8.30e+01 & -5.62e+00 & -14.76 &  & 5.37e+01 & -5.07e+00 & -1.06e+01 \\
		2 & 4 &  & 2.64e+01 & -6.25e+00 & -4.22 &  & 2.58e+01 & -1.21e+01 & -2.13e+00 \\
		10 & 24 &  & 1.49e+05 & -1.70e+04 & -8.78 &  & 2.77e+09 & -3.15e+08 & -8.77e+00 \\ \hline
	\end{tabular}\caption{Infeasibility measures $\lVert (r_{b}, r_{c})\rVert_{2}$, duality gaps ${\mu}$ and their ratios corresponding to MIP and STP1}
\end{table}
We see that it is not a evidence peculiar behaviour of the values of the infeasibility error and the duality gap obtained by each strategy. Even if the ratio is smaller for the STP1 initial points, the duality gap and the infeasibility error are competitive and they don't lead to an effective comparison.\\ 
\newpage
Now we deal on the termination criteria; unlike the simplex method, primal-dual algorithms never find an exact solution of the LP. In this research it is computed a finite termination phase that reports an approximate solution for which the residuals and duality measure are sufficiently small. After determinated a small tollerance $\epsilon$, the algorithms terminate when the following conditions on the relative primal and dual feasibility and the relative duality gap are satisfied:
\begin{align*}
\frac{\lVert Ax -b\rVert}{1+ \lVert b \rVert}\leq \epsilon, && \frac{\lVert A^{T}y -c\rVert}{1 + \lVert c \rVert}\leq \epsilon, &&\frac{|c^{T}x - b^{T}y|}{1+b^{T}y}\leq \epsilon,
\end{align*}
where $\epsilon > 0$, usually of the order $10^{-8}$, as required both in the literature and in practice, \cite{Wright}.
\section*{Geometric viewpoint}
Now we outline the geometric viewpoint of the simplex method and the primal-dual methods.\\
We already stated that the simplex method generates a sequence of basic feasible primal points of the solution set; hence, it creates a path along the boundary of the polytope, checking the cost value at each vertex.\\Instead, the primal-dual interior point methods approach the solution through the interior of the feasible polytope, generating the central path $\mathcal{C}$, rather than working around the boundary.\\ Path-following method follow $\mathcal{C}$ in the direction of decreasing $\tau$ in (4.7) ; ideed, they do not necessarily stay exactly on the path but within a loose and well-defined neighoborhood of $\mathcal{C}$ while steadily reducing the duality measure $\mu$ to zero. Each search direction is computed with a Newton's step toward a point for which the duality measure $\tau$ is equal to or smaller than the current duality measure $\mu$, as we know $\tau=\sigma\mu$. 
The affine-scaling method, based on pure Newton's steps, sets the central parameter $\sigma_{k}= 0$ in the system;
%In fact, the gap between neighborhood boundaries is wide enough to allow this step to make significant progress in reducing $\mu$. 
even if it makes significant progress, it also tends to worsen the centrality measure (condition of having all pairwise products $x_{i}s_{i}$ equal). It follows that the step length $\alpha_{k}$ is the maximum value such that the next points remain in the feasible set. We will see that we often can take only a small
step along the search direction before violating the condition; hence, the affine scaling direction, often does not allow us to make much progress toward a solution.\\ 
The long-path following method doesn't create a sequence that moves strongly to the solution, indeed, computes the search direction with $\sigma_{k}$ between two fixed limits $\sigma_{\text{min}}$ and $\sigma_{\text{max}}$, in order to improve the centrality measure. The lower bound $\sigma_{\text{min}}$ ensures that each search direction start by moving off the boundary of $\mathcal{N}_{-\infty}(\gamma)$ and into the interior of the neighborhood. Unit steps along the search direction takes the next point outside the neighborhood, since the error of approximating the nonlinear KKT system by the linear equations becomes more pronounced as $\alpha$ increases. Then, it selects $\alpha_{k}$ as large a possible subject to the next point remains $\mathcal{N}_{-\infty}(\gamma)$. The restriction of $\sigma_{k}\in(0,1)$ achieves the twin goals of improving centrality and reducing the duality measure into a single step.\\
Alternatively, the predictor-corrector methods consists on two types of steps. The predictor step, which start in the inner neighborhood and moves along the affine-scaling direction to the boundary of the outer neighborhood. Between these predictor steps, the algorithm takes corrector steps, computing $\sigma = 1$ and $\alpha= 1$, in order to come back inside the inner neighborhood to prepare for the next predictor corrector step. The Mehrotra's algorithm chooses the centering parameter adaptively: first calculates the affine-scaling direction, then assesses its usefulness as a search direction. If this direction yields a large reduction in $\mu$ without violating the positivity condition $(x, s)> 0$, the algorithm concludes that littele centering in needed, so it chooses $\sigma_{k}$ close to zero and calculates a centered search direction with small value. Otherwise, it enforces a larger amount of centering by choosing $\sigma_{k}$ close to 1. As we see in the description of the Mehrotra's algortihm, the computation of the centered direction and the corrector step are combined, so adaptive centering does not add further to the cost of each iteration. 

\section*{The centering measure}
Now we examinate the behaviour of the sequence computed by the IPM algorithms respect to the path $\mathcal{C}$, at which all the pairwise products are $x_{i}s_{i}$ are identical to $\mu$. To value this deviation from $\mathcal{C}$, we compare the pairwise products with their average value $\mu = x^{T}s/n$ using a scaled norm defined by. 
\begin{equation}
\frac{1}{\mu}\lVert XSe - \mu e \rVert_{2}
\end{equation}
The problem data are ten little scale LP problems formulated in canonical form. The codes implemented are the algorithm in previously described: affine-scaling, long-path following and Mehrtotra's algorithms. It is also implemented a variation of the long-path following method, in which the centering paramenter is $\sigma_{k}=\sigma$ for all $k$, instead chosen in a random way.
\newpage
\section*{The coefficient matrix}
Most of the computational effort in implementations of primal-dual methods is taken up in solving linear systems of the form (\ref{P}). The
coefficient matrix in these systems is usually large and sparse, since the constraint
matrix $A$ is itself large and sparse in most applications. Let us to reformulate
this equation as systems with more compact symmetric coefficient matrices, which
are easier and cheaper to factor than the original form. Since the current point $(x, \lambda, s)$ has $x$ and $s$ strictly
positive, the diagonal matrices $X$ and $S$ are nonsingular. Hence, by eliminating $\Delta s$, we obtain the following equivalent system, called \textit{augmented system}:
\begin{align*}
\begin{bmatrix}
0&A\\A^{T}&-D^{2}
\end{bmatrix}\begin{bmatrix}
\Delta\lambda^{k} \\\Delta x^{k}
\end{bmatrix}=&-\begin{bmatrix}
Ax^{k}-b\\A^{T}y^{k}+s^{k}-c+ se + \sigma_{k}\mu_{k}(X^{k})^{-1}e
\end{bmatrix},\\
\Delta s =& -s^{k} +\sigma_{k}\mu_{k} (X^{k})^{-1}S\Delta x,
\end{align*}
where we have introduced the notation $D = S^{-1/2}X^{1/2}$.\\
Since the matrix $X^{-1}S$ is also diagonal and nonsingular, we can eliminate $\Delta x$ from the first row of the augmented system to obtain another equaivalent form:
\begin{align*}
AD^{2}A^{T}\Delta\lambda &= -r_{b}+A(-S^{-1}Xr_{c}+ x - \sigma\mu S^{-1}e),\\
\Delta s &= -r_{c}-A^{T}\Delta \lambda,\\
\Delta x &= -x + \sigma \mu S^{-1}e-S^{-1}X\Delta s.
\end{align*}
with $r_{b} = Ax - b$ and $r_{c}= A^{T}\lambda +s = c$.\\
\\
This form often is called the \textit{normal equations} form and a direct sparse Cholesky algorithm is applied to factor the matrix $AD^{2}A^{T}$. \\In the implementations both forms are performed: ill conditioning is often observed during the final
steps of the long-path following algorithm with the second system, when the elements of the diagonal weighting
matrix $D^{2}$ takes on both huge and tiny values.

\chapter{Numerical experiments}
In this chapter it is developed a comprehensive analysis of the results obtained by some practical implementations. It is presented three LP problems: the forest service allocation, Swedish steel model, ...\\
The fictitious data used to test the LP methods come from \cite{RR}.
\section{Forest service allocation} 
The first model we illustrate is the \textit{Forest service allocation}. It is part of model class in which the main issue is how to divide or allocate a valuable resource among competing needs and the resource may be for example land, capital, time or fuel. We will see how the Forest Service has used this model to address the sensitive task of managing 191 million acres of national forestland \cite{(Natural)}.\\
The Forest Service is one of the major Federal land managing agencies; it has been part of the Department of Agricolture since 1905 and over the past 10 years significant administrative and legal challenges have plagued national forest management \cite{ForSer}. Resource simulation models are the principal technologies used for estimating ecological and enviromental responses to activities. These models try to qualify relationships among resources and results of management actions. Simulations such as timber growth-and-yeld models and sediment yield models often examine consequences of management activities for a singele resource. The regional diversity of forest resources has led to many unique, local models rather than universal models. The Forest Service, in 1979, designed FORPLAN as its principal tool for national forest: it is al linear programming system, used to analyze the temporal aspects of the forest output. FORPLAN was chosen because it addressed two key issues in forest plnning: cost efficiency and an allowable timber sale quantity. Besides, these models have been used by each national forest structure with input that represent their problem. This is a strengh of LP. \\
The models of a forest begin  by dividing land into homogeneous analysis area, then several prescriptions or land management policies are then proposed and evaluated for each. \\The optimization seeks the best possible allocation of land in the analysis areas to particular prescriptions, subject to forest-wide restrictions on land use.
We model, hypotetically, 788 thousand acre Wagonho National Forest, that is assumed to have 7 analysis areas, each subject to 3 different prescriptions. The first prescription encourages timbering, the second grazing and the third preserves the land as wilderness. Then we indices the variables as well:
\begin{itemize}
	\item \textit{i} is the analysis area number and \textit{j} is the prescription number
	\item $s_{i}$ is the size of area $i$ in thousands of acres
	\item $p_{i,j}$ is the net present value (PNV) per acre of all uses in area $i$ if managed under prescription $j$
	\item $t_{i,j}$ is the projected timber yield (in board feet per acre) of analysis area $i$ if managed under prescription $j$
	\item $g_{i,j}$ is the projected grazing capability (in animal unit months per acre) of analysis area $i$ if managed under prescription $j$
	\item $w_{i,j}$ is the wilderness index rating, from 0 to 100, of analysis area $i$ if manages under prescription $j$
\end{itemize}
We want to find an allocation that minimizes net present value while producing 40 million board feet of timber, 5 thousand animal unit months of grazing, and keeping average wilderness index at least 70.\\
The formulation of the model in a LP problem can be written as following:
\begin{align*}
\max&\sum_{i=1}^{7}\sum_{j=1}^{3} p_{i,j}x_{i,j}&(\text{present value})\\
s.t& \sum_{i=1}^{3}x_{i,j}=s_{i}\;\;\;\;i = 1, \dots,7&(\text{allocation})\\
&\sum_{i=1}^{7}\sum_{j=1}^{3} t_{i,j}x_{i,j}\geq 40000&(\text{timber})\\
&\sum_{i=1}^{7}\sum_{j=1}^{3} g_{i,j}x_{i,j}\geq5&(\text{grazing})\\
&\frac{1}{788}\sum_{i=1}^{7}\sum_{j=1}^{3} w_{i,j}x_{i,j}\geq 70&(\text{wilderness})\\
&x_{i,j}\geq 0 \;\;\;\;i = 1,\dots,7;\;\;\;\;j = 1,\dots,3;
\end{align*}
Since the LP is not in standard form, we convert the inequalies to equalities adding slack valriables $y_{i,k}$ to the last three constraints, with $i, k = 1, \dots, 3$. The Forest Service Application data used to test the methods are shown in the following table:\\
\begin{table}[]
	\begin{center}
	\begin{tabular}{cccllll}
		\hline
		\begin{tabular}[c]{@{}c@{}}\textbf{Analysis}\\ \textbf{area}, $i$ \end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{Acres},\\ $s_{i}$\end{tabular} & \begin{tabular}[c]{@{}c@{}}\textbf{Prescription},\\ j\end{tabular} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{NPV}, $p_{i,j}$\\ (per acre)\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Timber}, $t_{i,j}$\\ (per acre)\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Grazing}, $g_{i,j}$\\ (per acre)\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}\textbf{Wilderness}\\ \textbf{Index}, $w_{i,j}$\end{tabular}} \\ \hline
		\multirow{3}{*}{1} & \multirow{3}{*}{75} & 1 & 503 & 310 & 0.01 & 40 \\
		&  & 2 & 140 & 50 & 0.04 & 80 \\
		&  & 3 & 203 & 0 & 0 & 95 \\ \hline
		\multirow{3}{*}{2} & \multirow{3}{*}{90} & 1 & 675 & 198 & 0.03 & 55 \\
		&  & 2 & 100 & 46 & 0.06 & 60 \\
		&  & 3 & 45 & 0 & 0 & 0 \\ \hline
		\multirow{3}{*}{3} & \multirow{3}{*}{140} & 1 & 630 & 210 & 0.04 & 45 \\
		&  & 2 & 105 & 57 & 0.07 & 55 \\
		&  & 3 & 40 & 0 & 0 & 60 \\ \hline
		\multirow{3}{*}{4} & \multirow{3}{*}{60} & 1 & 330 & 112 & 0.01 & 30 \\
		&  & 2 & 40 & 30 & 0.02 & 35 \\
		&  & 3 & 295 & 0 & 0 & 90 \\ \hline
		\multirow{3}{*}{5} & \multirow{3}{*}{212} & 1 & 105 & 40 & 0.05 & 60 \\
		&  & 2 & 460 & 32 & 0.08 & 60 \\
		&  & 3 & 120 & 0 & 0 & 70 \\ \hline
		\multirow{3}{*}{6} & \multirow{3}{*}{98} & 1 & 490 & 105 & 0.02 & 35 \\
		&  & 2 & 55 & 25 & 0.03 & 50 \\
		&  & 3 & 180 & 0 & 0 & 75 \\ \hline
		\multirow{3}{*}{7} & \multirow{3}{*}{113} & 1 & 705 & 213 & 0.02 & 40 \\
		&  & 2 & 60 & 40 & 0.04 & 45 \\
		&  & 3 & 400 & 0 & 0 & 95 \\ \hline
	\end{tabular}
\end{center}
\end{table}
The minimum total net present value is \$ $322515.00$ with the following optimal allocation:
\begin{align*}
x_{1,1}^{*} &=  0 & x_{1,2}^{*}&= 0 & x_{1,3}^{*} &= 75 & x_{2,1}^{*} &= 90 & x_{2,2}^{*} &= 0 & x_{2,3}^{*} &= 0\\
x_{3,1}^{*} &= 140 & x_{3,2}^{*}&= 0 & x_{3,3}^{*} &= 0 & x_{4,1}^{*} &= 0 & x_{4,2}^{*} &= 0 & x_{4,3}^{*} &= 60\\
x_{5,1}^{*} &= 0 & x_{5,2}^{*}&= 154 & x_{5,3}^{*} &= 58 & x_{6,1}^{*} &= 0 & x_{6,2}^{*} &= 0 & x_{6,3}^{*} &= 98\\
 x_{7,1}^{*}&=0 &x_{7,2}^{*} &= 0 & x_{7,3}^{*} &= 113 & & & &  & & \\
\end{align*}
\section{Swedish steel}
As allocation models split a resource, instead blending models combine them. Various applications blend everything from chemicals, to diets, to metals, to animal food. This problems are formulated in a LP model in which you have to decide what mix of ingredients best fulfills specified output requirements. In this section we propose the Swedish steel problem.\\
The steel industry confronts a blending problem when it melts materials in high-temperature furnaces to manufacture new alloys from scrap. Fagersta AB of Fagersta, Sweden, is one of many companies that have used mathematical programming to plan this steel blending \cite{SSM}.\\
An optimization arises every time a furnace is charged. Scrap in the available inventory is combined with a pure additives to produce a blend having the required percentages of various chemical elements. It is critical to make maximum use of scrap because addittives are much more expensive. In this research we assess that the Swedish steel making will produce a 100-kilogram furnace charge. The following table shows the much smaller fractions of carbon, nickel, chromium, and molybdenum in the four available supplies of scrap. It also shows the three higher-cost addities that can be used and the acceptable ranges for the resulting blend.\\
The following table illustrate a fictitious version of Swedish steelimaking
\begin{table}\caption{text}
\begin{center}
	\begin{tabular}{@{}lllllll@{}}
		\toprule
		& Carbon & Nickel & Chromium & Molybdenum & Available & Cost \\ \midrule
		First scrap   & 0.80   & 18     & 12       & -          & 75        & 16   \\
		Second scrap  & 0.70   & -      & -        & -          & 250       & 10   \\
		Third scrap   & 0.85   & -      & -        & -          & Unlimited & 8    \\
		Fourth scrap  & 0.40   & -      & -        & -          & Unlimited & 9    \\
		Nickel        & -      & 100    & -        & -          & Unlimited & 48   \\
		Chronium      & -      & -      & 100      & 100        & Unlimited & 60   \\
		Molybdenum    & -      & -      & -        & -          & Unlimited & 53   \\ \midrule
		Minimum blend & 0.65   & 3.0    & 1.0      & 1.1        &           &      \\ 
		Maximum blend & 0.75   & 3.5    & 1.2      & 1.3        &           &      \\ \midrule
	\end{tabular}
\end{center}
\end{table}
The principal decision variables in blending models specify how much of each available ingredient to include in the mix. In the Swedish Steel example we define the decision variables $x_{j}$, where $j = 1, \dots, 4$ refers to the four supplies of scrap and $j = 5, \dots, 7$ refer to the pure additives.\\
We have also upper and lower limits on the fraction of carbon, nickel, chromium and molybdenum in the mix. Each constraint will have the form:\\

$\sum\limits_{j}\Bigg($\begin{tabular}{l}
 fraction in\\
jth\\
ingredient\\
\end{tabular}
$\Bigg)$$\Bigg($\begin{tabular}{l}
 amount of\\
jth\\
ingredient\\
\end{tabular}$\Bigg)$
\begin{tabular}{l}
	$\geq$\\
	or\\
	$\leq$\\
\end{tabular}
	$\Bigg($\begin{tabular}{l}
		allowed\\
		fraction in\\
		the blend\\
	\end{tabular}
	$\Bigg)$
	$\sum\limits_{j}\Big($\begin{tabular}{l}
		blend\\
		total\\
	\end{tabular}
	$\Big)$
	
	
\bigskip
Collecting all the elements, the LP model of the Swedish example is: 
\begin{align*}
\min16x_{1}+10x_{2}+8x_{3}+9x_{4}+48x_{5}+60x_{6}+53x_{7}& &\text{(cost)}&\\
x_{1}+x_{2}+x_{3}+x_{4}+x_{5}+x_{6} + x_{7}&= 1000&\text{(weight)}&\\
0.008x_{1}+0.007x_{2}+0.0085x_{3}+0.004x_{4}x_{7}&\geq 0.0065(1000)&\text{(carbon)}&\\
0.008x_{1}+0.007x_{2} + 0.0085x_{3} + 0.004x_{4}x_{7}&\leq 0.0075(1000)&\\
0.180x_{1}+0.032x_{2} + 1.0x_{5}&\geq 0.030(1000)& \text{(nickel)}&\\
0.180x_{1}+0.032x_{2} + 1.0x_{5}&\leq 0.035(1000)&\\
0.120x_{1}+0.011x_{2} + 1.0x_{6}&\geq 0.010(1000)& \text{(chromium)}&\\
0.120x_{1}+0.011x_{2} + 1.0x_{6}&\leq 0.012(1000)&\\
0.001x_{2} + 1.0x_{7}&\geq 0.011(1000)& \text{(molybdenum)}&\\
0.001x_{2} + 1.0x_{7}&\leq 0.013(1000)&\\
x_{1}&\leq 75&\text{(available)}&\\
x_{2}&\leq 250 &&\\
x_{1},\dots, x_{7}\geq 0\\
\end{align*}
The unique optimal solution of this model is according to \cite{RR} and confirmed by the tests illustrated below:
\begin{align*}
x_{1}^{*} &=  75\text{ kg,} & x_{2}^{*}&=  90.91\text{ kg,} & x_{3}^{*} &= 672.28 \text{ kg,} & x_{4}^{*} &= 137.31 \text{ kg,}\\
x_{5}^{*} &= 13.59 \text{ kg,}& x_{6}^{*}&= 0\text{ kg,}  & x_{7}^{*} &= 10.91 \text{ kg.} &&\\
\end{align*}
\section{Ohio National Bank shift scheduling}
Operations planning models decide what work to undertake so that available resources are used efficiently. In Shift scheduling or staff planning models the work is already fixed. We must now plan the resources to accomplish it.\\
The Ohio National Bank (ONB) confronted such a problem in staffing its check processing center \cite{ONB}. Checks received by the bank already have account numbers and other identifying information encoded on them. Machine operators in the check processing center key the dollar  amount of the check, which is then imprinted with the other information for computerized processing.\\Checks arrive through the business day in volumes peaking in the early evening. The fictious version will assume the following arrival (in thousand):
\begin{table}[H]\caption{\label{table:shiftscheduling}Possible ONB arrivals schedule.}
	\begin{center}
	\begin{tabular}{ll|ll}
		\hline
		\textbf{Hour} & \textbf{Arrivals} & \textbf{Hour} & \textbf{Arrivals} \\ \hline
		11:00 & 10 & 17:00 & 32 \\
		12:00 & 11 & 18:00 & 50 \\
		13:00 & 15 & 19:00 & 30 \\
		14:00 & 20 & 20:00 & 20 \\
		15:00 & 25 & 21:00 & 8 \\
		16:00 & 28 & - & -   \\ \hline
	\end{tabular}
\end{center}
\end{table}
Uncollected checks cost the bank money in lost interest. Thus it is essential that all checks be processed in time for collection on the next business day. ONB decided to enforce a requirement that all checks be completed by 22:00. Furthermore, the number unprocessed at any hour should not exceed 20 thousand. \\
Two types of employees can perform the check processing task. Full-time employees work an 8-hour shift with a 1-hour lunch break in the middle. Part-time employees work only 4 hour per day with no lunch. Both types of shifts can begin at any hour of the day and full-time employees can be assigned an hour of overtime.\\
In the analysis we assume that full-time employees receive \$ 11 per hour in pay and benefits, plus an extra \$ 1 per hour in "night differential" for time after 18:00 and 150\% pay for daily overtime. Part-time employees are paid \$ 7 per hour, plus \$ 1 per hour night differential after 18:00. Also, to keep overtime under control, we require that no more than half the full-time employees on any shift work overtime and that the total number of scheduled overtime hours not exceed 20 per day.\\
Naturally, full-time employees work faster than part-timers. We will assume that full-time operators process 1000 checks per hour and part-timers only 800.\\
One final complication is encoding stations. The number of machines available limits the number of employees who can work at any one time. Let us assume the center will have 35 machines.\\

\begin{table}[]\caption{\label{table:Shiftscheduling2}Possible Shifts in ONB Example}
	\begin{center}
	\begin{tabular}{llllllllllll}
		\hline
		\multirow{\textbf{Start}} & \multicolumn{3}{l}{\textbf{Full-time shift}} & \multicolumn{8}{l}{\textbf{Part-time shifts}} \\ \cline{2-12} 
		& \textbf{11} & \textbf{12} & \textbf{13} & \textbf{11} & \textbf{12} & \textbf{13} & \textbf{14} & \textbf{15} & \textbf{16} & \textbf{17} & \textbf{18} \\ \hline
		11:00 & R & - & - & R & - & - & - & - & - & - & - \\
		12:00 & R & R & - & R & R & - & - & - & - & - & - \\
		13:00 & R & R & R & R & R & R & - & - & - & - & - \\
		14:00 & R & R & R & R & R & R & R & - & - & - & - \\
		15:00 & - & R & R & - & R & R & R & R & - & - & - \\
		16:00 & R & - & R & - & - & R & R & R & R & - & - \\
		17:00 & R & R & - & - & - & - & R & R & R & R & - \\
		18:00 & RN & RN & RN & - & - & - & - & RN & RN & RN & RN \\
		19:00 & RN & RN & RN & - & - & - & - & - & RN & RN & RN \\
		20:00 & ON & RN & RN & - & - & - & - & - & - & RN & RN \\
		21:00 & - & ON & RN & - & - & - & - & - & - & - & RN \\ \hline
	\end{tabular}
	\end{center}
\end{table}
The main decisions to be made in shift scheduling models are the number of employees to work various shifts. \\In the ONB case we have all the possibilities in table \ref{table:Shiftscheduling2}. One additional hour may also be worked in overtime.\newpage
Using the index $h$ corresponding the shift start time, we define the following decision variables:
\begin{itemize}
	\item $x_{h}$ is the number of full-time employees beginning a shift at hour $h \in \{11, \dots, 13\}$.
	\item $y_{h}$ is the number of full-time employees with shift beginning at hour $h$ who overtime ($h \in \{11, 12\}$).
	\item $z_{h}$ corresponds to the number of part-time employees beginning a shift at hour $h\in\{11, \dots, 18\}$.
\end{itemize}
With the ONB case we have a slight complication in covering requirements. Work arrivals are specified on an hour-by-hour basis, but work completion is limited only by checks being finished at 22:00. To model covering in such a case, we define also $w$ as well:
\begin{itemize}
	\item $w_{h}$ as unclompeted work backlog at hour $h$ (in thousands).
\end{itemize}
\section{A comparative study}
In this section, we give a comparison between the results given by the infeasible prima-dual algorithms and the LPF predictor-corrector described in the previous chapter.\\ We compute the methods to solve the LP problems before illustrated. Then a study of the numerical results will be discussed.


\chapter{Conclusion}
 All variables $(x, \lambda, s)$ change at each iteration and the linear algebra operations which are required to update them have to involve the complete matrix $A$. This makes a single iteration of the interior point method significantly more expensive than that of the simplex method.
\lstinputlisting[language=Python]{MehrotraMethod.py}

\begin{thebibliography}{9}
	\bibitem{MARE} Adler I., Monteiro R. D. C., Resende M. G. C., \emph{ "A polynomial-time primal-dual affine scaling algorithm for linear and convex quadratic programming and its power serier extension"}, Math. of OR, 15: pp. 191-214, (1990).
	\bibitem{ADL} Adler I., Monteiro R. D. C., \emph{Limiting behaviour of the affine scaling continuous trajectories for linear programming problems}, Mathematical Programming, pp. 29-51, (1991).
			\bibitem{SPS} D'Apuzzo M., De Simone V., di Serafino D., \emph{ "Starting-point strategies for an infeassible potential reduction method."}, Springer-Verlag, D. Optim Lett, 4, pp: 131-146, (2010).
	\bibitem{1}Dantzig, G. B.,\emph{\;Linear Programming and Extensions}, Princeton, University Press, Princeton, NJ, (1963).	
	\bibitem{DAN}Dantzig, G. B.,\emph{\;Expected number of steps of the simplex method for a linear program with a convexity constraint.}, Technical Report SOL 80-3, Systems Optimization Laboratory, Department of Operations Research, Stanford University, Stanford, CA, (1980).
	\bibitem{2} Andersen E. D, and Ye Y.,  \textit{Combining interior-point and pivoting algorithms for Linear Programming}, (1996).
		\bibitem{MINTY} Klee, V., Minty, G., \emph{ How good is the simplex algorithm? } in O. Shisha, ed.,
	‘Inequalities–III’, Academic Press, New York, pp: 159–175, (1972).
	\bibitem{Lem} Lemke C.E, \textit{ The dual method of solving the linear programming problem.} Naval Research Logistics Quarterly, John Wiley and Sons, (1954).
		\bibitem{ONB}Based on Krajewski L. J., McKenzie P., Ritzman L. P., \textit{ "Shift Scheduling in Banking Operations: A Case Appllication"}, Interfaces, 10:12, (1980).
		\bibitem{LMS} Lustig I. J., Marsten E., Shanno D. F., \emph{ Computational experience with a primal-dual interior point method for linear programming}, Linear algebra and its applications, pp. 191-222, (1991).
		\bibitem{ComTeq} Maros I., \emph{ "Computational Techniques of the Simplex Method}, first ed., Kluwer
		Academic Publishers, Boston, (2003).
		\bibitem{meg} Megiddo N., \emph{ "Pathways to the optimal set in linear programming"}, in Progress in Mathematical Programming: Interior-Point and RElated Methods, Springer-Verlag, New York, pp. 131-158, (1986).
	\bibitem{MER} Mehrotra S., \emph{ On the implementation of a primal-dual interior point method. } SIAM Journal on Optimization. 2, pp: 575-601 (1992).
	\bibitem{MUR} Mehrotra S., \emph{ Advanced Linear Programming: Computation and
	Practice. } McGraw-Hill New York, New York (1981).

	\bibitem{W}Nocedal J., Wright J. S., \emph{\;Numerical Optimization}, Springer Series in OR, Springer, New York, (2006).
	\bibitem{3}Victor Klee and George J. Minty.\emph{ How good is the simplex algorithm? Technical report}, Washington University Department of Mathematics, 1970.
	\bibitem{Kar} N. K. Karmarkar,\emph{ A new polynomial-time algorithm for linear programming}, Combinatorica, (1984).
	\bibitem{5} S. Mizuno, M.J. Todd, and Y. Ye,\emph{\;On adaptive-step primal-dual interior-point algorithms for linear programming}, Math. of OR, vol. 18, pp. 964-981, (1993). 
	\bibitem{5} G. B. Dantzig, A. Orden, P. Wolfe, \emph{ Notes on linear programming: Part I- The generalized simplex method for
	minimizing a linear form under linear inequality restrictions.} Pacific J Math pp: 183-195, (1955). 
	\bibitem{Lexico2}  Charnes A. \emph{ Optimality and degeneracy in linear programming}, 1952. pp: 160-170. 
	\bibitem{(Natural)} B. Kent, B. B. Bare, R. C. Field, G. A. Bradley, \textit{Natural Resource Land Management Planning Using Large-Scale Linear Programs: The USDA Forest Service Experience with FORPLAN}, OR, 39, pp: 13-27, (1991).
\bibitem{RR} Rardin Ronald L., \textit{" Optimization in operations reseasch"}, Pearson Education (US), Second edition, University of Arkansas, (2017).

\bibitem{ForSer} \emph{"Forest Service planning : accommodating uses, producing outputs, and sustaining ecosystems"}, Congress of the United States-Office of technology assessment.
\bibitem {VAN} Vanderbei J. Robert, \emph{\;"An interior point code for quadratic programming"}, Optim. Methods Software, 1, pp: 451-484, (1999). 
\bibitem {LP} Vanderbei J. Robert, \emph{\;"Linear programming:
Foundations and Extensions"}. Dept. of Operations Research and Financial Engineering
Princeton University, Springer Science + Business Media, (2001).
\bibitem{SSM} Westerberg, C.-H., Bjorklund B., Hultman E., \emph{"An Application of Mixed Integer Programming in a Swedish Steel Mill" }, Interfaces, 7:2, pp: 39-43, (1977).
\bibitem {Wright} Wright J. Stephen, \emph{\;Primal-Dual Interior Point Methods.} SIAM: society for industrial and applied mathematics. Philadelphia, %pag 134.
\bibitem{XY}Xiaojie Xu, Yinyu Ye, \emph{"A generalized homogeneous and self-dual algorithm for linear programming"}, Operations Research Letters, 17, pp: 181-190, (1995).
\bibitem{LNP}Luenberger David G., Yinyu Ye, \emph{"Linear and Nonlinear Programming"}, Springer Science+Business Media, 3, pp: 136-140, (2008).


\end{thebibliography}



\end{document}
