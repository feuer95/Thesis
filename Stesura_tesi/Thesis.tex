\documentclass[a4paper,10 pt,titlepage,twoside]{book}
\usepackage[utf8]{inputenc}

\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
	backgroundcolor=\color{backcolour},   
	commentstyle=\color{codegreen},
	keywordstyle=\color{magenta},
	numberstyle=\tiny\color{codegray},
	stringstyle=\color{codepurple},
	basicstyle=\ttfamily\footnotesize,
	breakatwhitespace=false,         
	breaklines=true,                 
	captionpos=b,                    
	keepspaces=true,                 
	numbers=left,                    
	numbersep=5pt,                  
	showspaces=false,                
	showstringspaces=false,
	showtabs=false,                  
	tabsize=2
}

\lstset{style=mystyle}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{geometry}
\geometry{a4paper,top=3cm,bottom=3cm,left=3.5cm,right=3.5cm,heightrounded,bindingoffset=5mm}
\usepackage{booktabs}
\usepackage{color}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[toc,page]{appendix}
\usepackage{geometry}
\usepackage{statrep}
\usepackage{setspace}
\usepackage{emptypage}
\usepackage{newlfont}
\usepackage{multirow}
\usepackage{algpseudocode} 
\usepackage{verbatim}
\usepackage[]{algorithm2e}
\usepackage[Algorithm]{algorithm}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{lmodern}
\usepackage{fullpage}
% for plots
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.9}
\usepgfplotslibrary{external}
% for algorithm description
\usepackage{alltt}
\usepackage{boxedminipage2e}
% for algorithm description in a box
\usepackage{boxedminipage}
% for colorful comment
\usepackage{color}

\newcommand{\numberset}{\mathbb}
\newcommand{\N}{\numberset{N}}\usepackage{amsmath}
\newcommand{\Z}{\numberset{Z}}
\newcommand{\R}{\numberset{R}}
\newcommand{\Q}{\numberset{Q}}
\newcommand{\K}{\numberset{K}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\n}{\mathcal{N}}

\DeclareMathOperator{\ord}{ord}

%aggiunto da me
\theoremstyle{plain} 
\newtheorem{thm}{Theorem}[chapter] 
\newtheorem{cor}[thm]{Corollario} 
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposizione} 
\newtheorem*{theorem*}{Theorem}


\theoremstyle{definition} 
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Example}
\newtheorem{propr}{Propriet�}

\theoremstyle{remark} 
\newtheorem{oss}[thm]{Osservazione} 


%per gli spazi:
\usepackage{setspace}
\singlespacing


%\renewcommand{\rmdefault}{phv} % Arial
%\renewcommand{\sfdefault}{phv} % Arial
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\theoremstyle{definition}
%\newtheorem{definizione}{Definizione}

%\theoremstyle{plain}
%\newtheorem{teorema}{Teorema}

%\linespread{1.525}\selectfont

\begin{document}
\thispagestyle{empty}

\centerline {\huge{\textsc{Università degli Studi di Torino}}}
\vskip 27 pt

\centerline {\Large{\textsc{Dipartimento di Matematica Giuseppe Peano}}}

\vskip 20 pt

\centerline {\Large{\textsc{Scuola di Scienze della Natura}}}

\vskip 20 pt

\centerline {\Large{\textsc{Corso di Laurea Magistrale in Matematica}}}


\vskip 60 pt





%\begin{tabular}{ccc}
\centerline {\includegraphics[width=7cm]{logo.jpg}}
%\end{tabular}
\vskip 1.2cm
\centerline {\normalsize {Tesi Magistrale}} 

\vskip 0.7cm

\centerline {\Large {\bf A predictor-corrector LPF Method}}

\vskip 1.7cm

\noindent Relatore: Prof.ssa Paola Lamberti
\hfill  {Candidato: Elena Scotto }\\





\vskip 2.7cm


\centerline{Anno accademico 2018/2019}

\tableofcontents

% 
%
% CAPITOLO 0
\chapter*{Abstract}
The concept of optimization is now well rooted as a principle underlying the analysis
of many complex decisions or allocation problems: Linear Programming (LP) is one of the simplest ways to perform optimization.
This thesis discusses the Simplex method and the Interior-Point methods (IPM).
The aim is to show that the significant difference between them is reflected not only on the theoretical background but also in the practical implementation and to point out the powerful of the IPMs, owing to their vast applicability.\\
The research addresses the role of the combined predictor-corrector step in Mehrotra's IPM method and build  a new algorithm applying this correcting technique to the Long-Path Following methods (LPF), which displays an extensive theoretical complexity and uses the nested neighborhood $\mathcal{N}_{-\infty}(\gamma)$.\\
First, it is given a brief description of these methods,
%: the simplex method, that is known to be very efficient practically, and the primal-dual %interior-point
then we outline a comprehensive convergence analysis of three important IPM: the primal-dual affine scaling, the LPF and the Mehrotra's method. \\
After introducing the basic theoretical framework, we exhibit a comparison of these competitors, testing them on some real models. We show that the corrector approach of the LPF presented in this work, improves the efficiency of the algorithm but the 
neighborhood restricts the progress achived in Mehrotra's method.\\
The programs that implement these algorithms are written in Python. 

%\addcontentsline{toc}{chapter}{Abstract}  % se non si vuole numerare l'introduzione, ma farla comparire nell'indice


\chapter{Introduction to the linear programming}
Optimization is a fundamental tool for understanding nature, science, engineering, economics and mathematics: a large number of real world problems can be treated as optimization problems, in which the goal is to select values that maximize or minimize a given \textit{objective function}, subject to certain \textit{constraints}.\\ The process of identifying objective, variables and constraints for a given problem is knows as \textit{modeling}. Construction of an appropriate model is the first step and, once it is formulated, an optimization algorithm can be used to find its solution.\\ There is a collection of algorithms, each of them is tailored to a particular type of optimization problem. Linear programming problem remains one of the most well-studied optimization problems: it consists in maximizing or minimizing a linear function over a certain domain, defined by a set of linear constraints.\\
Linear Programming (LP) has been dominant paradigm in optimization since Dantzig's development of the simplex method in the 1940s. Regarding the theoretical complexity of this method, it has proved that the expected number of iterations in the solution of a linear problem is polynomial. Furthermore, the worst case complexity has exponential behavior. It has been observed that the simplex algorithm performs sufficiently well in practice, especially on small or medium sized LPs, but its performance is not satisfactory in large-scale LPs. This weakness of simplex algorithm is due to the stalling and cycling problem but many anti-cycling pivoting rules have been introduced in the past.\\
Since Dantzig's initial contribution, researchers have made many efforts in order to enhance the performance of simplex algorithm. In the 1980s the monopoly of the simplex algorithm in the solution of the LP has been challenged. Interior Point Methods (IPM) were the result of subsequent research and their performance has been more than satisfactory compared to the simplex algorithm. The main idea of IPMs is that the computation of the optimal solution can be achieved by moving inside the feasible region, defined by the constraints. \\
This thesis is organized as follow:
an introductory section summarizes the basic theory of the linear programming. In the chapter 2 we delineate the simplex method. The chapter 3 is dedicated to the primal-dual interior point methods, taking particular attention to the affine-scaling and the long-path following methods. It is also examined the Mehrotra's predictor-corrector algorithm, which is the basis of much of the current generation of software, even if no convergence theory is available for this algorithm.\\After a theoretical convergence analysis, the implementation illustrates the numerical results that we obtained for the considered physical problems and a comparison is performed.
Concluding, in the last chapter we give an overview of the work realized in this thesis and suggest possible next steps. 

%
% CAPITOLO 1
\chapter{Basic theory}
The variables in optimization models represent the decisions to be taken and the constraints specify the restrictions and the interactions that limit the variable values.
To complete the model, we need the objective functions that quantify the decision consequences to be maximized or minimized. This chapter introduces notations, terminologies and formulations of a general LP problem.

\section{Linear programming model}

Since 1950, generations of workers in management, economics, finance and engineerng have been trained in the techniques of formulating linear models that,
as the name implies, are characterized by linear objective function and constraints formulated with linear equalities or linear inequalities.
Then, the feasible set satisfying the constraints is a \textit{polytope}, i.e. a convex and connected set with polygonal faces. We say that the LP is \textit{infeasible} if the feasible set $\mathcal{P}$ is empty and \textit{unbounded} if the objective function, minimization function for istance, may be improved indefinitely without violating the constraints and bounds of the feasible region.\\
We consider the LP in the following \textit{standard form}:
\begin{alignat*}{1}\label{eq:stdform}
\text{minimize\;}\; &c_1 x_1 + c_2 x_2+ ... c_n x_n\\[1.8mm]
\text{subject\;to\;} &a_{11} x_1 + a_{12} x_2+ ... +a_{1n}x_n = b_1\\
&a_{21} x_1 + a_{22} x_2 + ... + a_{2m} x_n= b_2\\
&\vdots\\
&a_{m1} x_1 + a_{m2} x_2 + ... + a_{mn} x_n= b_m\\
\text{and}\; & x_1 \geq 0 , x_2 \geq 0, ... , x_m \geq 0
 \end{alignat*}

where the $b_{j}$, $c_{i}$ \text{and} $a_{ij}$ are fixed real costants, with $i \in\{1,...,n\}$ and $j\in\{1,...,m\}$.\\ In a compact notation, using vectors, the standard LP problem can be written as
\begin{equation}\label{(Prim)}
 \begin{split}
\min\;&c^{T}x\\
\text{subject\;to\;}&Ax= b\;\\\text{and\;}&x\geq0
 \end{split}
\end{equation}

with $x$ an \textit{n}-dimensional column vector of decision variables, $c^
{T}$ a \textit{n}-dimensional vector, \textit{A} a $m \times n$ real matrix, and \textit{b} a \textit{m}-dimensional column vector (Kantorovich L., 1939).\\
If $x$ satisfies the constraints $Ax = b$, $x\geq0$, we call it \textit{feasible point}; the set of all feasible points is the \textit{feasible set}, indicated by $\mathcal{P}=\lbrace x\in\mathbb{R}^{n,m}\; |\; Ax = b , x \geq0\rbrace$.\\
In the case the constraints set is determined entirely by linear inequalites $Ax \leq b$, which in the literature (see \cite{W}) is said to be a \textit{canonical form}, the problem may be alternatively expressed as:
\begin{alignat*}{3}
\text{minimize\;}&c_1 x_1 + c_2 x_2+ ...+c_n x_n&&&\\[1.8mm]
\text{subject\;to\;}&a_{11} x_1 +a_{12}x_2 + ... +a_{1n}x_n +y_{1}&&&= b_1\\
		   	&a_{21}x_1+a_{22}x_2+ ... +a_{2n}x_n&+y_{2}&&= b_2\\
&&\;\;\;\vdots&&\\
&a_{m1}x_1+a_{m2}x_2+ ... +a_{mn}x_n+&&&y_{m}=b_m\\
\text{and} \;& x_{i} \geq 0;\;\; y_{j} \geq 0; \text{\;\;for }i = 1,...,n&\text{ and }j&=&1,...,m.
\end{alignat*}
The new positive variables $\mathit{y_{i}}$, $\;i \in \{1, ..., n\}$ introduced to convert the inequalities into identities, are called \textit{slack variables} and the problem has the standard form with $n+m$ unknowns variables $x_{i}, y_{j},i \in \{1, ..., m\}$ and $j \in \{1, ..., n\}.$\\ The new matrix that now describes the linear equality constraints, assumes the form $\left[\begin{matrix}A\;\vert\; I\;\end{matrix}\right]$, with $A$ the $m \times n$ matrix of the original canonical LP and the identity matrix $I$ associated to the slack variables, and has dimension $m \times (n + m)$.\\
Considering the system of equalities \ref{(Prim)}, we can identify a set of \textit{m} linearly independent columns from the \textit{n} columns of  $A$ and create a $m \times m$ submatrix called \textit{basis matrix} ($A_{B}$) with the index set of the columns ($B$) called \textit{basis} of matrix $A$. Then, using a partition $(B, N)$, with basis $B$ and $N$ its complementary set, the \textit{nonbasis} set, we can formaulate the standard LP as following:
\begin{equation}\label{(Prim1)}
\begin{split}
\min\;&c_{B}^{T}x_{B}+c_{N}^{T}x_{N}\\
\text{subject\;to\;}&A_{B}x_{B}+A_{N}x_{N}= b\;\\\text{and\;}&x_{B},x_{N}\geq0
\end{split}
\end{equation}
Since $A_{B}$ is nonsingular, we may uniquely solve the equation $A_{B}x_{B} = b$; if we assume for simplicity $B = \{1, \dots, n\}$, then the point $x =\left(x_{B},0_{N}\right)$ is a solution of the original equality system. This leads to the following definition:
\begin{defn}

	We define the solution $x$ above as \textit{basic point} with respect to the basis $B$, the basic point is \textit{feasible} if $x_{B}\geq 0$. \\The components of $x$ associated with columns of $A_{B}$ are called \textit{basic variables} and components associated to the complementry set $N$ are the \textit{nonbasic variables}.\\
	A basis $B$ is \textit{degenerate} if $x_{i}= 0$ for some $i\in B$.\\
	A LP is said to be \textit{degenerate} if it has at least one degenerate basis.
\end{defn}
For the standard formulation, when $m \geq n$ the feasible region is empty or consists in a single point.\\
 We will assume throughout that $m < n$, hence the $m$ rows are linear indipendent: there is at least one basic point and, accordingly, one solution of the standard equality system in \ref{(Prim)}. Certainly, if the LP problem is in canonical form, then the extended $m \times (n+m)$ matrix $[A\;|\;I]$ with slack variables satisfies this property. \\
Now we outline the importance of basic feasible points in solving LP with the simplex method.
Throw the following theorem we state that it is necessary only to consider basic feasible
vectors when seeking an optimal solution because the optimal
value is always achieved at such a solution.\\ (The method to prove the theorem is in many respects as important as the result itself, since it represents the beginning of the development of the simplex
method.)
\begin{thm}[\textbf{Fundamental theorem of liner programming}]\label{Fund}
\begin{enumerate}
	\
\item If there is a feasible point for \ref{(Prim)}, then there is a basic feasible point.
\item If \ref{(Prim)} has solutions, then at least one such solution is a basic optimal point.
\item If \ref{(Prim)} is feasible and bounded, then it has an optimal solution.
\end{enumerate}
\end{thm}
\begin{proof}
	See \cite{LP}
\end{proof}
Thus, it describes a peculiar feature of the LP: reducing the task of solving it to searching over basic feasible points the solutions. Since for a problem having $n$ variables and $m$ constraints there are at most ${n}\choose{m}$ basic points (corresponding to the number of ways of selecting m of n columns), there are only a finite number of possibilities. 

\subsection*{A geometric approach}
A LP problem is simple to state and visualize. In fact, very simple graphic techniques have enough power to tiny models. They also yield helpful intuition about properties and soultion methods for model of more realistic size.\\ The set $\mathcal{P}$ defines a polytope: geometrically it constitutes the \textit{feasible region} and the \textit{vertices} are the points that do not lie on a stright line between two other points in the set. Algebraically, the vertices of the feasible set $\mathcal{P}$ are exactly the basic feasible points.\\ According to the Fundamental theorem, we can restrict our attention to the vertices of this polytope and it implies that we can explore only at most  ${m}\choose{n}$ points.\\[0.5cm]
Considering the following simple LP:
\begin{align*}
\min -&x_{1}+ x_{2}-4x_{3}\\
	&x_{1}+x_{2}+x_{3}=1, \text{\; with\;} x_{1}, x_{2}, x_{3} \geq 0
\end{align*}
the tetrahedron in \ref{tetra} is a geometric rappresentetion of the feasible set $\mathcal{P}$: the verteces ${x}_{B_{1}}$, ${x}_{B_{2}}$ and ${x}_{B_{3}}$ are feasible basic points respect to the the basis $B_{1} =\{1\}$,  $B_{2} =\{2\}$,  $B_{3} =\{3\}$.
\begin{figure}[h]\caption{\label{tetra}}
\begin{center}
\begin{tikzpicture}[y={(1cm,0cm)}, x={( -0.5cm, -0.5cm)}, z={(0cm,1cm)}] % s i s t e m a di r i f e r i m e n t o t i k z 3 d

\coordinate (O) at (0, 0, 0);
\draw[-latex] (O) -- (3.5 , 0, 0) node [left] {$x_{1}$};
\draw[-latex] (O) -- (0, 3.5, 0) node [right] {$x_{2}$};
\draw[-latex] (O) -- (0, 0, 3.5) node [above] {$x_{3}$};
\draw[help lines ,-latex] (O) -- (2.5 ,0 ,0)
 node[left] {${x}_{B_{1}}$};
\draw[help lines ,-latex] (O) -- (0 ,2.5 ,0)
 node[above] {${x}_{B_{2}}$};
 \draw[help lines ,-latex] (O) -- (0 ,0 ,2.5)
node[right] {${x}_{B_{3}}$};
\coordinate (A) at (0, 0 ,0);
\coordinate (B) at
(2.5 ,0 ,0) node [ left ] {$ x $};;
\coordinate (D) at (0 ,2.5 ,0);
\coordinate (C) at (0 ,0 ,2.5);
\draw (B) -- (D) -- (C) -- cycle;
\filldraw[draw=red,bottom color=red!50, top color=yellow]
(B) -- (D)  -- (A);
\filldraw[draw=red,bottom color=red!50, top color=yellow]
(C) -- (D)  -- (A);
\filldraw[draw=red,bottom color=red!50, top color=yellow]
(B) -- (C)  -- (A);
\end{tikzpicture} 
\end{center}
\end{figure}
%\begin{ex}
%The feasible set of a standard form linear programming problem is defined by the following constraints:
%\begin{alignat*}{3}
%-x_{1}+&x_{2}-x_{3}&\;&\;&= 0\\
%x_{1}+&\;&+x_{4}\;&\;&= 2\\
%&x_{2}&\;&+x_{5}&= 3\\
%x \geq 0&\;&\;&\;&\\
%\end{alignat*}
%\end{ex}
%[\textit{con una illustrazione grafica del poliedro si mostra l'insieme dei vertici presi in considerazione e candidati punti ottimali}]

\section{Optimality and duality in LP}
In this section we introduce the optimality and duality theory and investigate the important relationship between primal and dual LP, that provide algorithm strategies.\\ 
Optimality conditions for the LP can be derived from the theory of the constrained optimization related to a general non linear problem (NLP), defined as follow:

\begin{equation}\label{NLP}
\min f(x)\text{\;subject\;to\;}\begin{cases} c_{i}(x) = 0 &i \in \mathcal{E}\\ c_{i}(x)\leq 0 &i\in \mathcal{I}\end{cases}
\end{equation}
\\
where $f$ and $c_{i}$ are smooth, real-valued functions defined on subset of $\mathbb{R}^{n}$ and $\mathcal{E}$ and $\mathcal{I}$ are two finite sets of indices in $\mathbb{N}$.\\Let us recall only the necessary conditions, essential to explain the duality results for the linear case, after introducing the following definition of specific regular conditions, defined below:
\begin{defn}
	Given a point x, $\mathcal{A}(x)= \mathcal{E}\cup\left\lbrace i\in\mathcal{I}\;|\;c_{i}(x) =0\right\rbrace$ is called \textit{active set} and we say that the linear independence constraint qualification, $LICQ$, holds if the set of active constraint gradients $\left\lbrace \nabla c_{i}(x),,i\in\mathcal{A}(x)\right\rbrace$ is linear indipendent.
\end{defn}
We define the \textit{Lagrangian function} for the general problem \ref{NLP} 
\begin{equation*}
\mathcal{L}\left(x,\lambda\right)=f(x)-\sum_{i\in\mathcal{E}\cup\mathcal{I}}\lambda_{i}c_{i}(x).
\end{equation*}
The necessary conditions, defined in the following theorem, are called \textit{first-order conditions} because they are concerned with properties of the gradients of the objective and constraint functions.
\begin{thm}
Suppose that $x^{*}$ is a local solution of \ref{NLP}, that f and $c_{i}$ are continuously differentiable, and the LICQ holds at $x^{*}$. Then there is a Lagrange multiplier vector $\lambda^{*}$, such that 
\begin{alignat*}{2}
\nabla_{x}\mathcal{L}(x^{*},\lambda^{*})&=0&&\\
c_{i}(x^{*})&=0, &&\;\;\;\;\forall i\in\mathcal{E}\\
c_{i}(x^{*})&\geq 0, &&\;\;\;\;\forall i\in\mathcal{I}\\
\lambda^{*} &\geq 0, &&\;\;\;\;\forall \in\mathcal{I}\\
\lambda^{*}c_{i}(x^{*})&= 0,&&\;\;\;\;\forall i\in\mathcal{E}\cup\mathcal{I}.\label{CompCon}\\
\end{alignat*} 
\end{thm}

These equalites are called \textit{Karush-Kuhn-Tucker} conditions, or \textit{KKT} conditions for short and the last equality is the \textit{complementary condition}.\\ Though this theorem requires LICQ, the result continues to hold for \textit{dependent} constraints provided they are linear, as in the case of the standard LP \cite{W}. The LP Lagrangian function is:\\
\begin{equation}\label{Lagrangian}
\mathcal{L}(x,\lambda,s)=c^{T}x-\lambda^{T}\left(Ax-b\right)-s^{T}x.
\end{equation}
Now we illustrate the first-order necessary conditions: let us assume that the matrix $A\in\mathbb{R}^{m,n}$, the vectors $b\in\mathbb{R}^{m}$ and $c\in\mathbb{R}^{n}$ construct a standard LP. A vector $x^{*}$ is a solution if and only if exist Lagrange multipliers $\lambda^{*},\;s^{*}$ such that the \textit{primal-dual solution} $\left( x^{*},\lambda^{*},s^{*}\right)\in\mathbb{R}^{n}\times\mathbb{R}^{m}\times\mathbb{R}^{n}$ satisfies these conditions: 
\begin{align}
A^{T}\lambda+s&=c,\tag{2.5a}\\ \label{DF}
Ax&=b,\tag{2.5b}\\ \label{PF}
x&\geq 0,\tag{2.5c}\\
s&\geq 0,\tag{2.5d}\\
x_{i}s_{i}&=0,\; for\;i= 1,2,...,m.\label{CC} \tag{2.5e}
\end{align} 
The complementary conditions \ref{CC} show that at least one of the components $x_{i}$ and $s_{i}$ must be zero for each $i=0,1,2,...,n$.\\
 Convexity of the problem ensures that these conditions are also sufficient for a global minimum, hence the KKT conditions are also \textit{sufficient}: if we have a primal feasible vector $x\in\mathcal{P}$, and another vector $(\lambda, s)$ such that the equations are satisfied, then $x$ is the solution of \ref{(Prim)}. We can prove this claim directly by taking an arbitrary primal feasible vector $\bar{x}$ and showing that its objective value is no smaller than $c^{T}x$:
\begin{equation*}
c^{T}\bar{x}=(A^{T}\lambda+s)^{T}\bar{x}=b^{T}\lambda+s^{T}\bar{x}\geq b^{T}\lambda= c^{T}x.
\end{equation*}
We conclude that the KKT conditions are both necessary and sufficient for optimality in the LP. Besides, we find that
\begin{equation*}
	c^{T}x^{*}=\left(A^{T}\lambda^{*}+s^{*}\right)^{T}x^{*}=\left(Ax^{*}\right)^{T}\lambda^{*}=b^{T}\lambda^{*}.
\end{equation*}
With this equality, we can formulate the \textit{dual problem} of \ref{(Prim)}
\begin{equation}\label{Dual}
\begin{split}
&\text{maximize\;} b^{T}\lambda,\\
&\text{subject\;to\;}A^{T}\lambda \leq c.
\end{split}
\end{equation} 
We can restate this problem in a standard form introducing the slack variables as follows:
\begin{equation}\tag{D}\label{(Dual)}
\begin{split}
&\text{maximize\;}b^{T}\lambda,\\
&\text{subject\; to\;}A^{T}\lambda+s=c\\ &\text{and\;} s\geq0.
\end{split}
\end{equation}

Note that in \ref{Lagrangian} the Lagrange multipliers are the unknowns variables in (D). In fact, the primal-dual relationship is symmetric: by taking the dual of the dual problem, we recover the original problem \ref{(Prim)} that we briefly call \textit{primal} problem (P). In the following theorem is described this relationship:
\begin{thm}[\textbf{Strong duality}] 
	\begin{itemize}
		\
		\item If either the primal or the dual problem has a finite solution, then so does the other, and the objective values are equal.
		\item If either the primal or the dual problem is unbounded, then the other problem is infeasible.
	\end{itemize}
\end{thm}
(\textit{le dimostrazioni: riferimento: in [1] capitolo 12}).\\[0.5 cm] Hence, by examining the KKT conditions from both the primal and the dual viewpoints, we conclude that the vector $(x^{*},\lambda^{*},s^{*})$ is a primal-dual solution if ond only if $x^{*}$ solves (P) and $(\lambda^{*},s^{*})$ solves (D).\\[1cm]
%\onehalfspacing
Let us define the \textit{dual feasible set} $\mathcal{D}=\{(\lambda,s)\in\mathbb{R}^{m+n}| A^{T}\lambda+s= c,\;s>0\}$, then for every $x\in\mathcal{P}$ and $\left(\lambda,s\right)\in\mathcal{D}$, we have that $c^{T}x-b^{T}\lambda=\left(c-A^{T}\lambda\right)^{T}x=s^{T}x \geq0$.\\
This result leads to the definition of \textit{dual gap} the value $g = c^{T}x - b^{T}y$: since $c^{T}x\geq b^{T}\lambda$ when both primal and dual variables are feasible, we see:\begin{center}
	if $\exists(x,\lambda,s)\in\mathcal{P}\times\mathcal{D}$, then $g= x^{T}s \geq0$.
\end{center}
At a solution, the duality gap $g$ between primal and dual decreases to zero, as we show in the complementary slackness theorem: it is an important premise (foundation) in the development of the IPM illustrated in the Chapter ().
\begin{thm}[\textbf{Complementary slackness}] \ \\
	Let $(x^{*},\lambda^{*},s^{*})\in\mathcal{P}\times\mathcal{D}$. The following are equivalent:
	\begin{itemize}
		\item $x^{*}$ is an optimal solution to (P) and $(\lambda^{*},s^{*})$ is an optimal solution to (D);
		\item $g^{*} = (x^{*})^{T}s^{*}=0$;
		\item $x^{*}_{j}s^{*}_{j}=0,\;\forall\; j=0,...,n$;
		\item If $s^{*}_{j} > 0$ then $x^{*}_{j}= 0,\;\forall\; j=0,...,n$.
	\end{itemize}
\end{thm}

For every KKT solution $(x^{*}, \lambda^{*}, s^{*})$ we have $x_{j}^{*}= 0$ and/or $s_{j}^{*}= 0$ for all $j=0,1,\dots,m$.\\
We can define two index sets $\mathcal{B}$ and $\mathcal{N}$ as follows:
\begin{equation}\label{index}
\mathcal{B} =\{j\in\{1,\dots,m\}|\; x^{*} \not= 0\}, \;
\mathcal{N} =\{j\in\{1,\dots,m\}|\; s^{*} \not= 0\}
\end{equation}  
Obviously, $\mathcal{B}$ and $\mathcal{N}$ are disjoint and form a partition of the indices. Now we state an important theorem:
\begin{thm}[Goldman-Tucker]
	There is at least one solution $(x^{*}, \lambda^{*}, x^{*})$ such that $x^{*}+s^{*}\geq0$.
\end{thm}
The set $\mathcal{B}$ does not necessarily contain $m$ elements, that is the number of the rows of the matrix $A$. This set must not be confused with the set of the basic variables $B$, by the definition (2.1). In the following example, for istance, we have $|\mathcal{B}|= 2$ and three basis sets $B = \{1\}, \{2\}, \{3\}$.
\begin{ex}
Consider
\begin{center} $\min\limits_{x\in\mathbb{R}^{3}} x_{1} \text{\;subject to\;} x_{1}+x_{2}+x_{3} = 1,\; x\geq 0$.\end{center}
The primal solution is $x^{*}=(0, t, 1-t)$, for $t\in(0,1)$. 	
\end{ex} 

The multipliers $(\lambda,s)$ indicate the sensitivity of the optimal objective value  to perturbations in the constraints and the process of finding them is called \textit{sensitivity analysis}. \\ In fact, let we assume a small perturbation of input data, for example $b + \Delta b$. If $\Delta x$ and $\Delta s$ have zero in the same entries as $x$ and $s$ respectively, then
\begin{equation*}
0=x^{T}s=x^{T}\Delta s= \left( \Delta x\right)^{T}s=\left( \Delta x\right)^{T}\Delta s
\end{equation*}
and by the theorem we have that the optimal values for both the original and perturbated problems (P) and (D) equal, so

\begin{align*}
&c^{T}x=b^{T}\lambda  &c^{T}(x + \Delta x)=\left(b+\Delta b\right)^{T}\left(\lambda+\Delta \lambda\right),
\end{align*}
with the feasibility of $x + \Delta x$ and $\lambda+\Delta \lambda$:
\begin{align*}
&A(x + \Delta x)=b+\Delta b
&A^{T}\Delta\lambda=-\Delta s.
\end{align*}
Hence, the change in optimal value due to the perturbation is as follows:
\begin{align*}
c^{T}\Delta x&=\left(b+\Delta b\right)^{T}\left(\lambda+\Delta \lambda\right) - b^{T}\lambda\\
&=\left(b+\Delta b\right)^{T}\Delta \lambda+\left(\Delta b\right)^{T}\lambda\\
&=\left(x+\Delta x\right)^{T}A^{T}\Delta \lambda+\left(\Delta b\right)^{T}\lambda\\
&=\left(x+\Delta x\right)^{T}\Delta s+\left(\Delta b\right)^{T}\lambda\\
&=\left(\Delta b\right)^{T}\lambda.\\
\end{align*} 
In particular, if $\Delta b = \epsilon e_{j}$, we have that $c^{T}\Delta x+\epsilon \lambda_{j}$ and it shows that the change in optimal value is $\lambda_{j}$ times the perturbation to $b_{j}$.

After having delineated the basic tools of the multipliers in terms of sensitivity, the sensitivity analysis is developed later, examining the optimal results obtained by the methods designed.\\

%
%  CAPITOLO 2
%
\chapter{The simplex method}
The simplex method was introduced in 1947 by George Dantzig \cite{DAN1}. The discover of this method happened simultaneously with the realization of LP as an efficient modeling tool for practical decision making and, after 60 years later, it remains one of the most important algorithms in mathematical programming and
optimization, in general.\\
The method exploits the insight provided by the fundamental theorem
\ref{Fund}, which states that if it exists an optimal solution of the LP, it is at one of the vertices of the feasible polytope. \\
The idea of the simplex method is to proceed from one basic feasible point of the feasible set $\mathcal{P}$ to another, in such a way as to continually decrease the value of the objective
function until a minimum is reached.\\ Consider the general LP problem presented in standard form as in \ref{(Prim)}.
We assume for the remainder of the chapter that the matrix $A$ has full row rank: in practice, a preprocessing phase is applied to the user-supplied data to remove some
redundancies from the given constraints and eliminate some of the variables.\\Given an index sets $B$ and $N$, we can identify a partition of the $m$-elements vectors $x$, $c$ and of the matrix $A$ and formulate the LP as following:
\begin{equation}
\begin{split}
\text{minimize\;} &c^{T}_{B}x_{B}+c^{T}_{N}x_{N},\\
\text{subject\;to\;}&A_{B}x_{B}+A_{N}x_{N} = b\text{\;and\;}x_{B}, x_{N}\geq0
\end{split}
\end{equation}
 %with \textit{n} elements corresponding to the basic feasible point we are starting from.
 \\Note that for any $x$, the basic variables $x_{B}$ can be written as a function of the nonbasic variables $x_{N}$ and hence, $x_{B}=A_{B}^{-1}b-A_{B}^{-1}A_{N}x_{N}$. \\Similarly, the objective function can be written as $c^{T}x=c_{B}^{T}A_{B}^{-1}b+(c_{N}-A_{N}^{T}A_{B}^{-T}c_{B})^{T}x_{N}$, denoting the \textit{reduced cost} by \begin{center}
 	$\widetilde{c}=c_{N}-A_{N}^{T}A_{B}^{-T}c_{B}$.
 \end{center}Since we are dealing only with basic feasible points, we can consider the relative basic feasible point $x$ with $x_{N}= 0$, then the cost value it is exactly $\widetilde{c}$.\\
 We can choose the dual points $(\lambda,s)$ such that $(x, \lambda, s)$ satisfies the KKT condition as well: from \ref{CC} we set $s_{B}= 0$ for the complementary condition, therefore we get $s_{N}= c_{N}- A_{N}^{T}\lambda$ from \ref{DF}. Besides, since $A_{B}$ is not singular, this equality uniquely defines $\lambda$ as $\lambda = A_{B}^{-T}c_{B}$ and we can state that the reduced cost $\tilde{c}$ is identical to $s_{N}$ in the feasible basic point.\\  
 
 If there exists a $j \in N$ such that $\widetilde{c}_{j} \leq 0$, then by increasing $x_{j}$ up from zero, we will decrease the value of the objective function.\\
So, in a step of the simplex method we find an index $s \in N$ such that $\widetilde{c}_{s} \leq 0$ and increase $x_{s}$ as much as possible while keeping $x_{B} \geq 0$. We enforce that this non-basic variable is now positive and we include the index $s$ in the basis $B$.\\
In the next step we keep increasing $x_{s}$ until one of the components of $x_{B}$, for istance $x_{r}$, is driven to zero: the index $r$ is removed from $B$ and replaced it with $s$. This process of selecting entering and leaving indices is called \textit{pivoting operation}. \\
On the other hand, if there is no $j \in N$ such that $\widetilde{c}_{j} \leq 0$, then we stop and the current basic feasible solution is an optimal solution. \\
Formalizing the pivoting operation in algebraic terms, we have the current $x$ feasible basic point w.r.t. $B$ and the new iterate $\bar{x}$ such that $\bar{x}_{i} = 0$ for $i \in N\backslash\{s\}$.\\
Hence we have: 
\begin{align}
	A\bar{x} = A_{B}\bar{x}_{B} +A_{s}\bar{x}_{s} = A_{B}x_{B} = Ax,\\
	\text{  then }
	\bar{x}_{B} = x_{B} - A_{B}^{-1}A_{s}\bar{x}_{s}\label{Bar}.
\end{align}
Geometrically speaking, the pivoting operation is a "walk" along an edge of the polytope in order to decrease $c^{T}x$; we continue to move along the edge until a new vertex is encountered. At this vertex, we have $\bar{x}_{s}\geq0$ and one of the components $\bar{x}_{r}\in B$ decreased to zero: we obtain a new basis denoted by $\bar{B} = B \cup \{s\} \backslash \{r\}$.\\
It is possible that $x_{s}$ increases to $\infty$ without encountering a suitable $x_{r}$: that means that the contraint $\bar{x}_{\bar{B}} = x_{B} - A_{B}^{-1}A_{s}\bar{x}_{s}>0$ holds for all positive values of $\bar{x}_{s}$, due to the fact $d := A_{B}^{-1}A_{s}\leq0$. When it happens, the LP is \textit{unbounded}: the cost value $c^{T}x$ decreases to $-\infty$.\\[0.5cm]
Let us now verify that the step leads to a decrease of $c^{T}x$.\\
Since we obtain the new point with variables $\bar{x}_{B}$ defined in \ref{Bar} and $\bar{x}_{N}=(0,\dots, 0, \bar{x}_{s}, 0,\dots, 0)$, the cost function is:
\begin{align*}
c^{T}\bar{x} &=c^{T}_{B}\bar{x}_{B}+c^{T}_{N}\bar{x}_{N}\\
			 &=c_{B}^{T}\bar{x}_{B}+c^{T}_{s}\bar{x}_{s}\\
			 &=c_{B}^{T}x_{B}-c^{T}_{B}A_{B}^{-1}A_{s}\bar{x}_{s}+c_{s}\bar{x}_{s}.
\end{align*}
Having defined $ \lambda=A_{B}^{-T}c_{B}$ and $A^{T}_{s}\lambda = c_{s}-s_{s}$,
\begin{align*}
&= c^{T}_{B}x_{B}-(c_{s} -s_{s})\bar{x}_{s} +c_{s}\bar{x}_{s}.
\end{align*}
Since $x_{N}=0$, we have $c^{T}x=c^{T}_{B}x_{B}$ and therefore 
\begin{align*}
&=c^{T}\bar{x} = c^{T}x - s_{s}\bar{x}_{s}.
\end{align*}
We have covered most of the mechanics of taking a single step of the simplex method. The computational procedure is the following:
\\
\begin{algorithm}[H]\caption{\label{Alg:1}Simplex Method}
\begin{tabbing}
	\\
	\textbf{Given} \=$B, N, x_{B} = A_{B}^{-1}b\geq 0$ with $x_{N}=0$;\\
	%\>Solve $A_{B}^{T}\lambda = c_{B}, \text{ for }\lambda$;\\
	%\>Compute $\widetilde{c}_{N}=c_{N}-A_{N}^{T}\lambda$;\\
	%\>\textbf{If} {$\widetilde{c}_{N}\geq 0$} optimal solution found \textbf{stop};\\
	%\>\textbf{Else}\\
	\> Select $s\in N\;|\;\widetilde{c}_{s}\leq 0$ as the entering index;\\
	\> Solve $A_{B}d = A_{s}$ for $d$;\\
	\>\textbf{If} {$d \leq 0$} unbounded problem: \textbf{stop};\\
	\>\textbf{Else} \=\\
	\>\>Calculate the ratio test $\bar{x}_{r} = \min_{i | d_{i} > 0}(x_{B})_{i}/d_{i}$, and use $t$ to denote the minimizing $r = B[t]$;\\
	\>\>Update \=$\bar{x}_{B} = x_{B}-d\bar{x}_{r}$;\\
	\>\>\>$\bar{x}_{N} = (0,...,0_{[s-1]},\bar{x}_{r},0_{[s+1]},...,0)$;\\
	\>\> Update sets: $\bar{B} = B \backslash \{r\} + \{s\}$ and $\bar{N} = N \backslash \{s\} + \{r\}$;\\
	\textbf{end}
\end{tabbing}
\end{algorithm}

Summarizing, the simplex algorithm moves from basic feasible solution to another one and it moves from one vertex to an adjacent one, for which the basis $B$ differs inexactly one component.\\ Each iteration begins by checking the sign of the coefficients of the reduced cost $\widetilde{c}$ on non-basic variables: if none is negative, then the current basic fesible point is optimal. \\
As we see, it is required a basic feasible starting point $x$ with initial basis $B \in \left\{ 1,2,..., n \right\}$ such that $|B|=m$, $A_{B}$ non singular, $A_{B}^{-1}b=x_{B} \geq 0$ and $x_{N}=0$.\\[1cm]
Now we see that a basic feasible point is immediately available for some LP.\\ For example, in LP problems with constraints in canonical form and with $b > 0$, a basic feasible point corresponding to the standard form is provided by the slack variables as feasible basic ones: $x =\left(0_{[m]},b\right)$.\\Sometimes the problem of finding an initial point and a basis may be itself nontrivial but the \textit{two-phase} method deals with this difficulty. The idea is to add artificial variables in order to give a basic feasible initial point for a second phase in which we can extract easily the solution of the original problem.\\
In \textit{phase I} we solve the following problem, with unit vector $e= (1,\dots,1)^{T}$:
\begin{equation}\label{IIPH}
\begin{split}
\min &\;e^{T}u\\
\text{subject\;to\;}&A_{B}x_{B}+A_{N}x_{N} + \textbf{E}u = b\;\text{and\;} u\geq 0\\
\text{with\;} \textbf{E}_{jj}& =\begin{cases} -1\;\text{\;\;if\;} b_{j} \leq 0\\
0\;\; \text{\;\;\;\;otherwise}
\end{cases}   
\end{split}
\end{equation} \\
Using \textit{artificial variables} $u_{i}$ in each violated constraint, it is easier to complete a starting feasible point. Since they are restricted to be nonnegative, the objective value is as well. If this last one is zero, then the \textit{phase I} terminates and we compute a second linear programming (\textit{Phase II}).\\
The point $(x,u)$, defined by $x = 0$ and $u_{j} = |b_{j}| \text{\;for\;}j =\{1,2,...,n\}$, is a basic initial feasible point, corresponding to the basis $B = \{n-m,...,n\}$.\\ We can see that at any feasible point for \ref{IIPH}, $u$ represents the amounts by which the constraints $Ax = b$ are violated by the $x$ component and the objective function is the sum of these violations. \\
The \textit{phase I} minimizes this sum and it has an optimal objective value of zero if and only if the original LP is feasible. In fact we have two cases at the optimal solution $\bar{u}$: 
\begin{itemize}
	\item[-]$1^{T}\bar{u}$ is zero: the simplex method finds a solution $(\bar{x},\bar{u})$ with $\bar{u}=0$ and it starts the \textit{phase II} step with initial point $\bar{x}$;
	\item[-]$1^{T}\bar{u}$ is positive and the original problem is unfeasible.
\end{itemize}
If we are in the first case, after dropped all the artificial variables $\bar{u}$, we proceed with the second phase: it consists on an implementation of the simplex method, with starting feasible point $\bar{x}$.\\ 
While two-phases method deals with feasibility and optimality separately, the \textit{Big-M} method combines these activities in a single search and the key is a composite objective function: the original one added the artificial variable sum times  large positive multiplier M:\\
\begin{equation}
\text{minimize\;}\mathbf{c^{T}x+M \sum_{i}{u}_{i}}\\
\end{equation}
The simplex code \ref{app:A.1} implemented in this research performs the II phase steps.
 \section{Degenerate steps}
The simplex method may encounter situations in which $d_{r} = \left( A_{B}^{-1}A_{s}\right)_{r} > 0$ but $(A_{B}^{-1}b)_{s}= 0$. At this step, called \textit{degenerate step}, the objective function $c^{T}x$ may not decrease and, after a number of successive degenerate steps, we may return to the original basis $B$. \\
A. Charnes \cite{Lexico2} developed a technique of perturbation, that resulted in a finite simplex algorithm. This algorithm turned out to be equivalent to the lexicographic rule. The \textit{perturbation strategy} avoids this cycling: it consists on adding a small perturbation to the right-hand side of constraints, as follows:
\begin{equation*}
b(\epsilon) \vcentcolon= b + A_{B}
\begin{bmatrix}
\epsilon\\\epsilon^{2}\\\vdots\\\epsilon^{m}
\end{bmatrix}
\end{equation*}
where $\epsilon$ is a very small positive number. This perturbation in the components of the basic solution vector; we have
\begin{equation*}x_{B}(\epsilon) \vcentcolon= x_{B} + A_{B}
\begin{bmatrix}
\epsilon\\\epsilon^{2}\\\vdots\\\epsilon^{m}
\end{bmatrix}
\end{equation*}
Hence, we have that for all $\epsilon$ sufficiently small, $(x_{B^{+}})>0$. The basis is nondegenerate for the perturbed problem and we can perform a step of the simplex method that produces a nonzero decrease of the object value.\\
The question remains of how to choose $\epsilon$ small enough at the point at which the original degenerate basis B is encountered. The \textit{lexicographic strategy} finesses this issue by not making an explicit choice of $\epsilon$, but rather keeping track of the dependence of each basic variable on each power of $\epsilon$. When it comes to selecting the leaving variable, it chooses the index $s$ that minimizes $x_{B}(\epsilon)_{i}/d_{i}$ over all variables in the basis, for a sufficient small $\epsilon$.\\
Another method that avoids this cycling is the \textit{Bland's rule}. In the algorithm it selects:
\begin{itemize}
	\item the index that leaves the nonbasis $s$ such that $\min\limits_{i}\{c_{i}\leq0\}$
\item the index that leaves the basis $r$ such that $\bar{x}_{r} = \min\limits_{q}\{\bar{x}_{q}\;|\;\bar{x}_{q}^{+} \text{\;satisfies the ratio test} \}$ \end{itemize} 
\begin{theorem*}
	The simplex method always terminates provided that both the entering and the leaving variable are chosen according to the Bland's rule.
\end{theorem*}
\begin{proof}
to write ~\cite{LP} pagg. 36-37	
\end{proof}
In the simplex Algorithm \ref{Alg:1} it is implemented the Bland's rule (shown in Appendix \ref{A.1}) and in the following example is illustrated the results:
\begin{ex}
	We apply the method to the Beale's problem (1955): %~\cite{}:
	\begin{alignat*}{4}
	\min -\frac{3}{4}x_{1}&+150x_{2}&-\frac{1}{50}x_{3}&+6x_{4}&\\
	\text{such that\;}\frac{1}{4}x_{1}&-60x_{2}&-\frac{1}{25}x_{3}&+9x_{4}&\leq 0\\
	\frac{1}{2}x_{1}&-90x_{2}&-\frac{1}{50}x_{3}&+3x_{4}&\leq 0\\
	&\;&x_{3}&\;&\leq 1\\
	x&\;&\;&\;&\geq 0\\
	\end{alignat*}
	
Applying Bland's rule, we find optimal solution at $x^{*} = [0.04, 0,  1,   0,  0.03, 0,   0  ]$ in the basis $B = [0, 2, 4]$ after 7 iterations: the optimal cost value is $c^{T}x^{*} = -0.05$.\\

\begin{table}[h]
	\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Iteration} & \textbf{Current basis} & \textbf{Current x} & \textbf{Current value} \\ \hline
		1 & [4, 5, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		2 & [2, 5, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		3 & [0, 1, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		4 & [2, 1, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		5 & [2, 3, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		6 & [2, 3, 0] & [0.016, 0, 1, 0.004, 0, 0, 0] & 0.008 \\ \hline
		7 & [2, 4, 0] & [0.04, 0, 1, 0, 0.03, 0, 0] & -0.05 \\ \hline
	\end{tabular}\caption{Simplex algorithm result with Bland's rule}
\end{center}
\end{table}

Instead without the rule, after 18 iterations the simplex method returns to the same basis sequence, entering in a cycle: the original simplex method repeats the same sequence of six pivots indefinitely, making no progress toward the solution.

\begin{table}[h]
	\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Iteration} & \textbf{Current basis} & \textbf{Current x} & \textbf{Current cost value} \\ \hline
		1 & [4, 5, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		2 & [0, 5, 6] & [0, 0, 0, 0, 0, 0, 1] & 0, \\ \hline
		3 & [0, 1, 6] & [0, 0, 0, 0, 0, 0, 1] & 0, \\ \hline
		4 & [2, 1, 6] & [0, 0, 0, 0, 0, 0, 1] & 0, \\ \hline
		5 & [2, 3, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		6 & [4, 3, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		7 & [4, 5, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		8 & [0, 5, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		9 & [0, 1, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		10 & [2, 1, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		11 & [2, 3, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		12 & [4, 3, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		13 & [4, 5, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		14 & [0, 5, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
		15 & [0, 1, 6] & [0, 0, 0, 0, 0, 0, 1] & 0 \\ \hline
	\end{tabular}\caption{Simplex algorithm result without Bland's rule}
\end{center}
\end{table}
\end{ex} 

 \section{Analysis of the simplex method}
The simplex method, with ever-evolving improvements, has for five decades provided an efficient general
method. \\
 Since the method operates by moving from one basic feasible point
to another without ever returning to a previously visited point, an upper bound
on the number of iterations is the number of basic feasible points.\\Hence, given a LP in standard form with
coefficient matrix and vectors $A\in\mathbb{R}^{n,m}, b\in\mathbb{R}^{n}$ and $c\in\mathbb{R}^{m}$, it computes at most $m\choose n$ iterations.\\
The number of pivot steps to solve
the problem starting from a basic feasible solution is typically a small multiple of
$m$: usually between $2m$ and $3m$. At one time researchers believed (and attempted to prove) that the simplex
algorithm always requires a number of iterations that is
bounded by a polynomial expression in the problem size. In fact, Dantzig observed that for problems with
$m \leq 50$ and $n \leq 200$ the number of iterations is ordinarily less than $\frac{3}{2}m$ \cite{DAN}.
\\ However, in 1972, Victor Klee and George Minty exhibited a class of linear programs each of which requires an
exponential number in the size of the problem of iterations when solved by the simplex method.\\
One form of the Klee–Minty example is the following whose feasible polytope has $2^{n}$
vertices:
\begin{alignat*}{4}
\max &\sum_{j=1}^{n}10^{n-j}x_{j}&&&\\
\text{subject to\;}&2\sum_{j=1}^{i-1}10^{i-j}x_{j}+&x_{i}&\leq 100^{i-1}, \, &i = 1,\dots, n;\\
&&x_{j}&\geq 0, \,&j = 1,\dots, n.\\
\end{alignat*}
A specific case is that for $n = 3$, giving:
\begin{alignat*}{2}
\text{minimize\;}\; 100& x_1+10x_2+ x_3&&\\[2mm]
\text{subject\;to\;\;\;\;} &x_1+&&\leq 1\\
						20& x_1+x_2&&\leq 100\\
200 &x_1 +20x_2 +x_{3}&&\leq 10000\\
\text{and}\;& x_1\geq 0,x_2\geq 0,x_3&&\geq 0.
\end{alignat*}
with 3 constraints and 3 variables (along with their nonnegativity constraints).\\
The Python implementation solves the problem in $2^{3} - 1 = 7$ pivot steps without the Bland's rule: this confirms that the general problem requires $2^{n}- 1$ iterations and this is in fact
the number of vertices minus $1$.\cite{MINTY}\\ It is illustrated also the result obtained applying the simplex method with the Bland's rule, in this case the number of iterations is only $5$.  \\

\begin{table}[h]
	\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Iteration} & \textbf{Current basis} & \textbf{Current x} & \textbf{Current cost value} \\ \hline
		0 & [3, 4, 5] & [0, 0, 0, 1, 100, 10000] & 0 \\ \hline
		1 & [0, 4, 5] & [1, 0, 0, 0, 80, 9800] & -100 \\ \hline
		2 & [0, 1, 5] & [1, 80, 0, 0, 0, 8200] & -900 \\ \hline
		3 & [3, 1, 5] & [0, 100, 0, 1, 0, 8000] & -1000 \\ \hline
		4 & [0, 1, 5] & [0, 100, 8000, 1, 0, 0] & -9000 \\ \hline
		5 & [0, 1, 2] & [1, 80, 8200, 0, 0, 0] & -9100 \\ \hline
		6 & [0, 4, 2] & [1, 0, 9800, 0, 80, 0] & -9900 \\ \hline
		7 & [3, 4, 2] & [0, 0, 10000, 1, 100, 0] & -10000 \\ \hline
	\end{tabular}
\end{center}
\end{table}

\begin{table}[h]
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
			\hline
			\textbf{Iteration} & \textbf{Current basis} & \textbf{Current x} & \textbf{Current cost value} \\ \hline
			0 & [3, 4, 5] & [0, 0, 0, 1, 100, 10000] & 0 \\ \hline
			1 & [0, 4, 5] & [1, 0, 0, 0, 80, 9800] & -100 \\ \hline
			2 & [0, 1, 5] & [1, 80, 0, 0, 0, 8200] & -900 \\ \hline
			3 & [0, 1, 2] & [1, 80, 8200, 0, 0, 0] & -9100 \\ \hline
			4 & [0, 4, 2] & [1, 0, 9800, 0, 80, 0] & -9900 \\ \hline
			5 & [3, 4, 2] & [0, 0, 10000, 1, 100, 0] & -10000 \\ \hline
		\end{tabular}
	\end{center}
\end{table}

It has to be said, however, that it is only a theoretical drawback and in practice it is rather exceptional for the simplex method to perform more than $m + n$ iterations on its way to an optimal solution \cite{ComTeq}.
%Leke~\cite{Lem} developed the dual simplex method in 1954 but it was not found to be an alternative to the primal simplex method for nearly 40 years. This changed in due to the contributions of Forrest and Goldfarb.After discussing the Karush-Kuhn-Tucker optimalityconditions for linear programming, we derive the \textit{dual simplex method} by applying the simplex method to the dual formulation of the standard 
%form LP. 
\\


\chapter{Interior point methods}
In the 60 years of research since the introduction of the simplex method, this algorithm has been carefully optimized to perform extremely well in practice. However, a problem arose in the 1970s: it turns out that we cannot guarantee that it will work well on all possible linear programs ~\cite{3}.
In fact, the Klee and Minty's example confirms that the simplex method may need an exponential number of iterations to find the optimal solution of a LP. \\
This problem led to the introduction of the interior point methods for solving LP, which is the argument of this chapter.\\
The interior point methods is a family of algorithms solving linear programs which come along with an efficient performance guarantee. They share common features that distinguish them from the simplex method: each interior point iteration is expensive to compute but can make significant progress toward the solution, while the simplex method usually requires a larger number of inexpensive iterations. Geometrically, the simplex method works around the boundary of the feasible polytope, testing a sequence of vertices in turn until it finds the optimal one. Instead, interior point methods approach the boundary of the feasible set only in the region, but they never actually lie on the boundary of the feasible set.\\
Although the fundamentals of interior-point methods had been established several years
before, Leonid Khachiyan (in 1979) and then Narendra Karmarkar (in 1984) proposed their algorithms for solving linear programs \cite{WWW}. It is true that Khachiyan’s ellipsoid algorithm was the first algorithm for LP to be actually proven to
be theoretically efficient, but in comparison to it, the simplex method was clearly superior on average and, in particular, on essentially any practical
problem that would occur in a real-life context. The state changed when N. Karmarkar introduced the new interior-point algorithms \cite{Kar}; both efficient in theory and practice, nowadays are widely considered the first commercial interior-point
method for linear programming.\\
%The new algorithms can be divided in two main classes, \textit{affine-scaling} and \textit{projective-scaling} algorithms.
%The first ones are easy to describe but hard to analyze, in fact they have very simple, geometrically descriptions, but they don't have a strong convergence theory behind.
%Instead, the second class, that includes the original algorithm studied by Karmakar, involves technicalities such as logarithmic barrier functions and the analysis proceeds to a proof of polynomial-time convergence~\cite{4}.
By the early 1990s, a subclass of IPMs called \textit{primal-dual methods} had distinguished themselves as the most efficient practical approaches. The primal-dual interior point algorithm was introduced by Megiddo \cite{meg} who used logarithmic barrier methods to solve
the primal and dual problems simultaneously. An efficient
high-order primal-dual method was proposed by Mehrotra \cite{MER}: with his  predictor-corrector
strategy, is among the most efficient IPM and has became the back bones
of several optimization packages \cite{matlab}.\\ 
After a brief introduction of the primal-dual methods, we study three important algorithms: the \textit{primal-dual affine scaling}, the \textit{long-path following} and the \textit{Mehrotra predictor-corrector} methods.\\
TO CHECK!!
An overview of the details of the first two interior-point algorithms are given in the following chapter, instead no convergence theory is availabe for the third one. \\
In this research is proposed a new long-path following algorithm labeled as \textit{predictor-corrector long-path following algorithm}, based on a new centering parameter computation. With practical implementations a comparison will be discussed.
%The lack of theoretical analysis of the Mehrotra's algorithm leads to a study  their reliability both in theory and in practice will be shown 
%The great success of Mehrotra's approach in practice warrants further theoretical studies
%on its convergence properties, particularly its computational complexity, which have so far
%not been well understood due to its more complicated algorithmic form. In [3], Mehrotra
%described a few potential functions along with a 'fall-back' search direction. 

\newpage
\section{Introduction to primal-dual methods}
We consider the LP problem formulated in a standard form. \\
Following a fundamentally different approach from the simplex method, IPM avoid the boundary of the polytope until optimality and focus on the KKT conditions, solving the primal and dual LP currently.\\
\\
\\
The primal-dual methods find primal-dual solutions $(x^{*},\lambda^{*},s^{*})$ by applying variants of Newton's search direction method to the three optimatility conditions (\ref{DF}), (\ref{PF}), (\ref{CC}) and modifying the search directions and the step lengths so that the inequality $(x,s)>0$ is satisfied.\\

 Let restate the optimality conditions by a mapping $\mathit{F}$ from $\mathbb{R}^{2n+m}$ to $\mathbb{R}^{2n+m}$:
\begin{center}\label{F}
	$\mathit{F}(x,\lambda,s)= \begin{bmatrix}
	A^{T}\lambda+s-c \\Ax-b \\XSe
	\end{bmatrix}=0$, with $(x,s)\geq0,$
\end{center}
where $X = diag(x_{1}, x_{2},...,x_{n})$ and $S = diag(s_{1}, s_{2},...,s_{n})$.\\
Note that $\mathit{F}$ is linear in the first two equations and mildly nonlinear in the last equation. 
The general IPM algorithm generates iterates $(x^{k},\lambda^{k},s^{k})$ with the following properties:
\begin{itemize}
	\item $x^{k}$ and $s^{k}$ are nonnegative and strictly positive at each iteration (this requisite leads to the term \textit{interior point});
	\item the 2-norm of the residuals $r_{b}^{k} = b - Ax^{k}$ and $r_{c}^{k} =c - A^{T}\lambda^{k} -s^{k}$ decrease at each iteration;
	\item the duality measure $\mu_{k} = \frac{x^{T}_{k}s_{k}}{n}$ decreases at each iteration;
	\item the next iterate $(x^{k+1},\lambda^{k+1},s^{k+1})$ is computed by an increment of a modified Newton's direction.
\end{itemize}
If we define the primal-dual \textit{feasible set} $\mathcal{F}$ and \textit{strictly feasible set} $\mathcal{F}^{0}$ by
\begin{align*}
\mathcal{F} = \left\lbrace(x,\lambda,s)\;|\;Ax = b, A^{T}\lambda+s =c,\;(x,s)\geq0\right\rbrace, \\
\mathcal{F}^{0} = \left\lbrace(x,\lambda,s)\;|\;Ax = b, A^{T}\lambda+s =c,\;(x,s)>0\right\rbrace, 
\end{align*}
the strict feasibility condition can be written concisely as $(x,\lambda,s)\in\mathcal{F}^{0}$.\\
However, some LP have \textit{no} strictly feasible points, that is $\mathcal{F}^{o}=\emptyset$, although hey still may be feasible $(\mathcal{F}=0)$ and still may have finite optimal solutions, as we see in this example.
\begin{ex}
	\begin{equation*}
	\min\limits_{x\in\mathbb{R}^{3}} x_{1} \text{ subject to }x_{1} + x_{3} = 0, x\geq0.
	\end{equation*}

and its dual is 
	\begin{equation*}
\max\limits_{\lambda\in\mathbb{R}^{3}, s\in\mathbb{R}^{3}} 0 \text{ subject to } \begin{bmatrix}1\\0\\1\end{bmatrix}\lambda+\begin{bmatrix}
s_{1}\\s_{2}\\s_{3}
\end{bmatrix}=\begin{bmatrix}1\\0\\0\end{bmatrix}, s\geq0 
\end{equation*}
Any feasible primal-dual vector $(x, \lambda, s)\in\mathcal{F}$ has $x_{1}= x_{2}= s_{2}= 0$, so $\mathcal{F}^{0}=\emptyset$. The optimal objective function value for this problem is 0, and the primal-dual solutionn set is defined by
\begin{center}
$x^{*} = \begin{bmatrix}
0\\x^{*}_{2}\\ 0
\end{bmatrix}$ and $s^{*}=\begin{bmatrix}
1-\lambda^{*}\\0\\-\lambda^{*}
\end{bmatrix}$,  
\end{center}
where $x^{*}$ and $\lambda^{*}$ are any numberes for which $x_{2}^{*}\geq0$ and $\lambda^{*}\leq0$.
\end{ex}
\\
The Newton's method (see Appendix) forms a linear model for $\mathit{F}$ around the current point and obtains the search direction $(\Delta x,\Delta \lambda,\Delta s)$ by solving the following system of linear equations:
\begin{center}
	$\mathit{J}(x,\lambda,s)\begin{bmatrix}
	\Delta x\\\Delta\lambda \\\Delta s
	\end{bmatrix}=-\mathit{F}(x,\lambda,s)$,
\end{center}
where $\mathit{J}$ is the Jacobian of the linear mapping $\mathit{F}$. If the current point $(x, \lambda, s)\notin\mathcal{F}$, the Newton step equations becomes

\begin{equation}\label{(5.1)}
	\begin{bmatrix}
0&A^{T}&I \\A&0&0\\S&0&X
	\end{bmatrix}\begin{bmatrix}
	\Delta x\\\Delta\lambda \\\Delta s
	\end{bmatrix}=\begin{bmatrix}
	c-A^{T}\lambda-s\\b-Ax\\XSe
	\end{bmatrix}.
\end{equation}

A full step along this direction usually is not permissible, since it would violate the bound $(x,s)>0$. To avoid this difficulty, we perform a line search along the Newton direction so that the new iterate is
\begin{equation*}
	(x,\lambda,s) +\alpha (\Delta x,\Delta \lambda,\Delta s)
\end{equation*} 
for some line search parameter $\alpha \in (0,1]$. \\We maintain positivity conditions of $(x,s)$ at all iterates for two reasons. First, vectors that solve $\mathit{F}$ that have negative components are of no interest in terms of solving the primal and dual problems (P) and (\ref{(Dual)}). Second, when the matrix $A$ has linearly indipendent rows, the Jacobian $J$ is guaranteed to be nonsingular whenever $x>0$ and $s>0$ hold, and so the solution is guaranteed.

\section{Primal-dual affine-scaling method}

The simplest primal-dual approach is to apply Newton's method directly to the nonlinear system $F$ using in the $k^{th}$ iteration a step length $\alpha_{k}<1$ in order to guarantee $(x^{k+1},\lambda^{k+1},s^{k+1})\in \mathcal{F}^{0}$.\\ There are different ways to do this and the resulting algorithms are called \textit{Primal-dual affine-scaling methods}, for short Affine-scaling methods, which were proposed for linear programming by Monteiro,
Adler and Resende \cite{MARE}.\\ 
 The general primal-dual affine-scaling algorithm takes the following form:\\
\begin{algorithm}[H]
\begin{tabbing}
	\\
	\textbf{Given} $(x^{0}, \lambda^{0}, s^{0})$ with $(x^{0}, s^{0})>0$;\\
	\textbf{for} \= $k = 0, 1, 2,...$ \\
	\> solve
\begin{equation*}
\begin{bmatrix}
0&A^{T}&I \\A& 0&0\\X^{k}&0&S^{k}
\end{bmatrix}\begin{bmatrix}
\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
\end{bmatrix}=-\begin{bmatrix}
-r_{c}^{k}\\-r_{b}^{k}\\X^{k}S^{k}e
\end{bmatrix};
\end{equation*}
\\
	\\
	\>\textbf{set} \=$(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$
	\\
	\>\> with $\alpha_{k}$ such that $(x^{k+1}, s^{k+1})>0$; \\
	\textbf{end}
\end{tabbing}
\caption{\label{alg:AS}Primal-dual affine-scaling algorithm}
\end{algorithm}

The solution of this system $\left(\Delta x^{k},\Delta\lambda^{k},\Delta s^{k}\right)$ has either $\Delta x_{i}^{k}<0$ or $\Delta s_{i}^{k}<0$, or both because $x^{k}>0$ and $s^{k}>0$ and $s^{k}_{i}\Delta x^{k}_{i} + x^{k}_{i}\Delta s^{k}_{i} = - x^{k}_{i}s^{k}_{i}$, by the last block row of this system.
Then, we need to choose $\alpha_{k}$ such that
\begin{align*}
x^{k}_{i} + \alpha_{k} \Delta x^{k}_{i} >0, \\
s^{k}_{i} + \alpha_{k} \Delta s^{k}_{i} >0,	
\end{align*}
$\text{for\;} i = 1,...,n,$ and the largest value of $\alpha_{k}$ that satisfies these inequalities is computed by the following formula, which is similar to the ratio test used by the simplex method. 
\begin{align*}
\alpha_{\text{max}} = \min\bigg(\min_{i|\Delta x^{k}_{i}<0}\frac{x^{k}_{i}}{\Delta x^{k}_{i}}, \min_{i|\Delta s^{k}_{i}<0}\frac{s^{k}_{i}}{\Delta s^{k}_{i}}\bigg)
\end{align*} 

We can step back from this maximum value, and prevent each $x_{i}$ and $s_{i}$ from being too close to zero, by defining $\alpha_{k} = \min\left(1,\eta_{k}*\alpha_{max}\right)$, with $\eta_{k}$ usually $0.999$.\\
This approach is called \textit{primal-dual affine scaling} and often does not allow us to make much progress toward a solution. 
Even though, the search direction steps are used to find the predictor directions in the predictor-corrector algorithms, explained in the Chapter ().
\subsection{Affine-scaling convergence}
We examine the asymptotic behavior of this method, that is of significant theoretical interest: we assume that $(x, \lambda, s)\in\mathcal{F}^{0}$, hence, the affine-scaling direction $(\Delta x, \Delta \lambda, \Delta s)$ satisfies the following matricial system:\\
\begin{equation}\label{5.1}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\S&0&X
\end{bmatrix}\begin{bmatrix}
\Delta x\\\Delta\lambda \\\Delta s
\end{bmatrix}=-\begin{bmatrix}
0\\0\\XSe
\end{bmatrix},
\end{equation}\\
with residuals $r_{b}$ and $r_{c}$ equal to 0.\\
More precisely we assume that $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$.
\begin{lem}
	Suppose that $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$ and that the affine-scaling direction $(\Delta x,\Delta \lambda, \Delta s)$ is calculated. Then there is a costant $C$ such that
	\begin{equation*}
	\lVert \Delta x_{\mathcal{B}} \rVert \leq C \mu \text{\;and\;} \lVert \Delta s_\mathcal{B} \rVert \leq C \mu,
	\end{equation*}
	with the set $\mathcal{B}$ defined previously in $\ref{index}$. 
\end{lem}
\begin{proof}
	Let us define the positive diagonal matrix $D = X^{1/2}S^{-1/2}$. Multiplying the last block row of \ref{5.1} by $(XS)^{-1/2}$, we obtain 
	\begin{equation*}
	D^{-1}\Delta x + D \Delta s = -(XS)^{1/2}e.
	\end{equation*}
	Taking inner products of both sides of this expression, we have
	\begin{equation*}
	\lVert D^{-1}\Delta x \rVert^{2} + 2\Delta x^{T}\Delta s+ \lVert D\Delta s \rVert^{2}= \lVert(XS)^{1/2}e\rVert^{2}= x^{T}s= n\mu.
	\end{equation*}
	Because $\Delta x^{T}\Delta s= 0$ and the other two terms are positive, we can write
	\begin{equation*}
	\lVert D^{-1}\Delta x\rVert^{2}\leq n\mu, \;\;\lVert D\Delta s\rVert^{2}\leq n\mu.
	\end{equation*}
	Since $D_{i,i}= \sqrt{x_{i}/s_{i}}$ for any $i$, we have that
	\begin{equation*}
	\frac{s_{i}}{x_{i}}(\Delta x_{i})^{2}\leq\lVert D^{-1}\Delta x\rVert^{2}\leq n\mu.
	\end{equation*}
	Hence, choosing $i\in\mathcal{N}$ and using $x_{i}s_{i}\geq\gamma\mu$, we find
	\begin{equation*}
	(\Delta x_{i})^{2}\leq\frac{n\mu x_{i}}{s_{i}}=\frac{n\mu x_{i}^{2}}{x_{i}s_{i}}\leq\frac{n\mu^{3}}{\gamma\mu C^{2}}\mu^{2}.
	\end{equation*}
	Therefore, we have 
	\begin{equation*}
	\lVert \Delta x_{\mathcal{N}}\rVert \leq \sqrt{n}\max\limits_{i \in \mathcal{N}}|\Delta x_{i}|\leq\frac{n}{\gamma^{1/2}C}\mu.
	\end{equation*}
	To argument for $\lVert \Delta s_{\mathcal{B}}\rVert$ is identical.
\end{proof}
Now we show that $\lVert \Delta x_{\mathcal{B}}\rVert$ and $\lVert \Delta s_{\mathcal{N}}\rVert$ are also $\mathcal{O}(\mu)$ by using the following two technical lemmas and an important theorem.
\begin{lem} \label{(T)}
	Let the matrix $H\in\mathbb{R}^{p,q}$ be given. Then there exists a nonnegative constant $\bar{C}$ depending only on $H$ with the following property: for any vector $h\in Range(H)$ and any nonsingular diagonal matrix $\Sigma$, the unique solution $\bar{w}$ of the problem
	\begin{align*}
	\min\limits_{w}\frac{1}{2}\lVert\Sigma w\rVert^{2} \text{\;subject to\;} Hw = h
	\end{align*}
	satisfies $\lVert\bar{w}\rVert\leq \bar{C}\lVert h\rVert$.
\end{lem}
The next lemma is due essentially to Adler and Montiero \cite{ADL}. $A_{\mathcal{B}}$,  Let us denote $A_{\mathcal{N}}$, $D_{\mathcal{B}}$ and $D_{\mathcal{N}}$ a column partition of the matrices $A$ and $D$, according to the sets $\mathcal{B}$ and $\mathcal{N}$, respectively.
\begin{lem}
	Suppose that the assumption of the Lemma \ref{(T)} hold. Then
	\begin{enumerate}
		\item $u = \Delta x_{B}$ is the unique solution of the following convex quadratic problem
		\begin{align} \label{(U)}
		\min\limits_{u}\frac{1}{2}\lVert D_{\mathcal{B}}^{-1}u\rVert^{2} \text{subject to }A_{\mathcal{B}}u = -A_{\mathcal{N}}\Delta x_{\mathcal{N}};
		\end{align}
		\item $(v, \pi) = (\Delta s_{N}, \Delta \lambda)$ is a solution of the convex quadratic problem
		\begin{align}
		\min\limits_{(v, \pi)}\frac{1}{2}\lVert D_{\mathcal{N}}v\rVert^{2} \text{ subject to } &A_{\mathcal{B}u} = -A_{\mathcal{N}}\Delta x_{\mathcal{N}},\label{44}\\
		&A_{\mathcal{N}^{T}\pi}+ v =0.\label{45}		 
		\end{align}
		The $\Delta s_{\mathcal{N}}$ component is unique.
	\end{enumerate} 
\end{lem} 
\begin{proof}
	\textit{1}. From KKT conditions, we say that $\Delta x_{\mathcal{B}}$ is a solution if there exists a vector $\hat{\pi}$ such that
	\begin{align*}
	D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}}-A_{\mathcal{B}}^{T}\hat{\pi}&= 0,\\
	A_{\mathcal{B}}\Delta x_{B}&= -A_{\mathcal{N}}\Delta x_{\mathcal{N}}
	\end{align*}
	The second equation is satisfied from the second row of (\ref{5.1}). Combining the first and the third block rows in (\ref{5.1}), for the indices $\mathcal{B}$ we have:
	\begin{equation*}
	-D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}} + A_{\mathcal{B}}^{T}\Delta \lambda = s_{\mathcal{B}}
	\end{equation*}
	Since $(x, \lambda, s)$ is feasible, we have $s_{\mathcal{B}}= -A_{\mathcal{B}}^{T}\lambda+ c_{\mathcal{B}}$, whereas for any solution $(x^{*}, \lambda^{*}, s^{*})$, we have $c_{\mathcal{B}}= A_{\mathcal{B}^{T}\lambda^{*}}$. Then, we obtain
	\begin{equation*}
	-D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}} + A_{\mathcal{B}}^{T}\Delta \lambda = -A_{\mathcal{B}}^{T}\lambda+ c_{\mathcal{B}} = -A_{\mathcal{B}}^{T}(\lambda - \lambda^{*}). 
	\end{equation*}
	If we set $\hat{\pi} = \lambda + \Delta\lambda + \lambda^{*}$, then also the first KKT condition holds.\newline
	\textit{2.} We recall again the KKT conditions and $(v,\pi)=(\Delta s_{N},\Delta\lambda)$ is a solution if there exist vectors $\hat{u}_{\mathcal{B}}$ and $\hat{u}_{\mathcal{N}}$ such that
	\begin{align*}
	D_{\mathcal{N}}^{2}\Delta s_{N}-\hat{u}_{N}&=0,\\
	-A_{\mathcal{B}}^{T}\hat{u}_{\mathcal{B}}-A_{\mathcal{N}}^{T}\hat{u}_{N}&=0,\\
	A_{\mathcal{B}}^{T}\Delta \lambda &= -\Delta s_{\mathcal{B}},\\
	A_{\mathcal{N}}^{T}\Delta\lambda + \Delta s_{\mathcal{N}} &=0. 
	\end{align*}
	The last two equations follow immediately from the first block row of (\ref{5.1}).\\
	Then, it is easy to show that the choices $\hat{u}_{N}= x_{\mathcal{N}}+\Delta x_{\mathcal{N}}$ and $\hat{u}_{\mathcal{B}}=x_{\mathcal{B}}+\Delta x_{\mathcal{B}}-x_{\mathcal{B}}^{*}$, satisfy the first and the second equations, where $x^{*}$ is the primal solution.\\
	Now we prove the uniqueness of the $\Delta s_{\mathcal{B}}$.\\
	If we multiply (\ref{44}) by $A_{\mathcal{B}}$ and (\ref{45}) by $A_{\mathcal{N}}$ and add, then we obtain
	\begin{equation*}
	(A_{\mathcal{B}}A_{\mathcal{B}}^{T}+A_{\mathcal{N}}A_{\mathcal{N}}^{T})\pi+A_{\mathcal{N}}v = AA^{T}\pi+A_{\mathcal{N}}v = -A_{\mathcal{B}}\Delta s_{\mathcal{B}}.
	\end{equation*} 
	Since A has full rank for hypothesis, we can write
	\begin{equation*}
	\pi = -(AA^{T})^{-1}(A_{\mathcal{N}}v +A_{\mathcal{B}}\Delta s_{\mathcal{B}}),
	\end{equation*}
	so the minimization problem can be formulated as
	\begin{equation}\label{(V)}
	\min\limits_{v}\frac{1}{2}\lVert D_{\mathcal{N}}v\rVert^{2} \text{ subject to }
	(I-A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{N}})v =A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\Delta s_{\mathcal{B}}.		 
	\end{equation}
	Since this problem  has strictly convex objective, the solution $v=\Delta s_{\mathcal{N}}$ is unique. To conclude, we can recover $\Delta \lambda=\pi$ as defined above. 
\end{proof}
\begin{thm}\label{(Z)}
	Given $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$ and $(\Delta x,\Delta \lambda, \Delta s)$ computed in (\ref{5.1}), there is a constant K such that
	\begin{equation*}
	\lVert (\Delta x, \Delta s)\rVert \leq K \mu.
	\end{equation*}
\end{thm}
\begin{proof}
	Since the diagonal of $D_{\mathcal{B}}$ is strictly positive, we can apply the lemma~\ref{(T)} directly to the convex quadratic problem~\ref{(U)}. Hence, there is a constant $\bar{C}$ depending on $A_{\mathcal{B}}$ such that
	\begin{equation}
	\lVert \Delta x_{\mathcal{B}}\rVert \leq \bar{C}\lVert A_{\mathcal{N}}\Delta x_{\mathcal{N}}\rVert\leq \bar{C}\lVert A_{\mathcal{N}}\rVert C\mu,
	\end{equation}
	Similarly, from(~\ref{(V)}), there is a constant $\bar{K}$ depending on $A$ such that
	\begin{equation}
	\lVert \Delta s_{\mathcal{N}}\rVert \leq \bar{K}\lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert\lVert \Delta s_{\mathcal{B}}\rVert \leq\bar{K} \lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert C\mu,
	\end{equation}
	The result follows when we define K$\;=\bar{K} \lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert C$.
\end{proof}
A result similar to Theorem~\ref{(Z)} holds for steps of an IPM algorithm \cite{Wright}.\\ The implementation realized in this research computes the infeasible with two heuristic techniques, which we depict later.\\
Most primal-dual methods use less aggressive Newton search direction, making a perturbation of the system $F$ and they are presented in the next section.

\section{Long path-following methods}

Another method for solving a linear program is to follow a central path from a given initial primal-dual solution point.\\ Assuming $\mathcal{F}^{0}\neq \varnothing$, the \textit{central path} $\mathcal{C}$ is an arc of strictly feasible points that play an important role in the following primal-dual algorithm. It is parametrized by a scalar $\tau  > 0$ and each point $(x_{\tau}, \lambda_{\tau}, s_{\tau})\in \mathcal{C}$ satisfies the following equations:
\begin{align}
A^{T}\lambda+s&=c\tag{4.3a}\\
Ax&=b\tag{4.3b}\\\label{KKT2}
x&\geq 0\tag{4.3c}\\
s&\geq 0\tag{4.3d}\\
x_{i}s_{i}&= \tau,\; \text{for}\;i= 1,2,...,n.\tag{4.3e}\label{(Tao)}
\end{align} 
The conditions (4.3) are also the optimality conditions for the following \textit{logarithmic-barrier formulation} (P$_{\tau}$) of the original problem (P):
\begin{equation}\label{log}
\begin{split}
\text{minimize\;} &c^{T}x + \tau\sum_{i=0}^{n}\ln{x_{i}}\\
\text{subject\; to\;}&Ax = b\;\text{and\;} x\geq0
\end{split}
\end{equation}
In fact, the KKT conditions associated to this problem, with Lagrange multiplier $\lambda$ for the equality constraint, are
\begin{equation*}
c_{i} - \dfrac{\tau}{x_{i}} - A^{T}_{i}\lambda,\; \text{for}\;i = 1,2,...,n.
\end{equation*}  
Since the objective function is strictly convex, these conditions are sufficient as well as necessary for optimality; besides, defining $s_{i} = \dfrac{\tau}{x_{i}}$, we recover (\ref{(Tao)}): it requires that the pairwise products $x_{i}s_{i}$ have the same value for all indices $i$.\\[0.5cm]
Now we see the relation between the (P$_{\tau}$) and (P) with the following result.
\begin{prop}
	Assume that the set $\mathcal{P}^{o} = \mathcal{P}\cap\{x\in\mathbb{R}^{n}| x> 0\}$ is non-empty and let $\tau>0$ be given. Then problem (P$_{\tau}$) has an optimal solution if and only if the set of optimal solutions of (P) is non-empty and bounded.
\end{prop}
A proof of the proposition can be found in \cite{meg}. From this result, we immediately conclude that if (P$_{\tau}$) has a solution for some $\tau>0$ then it has a solution for all $\tau>0$.
\begin{prop}
	Assume that problem (P) is feasible. Then the set of optimal solutions of (P) is non-empty and bounded if and only if $\mathcal{D}^{0} = \mathcal{D}\cap\{x\in\mathbb{R}^{n}| s> 0\}$  is non-empty.
\end{prop}
The proof is an application of duality theory for linear programming. As a consequence of the two previous propositions, we have the following corollary.
\begin{cor}
If the sets $\mathcal{P}^{0}$ and $\mathcal{D}^{0}$ are non-empty, then the problem (P$_{\tau}$) (and consequently the relative KKT conditions) has a unique solution $(x(\tau),\lambda(\tau),s(\tau))$, for all $\tau>0$. 
\end{cor}
Let $(x(\tau), \lambda(\tau), s(\tau))$ be on the primal-dual path $\mathcal{C}$, then the non negative duality gap assumes this value: $g = c^{T}x-b^{T}\lambda=\left(c-A^{T}\lambda\right)^{T}x=s^{T}x=\tau$.\\
It means that $g$ provides a measure of closeness to optimality. It is clear that as $\tau\to0$ the duality gap goes to zero, and hence both $x(\tau)$ and
 $(\lambda(\tau), s(\tau))$ approach to the common optimal values of the roblems (P) and (D) respectively. The central path guides us to a solution along a route that maintains positivity of the $x$ and $s$ components and decreases the pairwise products $x_{i}s_{i},\;i = 1,2,...,n$ to zero at the same rate.\\
 
 
 Defining $\mathcal{C}$ with the notation introduced in the first section, we have the following mapping $\mathit{F}$:
 \begin{center}
 	$\mathit{F}(x,\lambda,s)= \begin{bmatrix}
 	A^{T}\lambda+s-c \\Ax-b \\XSe
 	\end{bmatrix}=\begin{bmatrix} 0\\0\\ \tau e \end{bmatrix}$, with $(x,s)\geq0$.
 \end{center}
Then, Newton steps toward points on $\mathcal{C}$ are computed as following:
 \begin{equation}\label{new}
 \begin{bmatrix}
 0&A^{T}&I \\A&0&0\\S&0&X
 \end{bmatrix}\begin{bmatrix}
 \Delta x\\\Delta\lambda \\\Delta s
 \end{bmatrix}=\begin{bmatrix}
 0\\0\\-XSe + \tau e
 \end{bmatrix}.
 \end{equation}
 Path-following methods follow $\mathcal{C}$ in the direction of decreasing $\tau$ to the solution set but they do not necessarily stay exactly on $\mathcal{C}$ or even particularly close to it. In fact they compute the target value $\tau = \sigma \mu$, where $\sigma = [0,1]$ is called \textit{centering parameter} and $\mu$ the \textit{duality measure}, defined by
 \begin{equation*}
 \mu = \frac{1}{n}\sum_{i=1}^{n} x_{i}s_{i} = \frac{x^{T}s}{n}.
 \end{equation*}\\
 The perturbation $\sigma\mu$ guarantees progress in reducing the duality gap $g = x^{T}s$,
 in this way path-following interior point algorithms attempt to reduce the term from
 its current value $\mu$ to a new one $\sigma\mu$. In fact, if we state the last equation of \ref{new} in vectorial form, we have:
 \begin{equation}
 S\Delta x + X\Delta s = s^{T}\Delta x + x^{T}\Delta s = - XSe + \sigma \mu e = (-1 + \sigma)x^{T}s
 \end{equation}
 and provides the necessary term to estimate the progress of the
 algorithm.\\  
 \\
 A path-following algorithm explicity restricts the iterates to a neighborhood of the central path $\mathcal{C}$: if $\sigma = 1$, the equations define a \textit{centering direction}, a Newton step toward the point $(x_{\sigma\mu},\lambda_{\sigma\mu}, s_{\sigma\mu})\in\mathcal{C}$, if $\sigma = 0$, then we have the \textit{affine-scaling method}.\\  
 Many algorithms use intermediate values of $\sigma$ in $(0,1)$ to trade off between the twin goals of reducing $\mu$ and improving centrality. A neighborhood of $\mathcal{C}$ excludes points $(x, s) $ that are too close to the boundary of the nonegative hyperplane. Therefore, search directions calculated from any point in the neighborhood make at least minimal progress toward the solution set.
 We define the two most interesting neighborhoods of the central path as given
by Mizuno et al.~\cite{5}:\\
\begin{equation*}
\mathcal{N}_{2}(\theta) =\{(x, \lambda,s)\in\mathcal{F}^{0} \;|\;\lVert XSe - \mu e \rVert \leq \theta \mu \}, \text{\;for some\;} \theta \in [0,1),
\end{equation*} 
\begin{equation*}
\mathcal{N}_{-\infty}(\gamma) =\{ (x, \lambda,s)\in\mathcal{F}^{0} \;|\; x_{i}s_{i} \geq \gamma \mu \}, \text{\;for some\;} \gamma \in [0,1).
\end{equation*} 
A disadvantage of the $\mathcal{N}_{2}(\theta)$ neighborhood is its restrictive nature \cite{W}: from the definition above, we have for $(x, \lambda,s)\in\mathcal{N}_{2}(\theta)$ that
\begin{center}
	$\sum\limits_{i=1}^{n}\big(\frac{x_{i}s_{i}}{\mu}-1\big)^{2}\leq \theta^{2}<1$,
\end{center} 
so that the sum of squares of all relative deviations of $x_{i}s_{i}$ from their average value $\mu$ cannot exceed 1. Even if $\theta$ is close to its upper bound of 1, the neighborhood $\mathcal{N}_{2}(\theta)$ contains only a small fraction of the points in the strictly feasible set $\mathcal{F}^{0}$. The neighborhood $\mathcal{N}_{-\infty}(\gamma)$, on the other hand, is much more expansive: when $\gamma$ is small, it takes up almost the entire strictly positive feasible set $\mathcal{F}^{0}$. 

\subsection*{LPF methods}
In this research we discuss the \textit{long-step path-following algorithms}, that are based on the second neighborhood. Since  $\mathcal{N}_{-\infty}(\gamma)$ is a larger central path neighborhood, it allows for more flexibility in the choice of the next iterate and hence larger  step length (hence, the name long-step method). It depends on two parameters $\sigma_{min}$, $\sigma_{max}$, which are lower and upper bounds on the centering parameter $\sigma_{k}$. After computed the search direction with the Newton method, the step length $\alpha_{k}$ is chosed as the maximum value subject to staying inside $\mathcal{N}_{-\infty}(\gamma)$.
The general path-following algorithm is:
\begin{algorithm}[H]
	\begin{tabbing}
		\\
		\textbf{Given  }\= $\gamma\in(0,1)$, $\sigma_{\text{min}}$, $\sigma_{\text{max}}$, with $0<\sigma_{\text{min}}< \sigma_{\text{max}}<1$,\\
		\> and $(x^{0}, \lambda^{0}, s^{0})\in\mathcal{N}_{-\infty}(\gamma)$;\\
		\textbf{for} \= $k = 0, 1, 2,...$ \\
		\> let $\sigma_{k}\in[\sigma_{\text{min}},\sigma_{\text{max}}]$ and solve
	\end{tabbing}
	\begin{equation}\label{Pb}
	\begin{bmatrix}
	0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
	\end{bmatrix}\begin{bmatrix}
	\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
	\end{bmatrix}=-\begin{bmatrix}
	A^{T}y^{k}+s^{k}-c\\Ax^{k}-b\\-X^{k}S^{k}e + \sigma_{k}\mu_{k}e
	\end{bmatrix};
	\end{equation}
	\begin{tabbing}
		\\
		$\;\;\;\;\;$\=choose the largest $\alpha_{k}\in[0,1]$ so that $(x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})\in\mathcal{N}_{-\infty}(\gamma)$; \\
		\>set $(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$;\\
		
		\textbf{end}
	\end{tabbing}
	\caption{LPF algorithm}
\end{algorithm}
%\begin{tabbing}
%	\textbf{Given} $\gamma, \sigma_{min}, \sigma_{max}$ and $(x^{o}, \lambda^{o}, s^{o})\in\mathcal{N}_{-\infty}(\gamma)$ with $(x^{o}, s^{o})>0$;\\
%	\textbf{for} \= $k = 0, 1, 2,...$ \\
%	\> Choose $\sigma_{k}\in[\sigma_{min},\sigma_{max}]$ and solve
%\end{tabbing}
%\begin{equation}\label{(5.9)}
%\begin{bmatrix}
%0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
%\end{bmatrix}\begin{bmatrix}
%\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
%\end{bmatrix}=-\begin{bmatrix}
%0\\0\\-X^{k}S^{k}e + \sigma_{k}\mu_{k}e
%\end{bmatrix}
%\end{equation}
%\begin{tabbing}
%	\textbf{Set} \=$(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$\\
%	\> Choosing the largest value in $\alpha_{k}\in[0,1]$ so that $(x^{k+1}, \lambda^{k+1}, s^{k+1})\in\mathcal{N}_{-\infty}(\gamma)$\\
%	\textbf{end}
%\end{tabbing}

The convergence results we will illustrate show that the sequence generated by a LPF algorithm is bounded and therefore has at least one limit point. Further, all limit points correspond to strictly complementary solutions $(x^{*},\lambda^{*},s^{*})$ for which:
\begin{align*}
&x^{*}_{i}>0, \text{\;for\;} i \in\mathcal{B},
&s^{*}_{i}>0, \text{\;for\;} i \in\mathcal{N},
\end{align*}
where $\mathcal{B}\cup\mathcal{N}$ is the partition of $\{1,2,\dots,m\}$ defined previously.
The following lemma shows properties of the points in $\mathcal{N}_{-\infty}(\gamma)$ that are used in the analysis section.
\begin{lem}
	Let $\mu_{0}\geq 0$ and $\gamma\in(0,1)$. Then for all points $(x,\lambda,s)$ with
	\begin{equation*}
	(x,\lambda,s)\in\mathcal{N}_{-\infty}(\gamma)\subset\mathcal{F}^{0}, \;\; \mu \leq \mu_{0}
	\end{equation*}
	there are constants $C_{0}$ and $C_{1}$ such that
	\begin{align*}
	\lVert(x,s) \rVert&\leq C_{0}\\0< x_{i}&\leq \mu/C_{1}\;\; (i \in\mathcal{N}),\\
	0< s_{i}&\leq \mu/C_{1}\;\; (i \in\mathcal{B}),\\ 
	s_{i}&\geq C_{1}\gamma \;\; (i \in\mathcal{N}),\\
	x_{i}&\geq C_{1}\gamma \;\; (i \in\mathcal{B}).\\
	\end{align*}
\end{lem}
\begin{proof}
	~\cite{Wright} pag. 101
\end{proof}
The following is a technical lemma.
\begin{lem}\label{lem1}
	Let u and v be any two vectors in $\mathbb{R}^{n}$ with $u^{T}v \geq 0$. Then, 
	\begin{align*}
	\lVert UVe \rVert_{2}\leq 2^{-3/2}\lVert u + v \rVert^{2}_{2},\\
	\end{align*}
	with $U = diag(u_{1}, u_{2}, ..., u_{n})$ and $V = diag(v_{1}, v_{2}, ..., v_{n})$. 
\end{lem}
\begin{proof}
	We can formulate $0 \leq u^{T}v = \sum\limits_{u_{i}v_{i} \geq 0}u_{i}v_{i} + \sum\limits_{u_{i}v_{i} \leq 0}u_{i}v_{i} = \sum\limits_{i \in \mathcal{P}}|u_{i}v_{i}| - \sum\limits_{i \in \mathcal{M}}|u_{i}v_{i}| $, with $\mathcal{P}= \{i | u_{i}v_{i} \geq 0\}$ and $\mathcal{M}= \{i | u_{i}v_{i} \leq 0\}$.
	Then
	\begin{align*}
	\lVert UVe \rVert_{2} &= ( \lVert[u_{i}v_{i}]_{i \in \mathcal{P}} \rVert^{2} +  \lVert[u_{i}v_{i}]_{i \in \mathcal{M}} \rVert^{2})^{1/2}\\
	&\leq ( \lVert[u_{i}v_{i}]_{i \in \mathcal{P}} \rVert^{2}_{1} +  \lVert[u_{i}v_{i}]_{i \in \mathcal{M}} \rVert^{2}_{1})^{1/2},\; \text{since\;} \lVert\dot\rVert_{2} \leq \lVert\dot\rVert_{1}\\
	&\leq\sqrt{2}\;\bigg\lVert\bigg[\frac{1}{4}(u_{i} + v_{i})^{2}\bigg]_{i\in \mathcal{P}}\bigg\rVert_{1}, \text{\;since\;} \sqrt{ab} \leq \frac{1}{2}|a+b|\\
	& = 2^{-3/2} \sum\limits_{i \in \mathcal{P}}(u_{i} + v_{i})^{2}\\
	& \leq 2^{-3/2} \sum\limits_{i = 0}^{n}(u_{i} + v_{i})^{2}\\
	& \leq 2^{-3/2} \lVert u + v \rVert^{2}_{2}.
	\end{align*}
\end{proof}	
The next lemma is an important tool to proof the following statement.
\begin{lem}\label{lem:ma1}
	If $(x, \lambda, s) \in \mathcal{N}_{-\infty}(\gamma)$, then
	\begin{align*}
	\lVert\Delta X\Delta S e \rVert \leq 2^{-3/2}(1 + 1/ \gamma)n\mu.\\
	\end{align*}
\end{lem}
\begin{proof}
%	$(x + \Delta x)^{T}(s +\Delta s) = SX + x \Delta s + s \Delta x + \Delta x \Delta s$ and $S \Delta x + X \Delta s + XS = 0$, by the last row of \ref{(5.1)}. These two equations show that $\Delta x\Delta s = 0$.\\
	By multiplying the last block row of $\ref{Pb}$ by $(XS)^{-1/2}$ and recalling the definition of $D = X^{1/2}S^{-1/2}$, we obtain 
	\begin{equation}\label{58}
	D^{-1}\Delta x + D \Delta s = (XS)^{-1/2}(-XSe + \sigma \mu e).
	\end{equation}
	Now, applying the Lemma \ref{lem1} with $u= D^{-1}\Delta x$ and $v = D \Delta s$, we obtain
	\begin{align*}
	\lVert \Delta X \Delta S e\rVert &= \lVert(D^{-1}\Delta X)(D\Delta S)e \rVert \\
	&\leq 2^{-3/2}\lVert D^{-1}\Delta x + D \Delta s\rVert^{2}, \text{\;from Lemma \ref{lem1}}\\
	&= 2^{-3/2}\lVert (XS)^{-1/2}(-XSe + \sigma \mu e)\rVert ^{2} \text{,\; from (\ref{58})}\\
	\end{align*}
	Expanding the squared Euclidean norm and using such relationships as $x^{T}s = n\mu$ and $e^{T}e = n$, we obtain
	\begin{align*}
	\lVert \Delta X \Delta S e\rVert_{2} &\leq 2^{-3/2}\bigg[x^{T}s - 2\sigma \mu e^{T}e + \sigma^{2}\mu^{2}\sum\limits_{i = 1}^{n}\frac{1}{x_{i}s_{i}}\bigg]\\
	&\leq s^{-3/2}\bigg[x^{T}s - 2\sigma \mu e^{T}e + \sigma^{2}\mu^{2}\frac{n}{\gamma \mu}\bigg], \text{\; since\;} s_{i}x_{i} \geq \gamma \mu\\
	&\leq 2^{-3/2}\bigg[1 - 2\sigma + \frac{\sigma^{2}}{\mu}\bigg]n \mu\\
	&\leq 2^{-3/2}(1 + 1/\gamma)n \mu.
	\end{align*}
\end{proof}

\begin{thm}
	Given the parameters $\gamma$, $\sigma_{\text{min}}$ and $\sigma_{\text{max}}$ in the long-step path following algorithm, there is a constant $\delta$ indipendent of n such that
	\begin{equation}\label{(5.10)}
	\mu_{k+1} \leq \bigg(1 - \frac{\delta}{n}\bigg)\mu_{k}, \text{\;for all\;}k\geq0.\\
	\end{equation} 
\end{thm}
\begin{proof}
	First of all we prove that $(x_{k}, \lambda_{k}, s_{k})+\alpha(\Delta x_{k},\Delta \lambda_{k},\Delta s_{k})\in\mathcal{N}_{-\infty}(\gamma)$ for all $\sigma \in \bigg[0,2^{3/2}\gamma \frac{1 - \gamma}{1 +\ \gamma}\frac{\sigma_{k}}{n}\bigg]$.\\
	
	From the last $n$ equalities of (\ref{Pb}), we have that 
	\begin{align}&(x_{i}^{k}, \lambda_{i}^{k}, s_{i}^{k})+\alpha(\Delta x_{i}^{k},\Delta \lambda_{i}^{k},\Delta s_{i}^{k});\\ 
	 &=x_{i}^{k}s_{i}^{k} + \alpha(x_{i}^{k} \Delta s_{i}^{k} + s_{i}^{k} \Delta x_{i}^{k})+\alpha^{2}\Delta x_{i}^{k} \Delta s_{i}^{k}; \\
	&=x_{i}^{k}s_{i}^{k}(1 - \alpha) + \alpha \sigma_{k}\mu_{k}-\alpha^{2}|\Delta x_{i}^{k} \Delta s_{i}^{k}| \label{(5.11)};\\
	&\geq \gamma(1 - \alpha)\mu_{k} + \alpha \sigma_{k}\mu_{k}-\alpha^{2}2^{-3/2}(1 + 1/ \gamma)n\mu_{k} \label{(5.12)}.\\
	\end{align}
	In the equation (\ref{(5.11)}) $\alpha x_{i}^{k}s_{i}^{k}$ is added in order to use the last equations of the matrix system.\\ 
	In (\ref{(5.12)}) it is used the inequality in \textbf{Lemma \ref{lem:ma1}}: $|\Delta x_{i}^{k}\Delta s_{i}^{k}|\leq2^{-3/2}(1 + 1/\gamma)n\mu_{k}$, for any $i = 1,2,...,n$. \\
	By summing the $n$ components of the equation $S^{k}\Delta x^{k} + X^{k} \Delta s^{k} = -X^{k}S^{k}e + \sigma_{k} \mu_{k}e$ and using the null product $\Delta x \Delta s$, we have
	\begin{align*}\mu_{k}(\alpha)\vcentcolon=(x_{i}^{k} + \alpha\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha\Delta s_{i}^{k})/n&=\\ 
	x_{i}^{k}s_{i}^{k}/n - \alpha \mu_{k}+\alpha \sigma_{k} \mu_{k} &=\\
	(1-\alpha(1-\sigma_{k}))\mu_{k}.
	\end{align*}
	From these last two formulas, we can see that proximity condition:\\$(x_{i}^{k} + \alpha\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha\Delta s_{i}^{k}) \geq \gamma\mu_{k}(\alpha)$ is satisfied if \begin{equation*}
	\gamma(1-\alpha)\mu_{k} + \alpha\sigma_{k}\mu_{k} - \alpha^{2}2^{-3/2}(1 + 1/\gamma)n\mu_{k}\geq \gamma(1 - \alpha +\alpha\sigma_{k})\mu_{k}.
	\end{equation*}
	Rearranging the expression in further two steps, we assert the upper bound of the interval of the parameter $\alpha$:
	\begin{align*}
	\alpha\sigma_{k}\mu_{k}(1-\gamma)&\geq\alpha^{2}2^{-3/2}(1+1/\gamma),\\
	\alpha&\leq \frac{2^{3/2}}{n} \sigma_{k}\gamma\frac{1-\gamma}{1+\gamma}.\\		
	\end{align*}
	Now, we complete the prof of the theorem by estimating the reduction in $\mu$ on the $k$th step. Using the inequality above, we get:
	\begin{align*}
	\mu_{k+1}& = (x_{i}^{k} + \alpha_{k}\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha_{k}\Delta s_{i}^{k})/n\\
	& = [(x^{k})^{T}s^{k} + \alpha_{k}\big((x^{k})^{T}\Delta s^{k} + (s^{k})^{T}\Delta x^{k}\big) +\alpha^{2}_{k}(\Delta x^{k})^{T}\Delta s^{k}]/n\\
	& = (1 - \alpha_{k}(1-\sigma_{k}))\mu_{k}\\
	& \leq \Big(1 - \frac{2^{3/2}}{n}\gamma\frac{1-\gamma}{1+\gamma}\sigma_{k}(1-\sigma_{k})\Big)\mu_{k}.\\
	\end{align*}
	Since the function $\sigma(1 - \sigma)$ is a concave quadratic function of $\sigma$, we have:
	\begin{equation*}
	\sigma_{k}(1-\sigma_{k})\geq \text{min}\{\sigma_{\text{min}}(1-\sigma_{\text{min}}),\sigma_{\text{max}}(1-\sigma_{\text{max}})\}, \text{\;for all\;}\sigma_{k}\in[\sigma_{\text{min}},\sigma_{\text{max}}].
	\end{equation*}
	We can use this estimate in the last inequality and set
	\begin{equation*}
	\delta \vcentcolon=2^{3/2}\gamma\frac{1-\gamma}{1+\gamma}\text{\text{min}}\{\sigma_{\text{min}}(1-\sigma_{\text{min}}),\sigma_{\text{max}}(1-\sigma_{\text{max}})\}, \text{\;for all\;}\sigma_{k}\in[\sigma_{\text{min}},\sigma_{\text{max}}].
	\end{equation*}
\end{proof}
We complete the analysis theory with the following theorem which shows that a reduction of a factor of $\epsilon$ in the duality measure $\mu$ can be obtained in $\mathcal{O}(n\log{1/\epsilon})$ iterations.
\begin{thm}
	Given $\epsilon>0$ and $\gamma\in(0,1)$, suppose the starting point in the algorithm satisfies $(x^{0},\lambda^{0},s^{0})\in\mathcal{N}(\gamma)$. Then there is an index $\mathcal{K}$ with $\mathcal{K}=\mathcal{O}(n\log1/\epsilon)$ such that $\mu_{k}\leq\epsilon\mu_{0}$.
\end{thm}
\begin{proof}
	By taking the logarithms of both sides in (\ref{(5.10)}), we obtain
	\begin{equation*}
	\log\mu_{k+1}\leq \log \bigg(1-\frac{\delta}{n}\bigg)+\log\mu_{k}\end{equation*}
	and applying this formula repeatedly
	\begin{equation*}
	\log\mu_{k+1}\leq \log \bigg(1-\frac{\delta}{n}\bigg)+\log\mu_{0}.
	\end{equation*}
	\text{Using the log estimate} $\log(1+\beta)\leq\beta$, with $\beta>-1$,\\
	\begin{equation*}
	\log(\mu_{k}/\mu_{0})\leq k\bigg(-\frac{\delta}{n}\bigg).
	\end{equation*}	
	For every $k$ that satisfy
	\begin{equation*}
	k\geq\mathcal{K}:= \frac{\delta}{n}\log\frac{1}{\epsilon} = \frac{\delta}{n}|\log(\epsilon)|,
	\end{equation*}
	we have 
	\begin{equation*}
	k\bigg(-\frac{\delta}{n}\bigg)\leq\log\epsilon
	\end{equation*}	
	that guarantees
	\begin{equation*}
	\mu_{k}/\mu_{o}\leq\epsilon.
	\end{equation*}	
\end{proof}
Most of algorithms do not require the initial point to be strictly feasible but require only that $(x^{k},s^{k})>0$ (\textit{infeasible-interior point algorithms}), as for the affine-scaling method formulated in \textbf{Algorithm \ref{alg:AS}}.\\

Instead for the LPF method, we define an extension of $\mathcal{N}_{-\infty}(\gamma)$ that includes infeasible points. The neighborhood is defined by
 \begin{equation}\label{neigh3}
\mathcal{N}(\gamma,\beta) =\Bigg\{(x, \lambda, s) | \frac{\lVert(r_{b}, r_{c})\rVert_{2}}{\mu} \leq \beta\frac{\lVert(r_{b}^{0}, r_{c}^{0})\rVert_{2}}{\mu^{0}},\; (x, s)>0,\; x_{i}s_{i} \geq \gamma\mu,\;i = 1,\dots, n \Bigg\}
\end{equation}
where $\gamma\in(0,1)$ and $\beta \geq 1$ are given parameters and the residuals $(r_{b}^{0}, r_{c}^{0})$ and $\mu_{0}$ are evaluated at the starting point. Notice that we must have $\beta \geq 1$ to ensure that the initial point $(x^{0}, \lambda^{0}, s^{0})\in\mathcal{N}(\gamma,\beta)$.
In the general framework \textbf{Algorithm 3} we have not specified how the centering parameter is choosen: different interior-point algorithms use a peculiar method to select $\sigma_{k}$.\\
Now we see two heuristic choices of $\sigma_{k}$ at the $k^{th}$ iteration of the algorithm; the first one decreases at each iteration and the second one is fixed: 
\begin{align}
\sigma^{1}_{k} &= \min\{0.1, 100\mu_{k} \},\label{LPF1}\tag{4.13a}\\
\sigma^{2}_{k} &= 1 -\frac{0.5}{\sqrt{n}},\tag{4.13b}\label{LPF2}
\end{align}
with $\mu_{k}$ the duality measure of the current primal-dual point and $n$ is the number of entries of $x$ and $s$. 

\begin{figure}\label{fig:float}
\begin{center}
\includegraphics[width=9 cm]{timeLPF12}\caption{Log plot time storage: test problems for comparing the two centering parameters} 
\end{center}
\end{figure}
Analyzing the graphic in Figure 4.1 we state that the LPF with the centering parameter (\ref{LPF1}) \textit{LPF 1} requires a less number of iterations and less time storage then \textit{LPF2} to find a LP solution, indipendently to the characteristic of the problem data. The storage time refers to the time required to solve LP problems with LPF codes I have implemented and outlined in the \textbf{Appendix A.3}.\\
In the research we will present a predictor-corrector LPF algorithm based on Mehrotra's method, in which the centering parameter is choosen adaptively.\\
Afterwards, in the numerical experiments it will be focused on the LPF method with  $\sigma^{2}$.
\section{Predictor-corrector algorithms}
Most interior-point software written since 1990s have been based on Mehrotra's predictor-corrector algorithm (MPC).\\
Since Karmarkar's landmark paper \cite{Kar}, IPM became one of the most active research area that produced a large amount of research results. Moreover, several powerful methods have been developed: predictor-corrector methods are among the most efficient and most implementations are based on a variant of Mehrotra's algorithm. \\
The Mehrotra's contribution was to combine the work developed by Montiero, Adles and Resende \cite{MARE} and the infeasible-interior-point path-following approach implemented by Lustig, Marsten and Shanno \cite{LMS}.\\ 
The method incorporates these algorithmic devices that contribute to its practical success, including the use of different step lengths for the primal and dual variables and a heuristic choice of the step lengths that is designed to speed the asymptotic convergence.\\
It generates sequence of infeasible iterates $(x^{k},\lambda^{k},s^{k})$ for which $(x^{k},s^{k})>0$. The search direction at each iteration consists of three components:
\begin{enumerate}
	\item an affine-scaling "predictor" direction;
	\item a centering term whose size is governed by the adaptively chosen centering parameter $\sigma$;
	\item a "corrector" direction that attempts to compensate for some of the nonlinearity in the affine-scaling direction.
	\end{enumerate}
The MPC algorithm is described later. \\
The affine-scaling component is calculated before the centering component. By arranging the computations in this way, we gain a key advantage: the ability to choose the centering parameter $\sigma$ adaptively rather then a priori, as in the algorithm LPF.\\
If the affine-scaling direction makes good progress in reducing the duality measure $\mu$ while remaining inside the positive hyperplane defined by $(x,s)>0$, we conclude that little centering is needed, so we choose $\sigma$ close to 1.
\subsection{Mehrotra's algorithm}
Given a point $(x, \lambda, s)$ with $(x, s)> 0$, we compute the affine-scaling direction:
\begin{equation}\label{(A)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{aff}}\\\Delta\lambda^{\text{aff}}\\\Delta s^{\text{aff}}
\end{bmatrix}=-\begin{bmatrix}
A^{T}\lambda+s-c\\Ax-b\\XSe
\end{bmatrix}.
\end{equation}
Now we find the step lengths to the boundary along this direction, performing separate calculations for the primal and dual components as follow:
\begin{align}\label{Qw}\tag{4.22a}
\alpha_{\text{aff}}^{\text{pri}}=\arg\max\{\alpha\in[0,1]\;|\;x +\alpha\Delta x^{\text{aff}}\geq 0\}, \\
\alpha_{\text{aff}}^{\text{dual}}=\arg\max\{\alpha\in[0,1]\;|\;s +\alpha\Delta s^{\text{aff}}\geq 0\}\tag{4.22b}.
\end{align}
To measure the efficacy of the affine-scaling direction, we define $\mu_{\text{aff}}$ as the hypothetical value of $\mu$ resulting from a full step to the boundary, that is,
\begin{equation*}
	\mu_{\text{aff}}= (x+\alpha_{\text{aff}}^{\text{pri}}\Delta x^{\text{aff}})^{T}(s+\alpha_{\text{aff}}^{\text{dual}}\Delta s^{\text{aff}})/n
\end{equation*}
If $\mu_{\text{aff}}\ll\mu$, the affine-scaling direction is a good search direction that permits significant progress to be made in reducing $\mu$, so we choose the centering parameter $\sigma$ close to 0. If $\mu_{\text{aff}}$ is just a little smaller than $\mu$, we choose $\sigma$ closer to 1. This choice has the effect of moving us closer  to the central path $\mathcal{C}$, so that the algorithm is in a better position to achieve a substantial decrease in $\mu$ on the next iteration.\\
Mehrotra \cite{MER} suggests the following heuristic, which has proved to be effective in exhaustive computational testing:
\begin{equation}\tag{4.22c}\label{CP}
\sigma = \bigg(\frac{\mu_{\text{aff}}}{\mu}\bigg)^{3}.
\end{equation}
The centering step component is computed solving a linear system with the same coefficient matrix as in (\ref{(A)}) but the right-hand side equal to $[0, 0,\sigma\mu e]$: actually it is combined with the corrector step, as we see later.\\
To motivate the corrector step, we see how the $i$th pairwise product $x_{i}s_{i}$ is affected by a full step in the affine-scaling direction:
\begin{equation*}
(x_{i}+\Delta x_{i}^{\text{aff}})(s_{i}+\Delta s_{i}^{\text{aff}})= x_{i}s_{i}+ x_{i}\Delta s_{i}^{\text{aff}}+s_{i}\Delta x_{i}^{\text{aff}}+\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}} =\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}}.
\end{equation*}
When a full step is taken, the pairwise product $x_{i}s_{i}$ transforms to $\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}}$, instead of 0. The corrector component $(\Delta x^{\text{cor}}, \Delta \lambda^{\text{cor}}, \Delta s^{\text{cor}})$ tries to compensate for this deviation from linearity, modifying the search direction so that the pairwise products come closer to their target value to 0. This step satisfies the following system:
\begin{equation}\label{(B)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{cor}}\\\Delta\lambda^{\text{cor}} \\\Delta s^{\text{cor}}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\\Delta X^{\text{aff}}\Delta S^{\text{aff}}e
\end{bmatrix},
\end{equation}
where
\begin{align*}
\Delta X^{\text{cor}}& = \text{diag}(\Delta x_{1}^{\text{aff}}, \Delta x_{2}^{\text{aff}},\dots,\Delta x_{n}^{\text{aff}}),\\
\Delta S^{\text{cor}}& = \text{diag}(\Delta s_{1}^{\text{aff}}, \Delta s_{2}^{\text{aff}},\dots,\Delta s_{n}^{\text{aff}}).
\end{align*}
To assess the effect of the corrector component, we examine the pairwise product obtained from a full step along the combined affine-scaling/corrector direction. From (\ref{(B)}), we have:
\begin{equation*}
(x_{i}+\Delta x_{i}^{\text{aff}}+\Delta x_{i}^{\text{cor}})(s_{i}+\Delta s_{i}^{\text{aff}}+\Delta s_{i}^{\text{cor}})= \Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{cor}}+\Delta x_{i}^{\text{cor}}\Delta s_{i}^{\text{aff}}+\Delta x_{i}^{\text{cor}}\Delta s_{i}^{\text{cor}}.
\end{equation*}
This result yelds to a better reduction of the duality measure: in fact it results:
\begin{center} 
	\\$\lVert(\Delta x^{\text{aff}},\Delta s^{\text{aff}}) \rVert = \mathcal{O}(\mu)$ and $\lVert(\Delta x^{\text{cor}},\Delta s^{\text{cor}}) \rVert = \mathcal{O}(\mu^{2})$.
\end{center}
When the limiting matrix is singular, the corrector step may no longer be smaller in norm than the affine-scaling step, ideed, it is often larger. Even in this situation, the use of the corrector component usually enhances the overall efficiency of the algorithm in practice.\\
Since the centering and corrector components are obtained by solving linear system with the same coefficient matrix and they are indipendent each other, we can merge them into a single direction by adding their corresponding right-hand sides and compute the combined direction. 
We obtain the combined centering-corrector step $(\Delta x^{\text{cc}}, \Delta \lambda^{\text{cc}}, \Delta s^{\text{cc}})$ solving the following system:
\begin{equation}\label{(C)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{cc}}\\\Delta\lambda^{\text{cc}} \\\Delta s^{\text{cc}}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\\Delta X^{\text{aff}}\Delta S^{\text{aff}}e - \sigma\mu e
\end{bmatrix}.
\end{equation}
Although we need to solve at each iteration two linear systems instead of one, the marginal cost is not great because the systems have the same coeffifient matrix and then we need only modify the right-hand side. \\
 Having described the essential elements of Mehrotra'a approach, the algorithm is structured as follows:
\\

\begin{algorithm}\caption{Mehrotra's algorithm}
\begin{tabbing}
	\\
	\textbf{Given} $(x^{0}, \lambda^{0}, s^{0})> 0$; \\
	\textbf{for} \= $k = 0, 1, 2,...$ \\
	\> solve \ref{(A)} for $(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})$;\\
	\> calculate $\alpha_{\text{aff}}^{\text{pri}}$, $\alpha_{\text{aff}}^{\text{dual}}$ and $\mu_{\text{aff}}$ as in (4.22);\\
	\> set centering parameter to $\sigma = (\mu_{\text{aff}}/\mu)^{3}$; \\
	\> solve (\ref{(C)}) for $(\Delta x^{cc},\Delta \lambda^{cc},\Delta s^{cc})$;\\
	\> compute the search direction and step to boundary from: \\
	\> \\
	\> $\;\;\;\;\;\;\;(\Delta x^{k},\Delta \lambda^{k},\Delta s^{k})=(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+(\Delta x^{cc},\Delta  \lambda^{cc},\Delta s^{cc})$;\\
	\> $\;\;\;\;\;\;\;\alpha_{\text{max}}^{\text{pri}}=\arg\max\{\alpha\geq0\;|\;x^{k} +\alpha\Delta x^{k}\geq 0\}$,\\
	\> $\;\;\;\;\;\;\;\alpha_{\text{max}}^{\text{dual}}=\arg\max\{\alpha\geq0\;|\;s^{k} +\alpha\Delta s^{k}\geq 0\}$,\\
	\>\\
	\> set $\alpha_{k}^{\text{pri}}=\min(0.99\ast\alpha_{\text{max}}^{\text{pri}},1)$ and $\alpha_{k}^{\text{dual}}=\min(0.99\ast\alpha_{\text{max}}^{\text{dual}},1)$;\\
	\> set\\
	\> $\;\;\;\;\;\;\;x^{k+1} = x^{k} + \alpha_{k}^{\text{pri}}\Delta x^{k}$;\\
	\>$\;\;\;\;\;\;\;(\lambda^{k+1},s^{k+1}) = (\lambda^{k},s^{k}) + \alpha_{k}^{\text{dual}}\Delta (\lambda^{k},\Delta s^{k})$;\\
\textbf{end}
\end{tabbing}
\end{algorithm}

\subsection*{Analysis of MPC}
In order to study the performance of the Mehrotra's algorithm, we introduce the trajectory-following methods from ODEs. These one define a trajectory from the current point, we say $(x,\lambda,s)$, to the solution set $\Omega$. There are infinitely many trajectories to choose from, but in this case it is obtained from a linear scaling of the function (\ref{F}).\\ Denoting this trajectory by $\mathcal{H}$ and parametrizing it by $\tau\in[0,1)$, we find that each point $(x_{\tau},\lambda_{\tau},s_{\tau})\in\mathcal{H}$ is a solution of the following nonlinear system:
\begin{equation}\label{T}
\begin{bmatrix}
A^{T}\lambda+s-c \\Ax-b \\XSe
\end{bmatrix}=\begin{bmatrix}
(1-\tau)(A^{T}\lambda-c)\\(1-\tau)(Ax-b)\\(1-\tau)XSe
\end{bmatrix}, (x,s)\geq0.
\end{equation}
We see that $(x_{\tau},\lambda_{\tau},s_{\tau})$ with $\tau = 0$ is exactly the initial point and that, if the limit exists, then $\lim\limits_{\tau\to\infty}(x_{\tau},\lambda_{\tau},s_{\tau}) = (x^{*},\lambda^{*},s^{*})$.\\
To move along the trajectory $\mathcal{H}$, we can form a Taylor series approximation to $(x_{\tau},\lambda_{\tau},s_{\tau})$ by expanding about the initial point  $(x,\lambda,s)$ as follows:
\begin{equation*}
(x_{\tau},\lambda_{\tau},s_{\tau})=(x_{0},\lambda_{0},s_{0})+\tau(x_{0}^{'},\lambda_{0}^{'},s_{0}^{'})+\frac{1}{2}\tau^{2}(x_{0}^{"},\lambda_{0}^{"},s_{0}^{"})+\dots = \sum_{j=0}^{\infty}\frac{\tau^{j}}{j!}(x_{0}^{j},\lambda_{0}^{j},s_{0}^{j}).
\end{equation*}
Here, $(x_{0}^{j},\lambda_{0}^{j},s_{0}^{j})$ is the derivative of $(x_{\tau},\lambda_{\tau},s_{\tau})$ with respect to $\tau$, evaluated in $\tau = 0$. We can find these derivatives by implicity differenziating (\ref{T}). Setting $\tau=0$ we have:
\begin{equation}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
x_{0}^{'}\\\lambda_{0}^{'}\\s_{0}^{'}
\end{bmatrix}=-\begin{bmatrix}
A^{T}\lambda-c\\Ax-b\\XSe
\end{bmatrix},
\end{equation}
which is exactly the same system as the affine-scaling step equation.\\
Hence, we can make the identification $(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})=(x^{'}_{0},\lambda^{'}_{0},s^{'}_{0})$. Differentiating again with respect to $\tau$, we obtain the second derivative solving
\begin{equation}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
x_{0}^{''}\\\lambda_{0}^{''}\\s_{0}^{''}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\2X^{'}_{0}S^{'}_{0}e
\end{bmatrix}
\end{equation}
and we see that $(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})=\frac{1}{2}(x^{''}_{0},\lambda^{''}_{0},s^{''}_{0})$. Now we truncate the Taylor series at two terms and use the last two results, in order to have the following approximation:
\begin{equation}
(x_{\tau},\lambda_{\tau}, s_{\tau})\approx(x, \lambda, s)+ \tau(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+\tau^{2}(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})
\end{equation}
If we ignore the centering term  by setting $\sigma =0$ and, hence, constrain the primal and dual step lengths to be identical, then the algorithm searches the successive point along the line
\begin{equation}
(x_{\tau},\lambda_{\tau}, s_{\tau})\approx(x, \lambda, s)+ \tau(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+\tau(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})
\end{equation} 
that is, the $\tau^{2}$ coefficient in the last term is replaced by $\tau$. Instead when we account for the centering parameter, the correspondence between the derivatives of the trajectory and the MPC search direction no longer holds. \\
Then we introduce the modified trajectory $\mathcal{H}_{\sigma}$ for which the correspondence continues to hold even in the presence of $\sigma$. Also $\mathcal{H}_{\sigma}$ starts at $(x, \lambda, s)$ and aims at the solution set $\Omega$. All $(x_{\tau},\lambda_{\tau},s_{\tau})$ in this trajectory satisfy:
\begin{equation}\label{T}
\begin{bmatrix}
A^{T}\lambda+s-c \\Ax-b \\XSe
\end{bmatrix}=\begin{bmatrix}
(1-\tau)(A^{T}\lambda-c)\\(1-\tau)(Ax-b)\\(1-\tau)XSe+\tau^{2}(1-\tau)\sigma\mu e
\end{bmatrix},(x,s)\geq0.
\end{equation}
The tangent to this trajectory is the affine-scaling direction, as for $\mathcal{H}$, but the curvature can be identified with the combined centering-corrector step rather than the corrector component alone. The trajectory $\mathcal{H}_{\sigma}$ tends to bulge more toward the central path than $\mathcal{H}$. Despite the closer relationship between $\mathcal{H}_{\sigma}$  and MPC algorithm, we can not qualify it as a second-order trajectory-following algorithm because it still searches along a linear direction rather than a quadratic path.  
\subsection{A predictor-corrector LPF method}
In this research it is proposed a predictor-corrector long-path following method (PC-LPF) in which the centering parameter $\sigma$ is computed adaptively, equal to (\ref{CP}).\\
This predictor-corrector algorithm below is a definite improvement over the long-path following algorithm because of the adaptivity that is built into the choice of the predictor step. We will discuss if eventually this potential
technique may further accelerate the performance of the LPF method.
The values of the step lengths and the centering parameter are performed in order to guarantee that the next iteration $(x^{k}, \lambda^{k}, s^{k})$ is in $\mathcal{N}_{-\infty}(\gamma,\beta)$:
\begin{align}\label{QWw}
\alpha_{\text{aff}}^{\text{pri}}=\arg\max\{\alpha\in[0,1]\;|\;(x^{k}, \lambda^{k}, s^{k})+ \alpha(\Delta x^{\text{aff}}, \Delta\lambda^{\text{aff}}, \Delta s^{\text{aff}})\in\mathcal{N}_{-\infty}(\gamma,\beta)\}
\end{align}
To measure the efficiency of the affine-scaling direction, we define $\mu_{\text{aff}}$ as the hypothetical value of $\mu$ resulting from a full step to the boundary, that is,
\begin{equation*}
\mu_{\text{aff}}= (x+\alpha_{\text{aff}}^{\text{pri}}\Delta x^{\text{aff}})^{T}(s+\alpha_{\text{aff}}^{\text{dual}}\Delta s^{\text{aff}})/n.
\end{equation*}
\begin{algorithm}\caption{\label{alg:pc}PC-LPF algorithm}
\begin{tabbing}
	\\
	\textbf{Given} $(x^{0}, \lambda^{0}, s^{0})> 0$; \\
	\textbf{for} \= $k = 0, 1, 2,...$ \\
	\> solve (\ref{(A)}) for $(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})$;\\
	\> calculate $\alpha_{\text{pre}}^{\text{pri}}$ and $\mu_{\text{aff}}$ as in (4.22);\\
	\> set centering parameter to $\sigma_{k} = (\mu_{\text{aff}}/\mu)^{3}$; \\
	\> solve (\ref{Pb}) for $(\Delta x^{k},\Delta \lambda^{k},\Delta s^{k})$;\\
	\> choose the largest value in $\alpha_{k}\in[0,1]$ so that $(x^{k+1}, \lambda^{k+1}, s^{k+1})\in\mathcal{N}_{-\infty}(\gamma,\beta)$;\\
	\textbf{end}
\end{tabbing}
\end{algorithm}
.
\section{IPM algorithms performance}
In this section we develop an empirical study of the IPM algorithms performace. \\
We introduce a model that allow us to summarize the results obtained in this fashion: we rate the number of iterations $T$ required to solve a LP to the number of constraints $m$ and/or the number of variables $n$ in the problem. We may assume that $T$ can be approximated by a function of the form 
\begin{equation*}
	T = 2^{\alpha}(m+n)^{\beta},
\end{equation*}
for a pair of real numbers $\alpha$ and $\beta$. This multiplicative representation of the numbers of iterations can be converted into an additive representation by taking logarithms. Introducing an $\epsilon$ to value the difference between the model's prediction and the true number of iterations, we see that the model can be written as
\begin{equation*}
\log T = \alpha \log 2 +\beta \log (m+n) +\epsilon.
\end{equation*}
\\For each empirical LP problem $k$ we find the two parameters $\alpha$ and $\beta$ and compute $T_{k}$ related to the IPM methods proposed in this thesis: long-path following algorithms with centering parameter $\sigma_{k}^{1}$ and with $\sigma_{k}^{2}$, LPF PC and Mehrotra's algorithms. \\
Here we give the numerical results about the number of iterations required to compute the algorithms on 30 LP problems retrieved in the \textbf{Appendix}.

\begin{table}[]
	\begin{center}
	\begin{tabular}{cccccc}
		\hline
		\textbf{rows} & \textbf{columns} & \textbf{Mehrotra $T_{k}$} & \textbf{LPF PC $T_{k}$} & \textbf{LPF 1 $T_{k}$} & \textbf{LPF 2 $T_{k}$} \\ \hline
		1 & 2 & 6 & 7 & 60 & 8 \\
		2 & 2 & 6 & 7 & 66 & 8 \\
		4 & 2 & 6 & 7 & 83 & 10 \\
		2 & 2 & 5 & 6 & 64 & 8 \\
		3 & 3 & 7 & 11 & 88 & 8 \\
		2 & 5 & 7 & 9 & 96 & 9 \\
		2 & 5 & 7 & 8 & 99 & 10 \\
		3 & 2 & 5 & 6 & 74 & 7 \\
		2 & 4 & 7 & 9 & 93 & 9 \\
		3 & 4 & 7 & 11 & 99 & 8 \\
		3 & 2 & 6 & 7 & 74 & 8 \\
		3 & 3 & 7 & 8 & 80 & 8 \\
		3 & 2 & 6 & 9 & 81 & 9 \\
		2 & 3 & 6 & 7 & 81 & 8 \\
		3 & 3 & 7 & 10 & 102 & 9 \\
		3 & 3 & 7 & 10 & 90 & 9 \\
		3 & 2 & 5 & 7 & 72 & 7 \\
		10 & 6 & 9 & 15 & 162 & 14 \\
		2 & 2 & 5 & 5 & 61 & 6 \\
		20 & 10 & 9 & 11 & 208 & 15 \\
		55 & 50 & 11 & 21 & 405 & 17 \\
		6 & 5 & 7 & 8 & 126 & 8 \\
		7 & 7 & 6 & 8 & 131 & 8 \\
		8 & 2 & 7 & 10 & 138 & 10 \\
		2 & 4 & 7 & 8 & 98 & 8 \\
		10 & 24 & 8 & 16 & 224 & 15 \\
		11 & 17 & 7 & 13 & 213 & 12 \\
		20 & 64 & 9 & 19 & 20 & 20 \\
		8 & 19 & 6 & 11 & 174 & 12 \\
		35 & 23 & 9 & 41 & 306 & 16 \\ \hline
	\end{tabular}
\end{center}
\end{table}

\begin{figure}\label{figure:T}
	\begin{center}
		\includegraphics[width= 13 cm]{numberiterations}\caption{number of iterations}
	\end{center}
\end{figure}
%\ref{figure:T}
The Figure (4.2) shows a log-log plot of iterations versus $m + n$ and the $L^{1}$ regression lines.
%\lstinputlisting[language=py,caption=applicationContext.py]{Forest.py}

%\begin{table}[]
%\begin{center}
%	\begin{tabular}{|l|l|}
%		\hline
%		{Example} & {\color[HTML]{333333} Convergence rate: K} \\ \hline
%		0 & 2.006 \\
%		1 & 5.537 \\
%		2 & 0.736 \\
%		3 & 3.152 \\
%		5 & 4.025 \\
%		6 & 7.115 \\
%		7 & 3.358 \\
%		8 & 7.208 \\
%		9 & 3.246 \\
%		10 & 1805.964 \\
%		11 & 5.712 \\
%		12 & 9.208 \\
%		13 & 14.010 \\
%		14 & 1.532 \\
%		17 & 6.714 \\
%		19 & 36.431 \\
%		21 & 24.663 \\
%		22 & 1237.766 \\
%		23 & 4.223  \\ \hline
%	\end{tabular}
%\end{center}
%\end{table}

\newpage
\section{Asymptotic convergence}
The algorithms studied generate a sequence of improving primal-dual points $(x^{k},\lambda^{k}, s^{k})$ to the exact solution and in this section we describe the convergence rate of each of them. \\
The codes implemented in this research solve linear programming problems with a starting infeasible point, as we will delineate in the chapter 7. Then, we can determine the order of convergence checking the convergence to the feasible set $\mathcal{F}$, hence to the exact solution.\\
We define the residual function $r$ that converts the vector sequence into a real number sequence.
\chapter{Implementation issues}
There are several important issues concerning interior-point algorithms
for linear programs.
\section*{Initialization and termination}
In the discussion of the interior point methods, it is assumed the starting point $(x^{0}, \lambda^{0}, s^{0})$ is feasible respect to the linear equations \ref{DF} and \ref{PF}, instead in the predictor-corrector alforithms it is required only $(x^{0},s^{0})>0$.\\
IPMs are sensitive to the choice of an initial primal-dual point. In fact, the choice of "poor" starting points may drastically reduce the steps toward the solutiona, giving significant effect on the robustness of the algorithm. Therefore, the choice of good initial values is an important issue in the implementation of the methods. A common way to deal with this issue is to use heuristic-based strategies that try to keep the infeasibility small while ensuring that nonnegative variables are far enough from zero.\\
Since most of IPM explicity or implicity attempt to follow the central path $\mathcal{C}$, a very simple choice for the starting point would be to set the nonnegative variables to one and the others to zero. This choice guarantees that the point is perfectly centered, i.e. all pairwise complementarity products are equal to $\mu$ and the nonnegative variables are sufficiently bounded away from zero. However, this point be far from satisfying the constraints \cite{VAN}.\\
Another strategy aimed to satisfy the requirement that the starting point is both well centerd and not to infeasible is presented \cite{MER} by Mehrotra; we will briefly call it as Mehrotra's initial point method (MIP). This popular heuristic approach for finding $(x^{0}, \lambda^{0}, s^{0})$ consists on computing least squares solutions to the equations corresponding to the linear constraints of the LP and then shifting the values of the variables to ensure that they are kept away from the boundary of the orthant. \\
The construction starts by calculating $(\tilde{x}, \tilde{\lambda}, \tilde{s})$ as solution of two least-squares problems:
\begin{align*}
\min\limits_{x} \lVert x \rVert ^{2} &\text{ subject to }Ax = b,\\
\min\limits_{(\lambda,s)} \lVert s \rVert ^{2} &\text{ subject to } A^{T}\lambda +s = c.
\end{align*}
That is, $\tilde{x}$ and $\tilde{s}$ are the vectors of least norm that are in the feasible set and they are computed using the following formulas:
\begin{equation}\label{71}
\tilde{x} = A^{T}(AA^{T})^{-1}b,\;\;\;\tilde{\lambda}=(AA^{T})^{-1}Ac,\;\;\; \tilde{s} = c- A^{T}\tilde{\lambda}.
\end{equation}
In general, $\tilde{x}$ and $\tilde{s}$ are not positive, so we we define
\begin{equation*}
\delta_{x} = \max(-(3/2)\min\limits_{i}\tilde{x}_{i},0),\;\;\; \delta_{s} = \max(-(3/2)\min\limits_{i}\tilde{s}_{i},0),
\end{equation*}
and compute the positive vectors $\hat{x}= \tilde{x}+\delta_{x}e$ and $\hat{s}= \tilde{s}+\delta_{s}e$ where e is the unit vector. To ensure that the initial points $x^{0}$ and $s^{0}$ are not too close to zero, we add two more scalars defined as follow:
\begin{align}\label{72}
2\tilde{\delta}_{x}= \frac{\hat{x}^{T}\hat{s}}{e^{T}\hat{s}},\;\;\;2\tilde{\delta}_{s} = \frac{\hat{x}^{T}\hat{s}}{e^{T}\hat{x}}.
\end{align}
The starting point is then defined as 
\begin{align*}
(x^{0}, \lambda^{0}, s^{0}) = (\tilde{x}+\tilde{\delta}_{x} e,\;\tilde{\lambda},\;\tilde{s}+\tilde{\delta}_{s} e).
\end{align*}
\\
\begin{figure}
	\centering
	\subfloat
	{\noindent\begin{boxedminipage}{1\linewidth}
			\begin{tabbing}
				compute $(\tilde{x},\tilde{\lambda},\tilde{s})$ as in \ref{71}\\
				\>\\
				$\bar{x} = \min\{x_{i}\}$\\
				$\bar{s} = \min\{s_{i}\}$\\
				\textbf{if} \= $\bar{x}<0$ then\\
				\> $\hat{x}= \tilde{x} -(3/2)\bar{x}e$\\
				\textbf{else} \=\\
				\> $\hat{x} = \tilde{x}$\\
				\textbf{if} \= $\bar{s}<0$ then\\
				\> $\hat{s}= \tilde{s} -(3/2)\bar{s}e$\\
				\textbf{else} \=\\
				\> $\hat{s} = \tilde{s}$\\
				compute \=\ref{72} with $\hat{x}$ and $\hat{s}$\\
				\>$(x^{0}, \lambda^{0}, s^{0}) = (\tilde{x}+\tilde{\delta}_{x} e,\;\tilde{\lambda},\;\tilde{s}+\tilde{\delta}_{s} e)$\\
				\textbf{end}
			\end{tabbing}
		\end{boxedminipage}
		} \quad
\subfloat
	{
	\begin{boxedminipage}{1\linewidth}
		\begin{tabbing}
			choose $\tau < 1$ \\
			$\tilde{w}=(e,0,e)$\\
			$\tilde{\sigma}= \lVert\tilde{r}_{b},\tilde{r}_{c})\rVert_{2}$\\
			$\tilde{\mu}= n$\\
			\textbf{If} \= $\tilde{\sigma}/n\leq \tau$ then\\
			\> $(x^{0}, \lambda^{0}, s^{0}) = \tilde{w}$\\
			\textbf{else}\>\\
			\> $\tilde{\mu}=\tilde{\sigma}/(\tau n)$ \\
			\> $(x^{0}, \lambda^{0}, s^{0}) = \eta \tilde{w}$\\
			\textbf{end}
		\end{tabbing}
	\end{boxedminipage}

} 
\end{figure}

\begin{figure}[t]
	\begin{center}
			
	\end{center}
\end{figure}
The logical basis of this strategy (outlined in Figure \ref{fig:STP2}) is that many path-following methods are able to perform long steps toward the solution and to drive the infeasibility to zero at least at the same rate as the duality gap, by keeping the iterates in the central path neighbourhood $\mathcal{N}_{-\infty}(\gamma,\beta)$, see \ref{neigh3},  \cite{SPS}.
The second starting-point strategy is suggested by the convergence theory of the Potential Reduction (PR) method.\\
The starting point can be chosen as \begin{equation*}
(x^{0}, \lambda^{0}, s^{0}) = \eta \tilde{w},
\end{equation*}where $\tilde{w} = (e,0,e)$ and $\eta$ such that 
\begin{equation}\label{su}
\frac{\lVert(r^{0}_{b},r^{0}_{c})\rVert_{2}}{\mu^{0}}\leq \tau<1. 
\end{equation}
It easy to verify that, since $\mu^{0}$ increases quadratically with $\eta$ and $\lVert(r^{0}_{b},r^{0}_{c})\rVert_{2}$ incrreases linearly, inequality \ref{su} approximately holds if $\eta$ satisfies
\begin{equation*}
\eta\geq \frac{\lVert(\tilde{r}_{b},\tilde{r}_{c})\rVert_{2}}{\tau\tilde{\mu}},
\end{equation*}
where $\lVert\tilde{r}_{b},\tilde{r}_{c})\rVert_{2}$ and $\tilde{\mu}$ are respectively the infeasibility and the duality measure associated with $\tilde{w}$ (in this case $\tilde{\mu} = n$). \\
We note that $(x^{0},\lambda^{0},s^{0})$ is perfectly centered and all its components with lower bound 0 are "sufficient" positive, but even if the ratio in \ref{su} is small, the duality gap and the infeasibility may very large, slowing the progress toward the solution.\\
This method strategy, labeled with STP1 (\cite{SPS}), is summarized in the Figure \ref{fig:STP1}.\\
\begin{figure}[h]
	\begin{center}
\caption{\label{fig:STP1} starting-point strategy STP1}	
\end{center}
\end{figure}
Now we analyze the infeability measures and the duality gaps corresponding to the starting points computed with MIP and STP1.\\
\begin{table}[!h]
	\begin{tabular}{llllllllll}
		\hline
		\textbf{Size} &  &  & \textbf{MIP}&&  &  & \multicolumn{3}{l}{\textbf{      STP1}} \\ \cline{1-2} \cline{4-6} \cline{8-10} 
		n & m &  & infeasibility & duality gap & ratio &  & infeasibility & duality gap & ratio \\ \hline
		1 & 2 &  & 2.07e+01 & -1.98e-01 & -104.65 &  & 2.73e+01 & -1.12e+00 & -2.43e+01 \\
%		2 & 2 &  & 8.05e+00 & 6.25e-01 & 12.87 &  & 9.17e+00 & 9.71e-01 & 9.45e+00 \\
		4 & 2 &  & 5.39e+03 & 2.32e+03 & 2.32 &  & 1.65e+04 & 8.90e+03 & 1.85e+00 \\
%		2 & 2 &  & 5.19e+01 & 1.62e+01 & 3.21 &  & 9.20e+01 & 4.33e+01 & 2.12e+00 \\
%		2 & 2 &  & 6.04e+01 & 4.41e+00 & 13.70 &  & 1.20e+01 & 9.62e-01 & 1.25e+01 \\
		3 & 3 &  & 4.30e+01 & 6.72e+00 & 6.40 &  & 1.93e+02 & 3.05e+01 & 6.32e+00 \\
		2 & 5 &  & 4.73e+01 & 1.46e+00 & 32.31 &  & 9.88e+00 & 1.64e+00 & 6.02e+00 \\
		2 & 5 &  & 3.60e+01 & -3.93e+01 & -0.92 &  & 1.34e+02 & -1.53e+02 & -8.73e-01 \\
		3 & 2 &  & 5.66e+00 & 4.41e-01 & 12.82 &  & 3.61e+00 & 4.00e-01 & 9.01e+00 \\
		2 & 4 &  & 1.11e+02 & -2.14e+01 & -5.20 &  & 1.16e+02 & -4.26e+01 & -2.73e+00 \\
%		3 & 4 &  & 3.11e+01 & -5.69e+00 & -5.46 &  & 1.28e+04 & -2.86e+03 & -4.46e+00 \\
		3 & 2 &  & 1.09e+01 & 1.05e+00 & 10.36 &  & 1.02e+02 & 1.02e+01 & 9.97e+00 \\
		3 & 3 &  & 1.86e+01 & 2.52e+00 & 7.38 &  & 2.90e+01 & 5.44e+00 & 5.33e+00 \\
		3 & 2 &  & 5.09e+01 & 1.07e+01 & 4.74 &  & 1.10e+01 & 3.33e+00 & 3.30e+00 \\
		2 & 3 &  & 3.25e+01 & -2.11e+00 & -15.37 &  & 9.92e+00 & -1.95e+00 & -5.09e+00 \\
%		3 & 3 &  & 2.74e+01 & -2.78e+00 & -9.83 &  & 5.82e+00 & -1.58e+00 & -3.69e+00 \\
		3 & 3 &  & 5.90e+01 & 6.51e+00 & 9.07 &  & 3.21e+01 & 4.16e+00 & 7.72e+00 \\
		3 & 2 &  & 1.44e+01 & 3.38e+00 & 4.25 &  & 3.55e+01 & 1.18e+01 & 3.01e+00 \\
		10 & 6 &  & 9.23e+03 & 1.08e+04 & 0.86 &  & 6.43e+04 & 9.45e+04 & 6.80e-01 \\
		2 & 2 &  & 3.33e+01 & 5.88e-01 & 56.57 &  & 3.97e+01 & 8.77e-01 & 4.53e+01 \\
%		2 & 2 &  & 3.49e+01 & 2.42e+01 & 1.44 &  & 3.13e+01 & 3.22e+01 & 9.71e-01 \\
		20 & 10 &  & 7.46e+04 & 1.65e+04 & 4.51 &  & 8.09e+05 & 1.80e+05 & 4.50e+00 \\
		55 & 50 &  & 1.15e+04 & 2.07e+02 & 55.81 &  & 6.71e+05 & 6.24e+04 & 1.08e+01 \\
		4 & 8 &  & 6.14e+01 & -2.72e+00 & -22.57 &  & 1.50e+01 & -5.48e+00 & -2.74e+00 \\
		6 & 5 &  & 1.81e+01 & -5.88e-01 & -30.79 &  & 4.06e+00 & -2.73e-01 & -1.49e+01 \\
		13 & 6 &  & 1.18e+04 & 1.41e+05 & 0.08 &  & 5.20e+03 & 1.05e+05 & 4.94e-02 \\
		7 & 7 &  & 5.86e+01 & -2.77e+00 & -21.17 &  & 1.05e+01 & -5.00e-01 & -2.11e+01 \\
		8 & 2 &  & 8.30e+01 & -5.62e+00 & -14.76 &  & 5.37e+01 & -5.07e+00 & -1.06e+01 \\
		2 & 4 &  & 2.64e+01 & -6.25e+00 & -4.22 &  & 2.58e+01 & -1.21e+01 & -2.13e+00 \\
		10 & 24 &  & 1.49e+05 & -1.70e+04 & -8.78 &  & 2.77e+09 & -3.15e+08 & -8.77e+00 \\ \hline
	\end{tabular}\caption{Infeasibility measures $\lVert (r_{b}, r_{c})\rVert_{2}$, duality gaps ${\mu}$ and their ratios corresponding to MIP and STP1}
\end{table}
We see that it is not a evidence peculiar behaviour of the values of the infeasibility error and the duality gap obtained by each strategy. Even if the ratio is smaller for the STP1 initial points, the duality gap and the infeasibility error are competitive and they don't lead to an effective comparison.\\ 
\newpage
Now we deal on the termination criteria; unlike the simplex method, primal-dual algorithms never find an exact solution of the LP. In this research it is computed a finite termination phase that reports an approximate solution for which the residuals and duality measure are sufficiently small. After determinated a small tollerance $\epsilon$, the algorithms terminate when the following conditions on the relative primal and dual feasibility and the relative duality gap are satisfied:
\begin{align*}
\frac{\lVert Ax -b\rVert}{1+ \lVert b \rVert}\leq \epsilon, && \frac{\lVert A^{T}y -c\rVert}{1 + \lVert c \rVert}\leq \epsilon, &&\frac{|c^{T}x - b^{T}y|}{1+b^{T}y}\leq \epsilon,
\end{align*}
where $\epsilon > 0$, usually of the order $10^{-8}$, as required both in the literature and in practice, \cite{Wright}.
\section*{The coefficient matrix/ Solving the linear system}
Most of the computational effort in implementations of primal-dual methods is taken up in solving linear systems of the form (\ref{P}). The
coefficient matrix in these systems is usually large and sparse, since the constraint
matrix $A$ is itself large and sparse in most applications. Let us to reformulate
this equation as systems with more compact symmetric coefficient matrices, which
are easier and cheaper to factor than the original form. Since the current point $(x, \lambda, s)$ has $x$ and $s$ strictly
positive, the diagonal matrices $X$ and $S$ are nonsingular. Hence, by eliminating $\Delta s$, we obtain the following equivalent system, called \textit{augmented system}:
\begin{align*}
\begin{bmatrix}
0&A\\A^{T}&-D^{2}
\end{bmatrix}\begin{bmatrix}
\Delta\lambda^{k} \\\Delta x^{k}
\end{bmatrix}=&-\begin{bmatrix}
Ax^{k}-b\\A^{T}y^{k}+s^{k}-c+ se + \sigma_{k}\mu_{k}(X^{k})^{-1}e
\end{bmatrix},\\
\Delta s =& -s^{k} +\sigma_{k}\mu_{k} (X^{k})^{-1}S\Delta x,
\end{align*}
where we have introduced the notation $D = S^{-1/2}X^{1/2}$.\\
Since the matrix $X^{-1}S$ is also diagonal and nonsingular, we can eliminate $\Delta x$ from the first row of the augmented system to obtain another equaivalent form:
\begin{align*}
AD^{2}A^{T}\Delta\lambda &= -r_{b}+A(-S^{-1}Xr_{c}+ x - \sigma\mu S^{-1}e),\\
\Delta s &= -r_{c}-A^{T}\Delta \lambda,\\
\Delta x &= -x + \sigma \mu S^{-1}e-S^{-1}X\Delta s.
\end{align*}
with $r_{b} = Ax - b$ and $r_{c}= A^{T}\lambda +s = c$.\\
\\
This form often is called the \textit{normal equations} form and a direct sparse Cholesky algorithm is applied to factor the matrix $AD^{2}A^{T}$. \\In the implementations both forms are performed: ill conditioning is often observed during the final
steps of the long-path following algorithm with the second system, when the elements of the diagonal weighting
matrix $D^{2}$ takes on both huge and tiny values.
\section*{Geometric viewpoint}
Now we outline the geometric viewpoint of the simplex method and the primal-dual methods.\\
We already stated that the simplex method generates a sequence of basic feasible primal points of the solution set; hence, it creates a path along the boundary of the polytope, checking the cost value at each vertex.\\Instead, the primal-dual interior point methods approach the solution through the interior of the feasible polytope, generating the central path $\mathcal{C}$, rather than working around the boundary.\\ Path-following method follow $\mathcal{C}$ in the direction of decreasing $\tau$ in (4.7) ; ideed, they do not necessarily stay exactly on the path but within a loose and well-defined neighoborhood of $\mathcal{C}$ while steadily reducing the duality measure $\mu$ to zero. Each search direction is computed with a Newton's step toward a point for which the duality measure $\tau$ is equal to or smaller than the current duality measure $\mu$, as we know $\tau=\sigma\mu$. 
The affine-scaling method, based on pure Newton's steps, sets the central parameter $\sigma_{k}= 0$ in the system;
%In fact, the gap between neighborhood boundaries is wide enough to allow this step to make significant progress in reducing $\mu$. 
even if it makes significant progress, it also tends to worsen the centrality measure (condition of having all pairwise products $x_{i}s_{i}$ equal). It follows that the step length $\alpha_{k}$ is the maximum value such that the next points remain in the feasible set. We will see that we often can take only a small
step along the search direction before violating the condition; hence, the affine scaling direction, often does not allow us to make much progress toward a solution.\\ 
The long-path following method doesn't create a sequence that moves strongly to the solution, indeed, computes the search direction with $\sigma_{k}$ between two fixed limits $\sigma_{\text{min}}$ and $\sigma_{\text{max}}$, in order to improve the centrality measure. The lower bound $\sigma_{\text{min}}$ ensures that each search direction start by moving off the boundary of $\mathcal{N}_{-\infty}(\gamma)$ and into the interior of the neighborhood. Unit steps along the search direction takes the next point outside the neighborhood, since the error of approximating the nonlinear KKT system by the linear equations becomes more pronounced as $\alpha$ increases. Then, it selects $\alpha_{k}$ as large a possible subject to the next point remains $\mathcal{N}_{-\infty}(\gamma)$. The restriction of $\sigma_{k}\in(0,1)$ achieves the twin goals of improving centrality and reducing the duality measure into a single step.\\
Alternatively, the predictor-corrector methods consists on two types of steps. The predictor step, which start in the inner neighborhood and moves along the affine-scaling direction to the boundary of the outer neighborhood. Between these predictor steps, the algorithm takes corrector steps, computing $\sigma = 1$ and $\alpha= 1$, in order to come back inside the inner neighborhood to prepare for the next predictor corrector step. The Mehrotra's algorithm chooses the centering parameter adaptively: first calculates the affine-scaling direction, then assesses its usefulness as a search direction. If this direction yields a large reduction in $\mu$ without violating the positivity condition $(x, s)> 0$, the algorithm concludes that littele centering in needed, so it chooses $\sigma_{k}$ close to zero and calculates a centered search direction with small value. Otherwise, it enforces a larger amount of centering by choosing $\sigma_{k}$ close to 1. As we see in the description of the Mehrotra's algortihm, the computation of the centered direction and the corrector step are combined, so adaptive centering does not add further to the cost of each iteration. 

\section*{The centering measure}
Now we examinate the behaviour of the sequence computed by the IPM algorithms respect to the path $\mathcal{C}$, at which all the pairwise products are $x_{i}s_{i}$ are identical to $\mu$. To value this deviation from $\mathcal{C}$, we compare the pairwise products with their average value $\mu = x^{T}s/n$ using a scaled norm defined by. 
\begin{equation}
\frac{1}{\mu}\lVert XSe - \mu e \rVert_{2}
\end{equation}
The problem data are ten little scale LP problems formulated in canonical form. The codes implemented are the algorithm in previously described: affine-scaling, long-path following and Mehrtotra's algorithms. It is also implemented a variation of the long-path following method, in which the centering paramenter is $\sigma_{k}=\sigma$ for all $k$, instead chosen in a random way.



\chapter{Numerical experiments}
In this chapter it is developed a comprehensive analysis of the results obtained by some practical implementations. It is presented three LP problems: the forest service allocation, Swedish steel model, ...\\
The fictitious data used to test the LP methods come from \cite{RR}.
\section{Forest service allocation} 
The first model we illustrate is the \textit{Forest service allocation}. It is part of model class in which the main issue is how to divide or allocate a valuable resource among competing needs and the resource may be for example land, capital, time or fuel. We will see how U.S Forest Service has used this model to address the sensitive task of managing 191 million acres of national forestland \cite{(Natural)}.\\
The Forest Service is one of the major Federal land managing agencies. It has been part of the Department of Agricolture since 1905 and over the past 10 years significant administrative and legal challenges have plagued national forest management \cite{ForSer}. Resource simulation models are the principal technologies used for estimating ecological and enviromental responses to activities. These models try to qualify relationships among resources and results of management actions. Simulations such as timber growth-and-yeld models and sediment yield models often examine consequences of management activities for a singele resource. The regional diversity of forest resources has led to many unique, local models rather than universal models. The Forest Service, in 1979, designed FORPLAN as its principal tool for national forest: it is al linear programming system, used to analyze the temporal aspects of the forest output. FORPLAN was chosen because it addressed two key issues in forest plnning: cost efficiency and an allowable timber sale quantity. Besides, these models have been used by each national forest structure with input that represent their problem. This is a strengh of LP. \\
The models of a forest begin  by dividing land into homogeneous analysis area, then several prescriptions or land management policies are then proposed and evaluated for each. \\The optimization seeks the best possible allocation of land in the analysis areas to particular prescriptions, subject to forest-wide restrictions on land use.
We model, hypotetically, 788 thousand acre Wagonho National Forest, that is assumed to have 7 analysis areas, each subject to 3 different prescriptions. The first prescription encourages timbering, the second grazing and the third preserves the land as wilderness. Then we indices the variables as well:
\begin{itemize}
	\item \textit{i} is the analysis area number and \textit{j} is the prescription number
	\item $s_{i}$ is the size of area $i$ in thousands of acres
	\item $p_{i,j}$ is the net present value (PNV) per acre of all uses in area $i$ if managed under prescription $j$
	\item $t_{i,j}$ is the projected timber yield (in board feet per acre) of analysis area $i$ if managed under prescription $j$
	\item $g_{i,j}$ is the projected grazing capability (in animal unit months per acre) of analysis area $i$ if managed under prescription $j$
	\item $w_{i,j}$ is the wilderness index rating, from 0 to 100, of analysis area $i$ if manages under prescription $j$
\end{itemize}
We want to find an allocation that minimizes net present value while producing 40 million board feet of timber, 5 thousand animal unit months of grazing, and keeping average wilderness index at least 70.\\
The formulation of the model in a LP problem can be written as following:
\begin{align*}
\max&\sum_{i=1}^{7}\sum_{j=1}^{3} p_{i,j}x_{i,j}&(\text{present value})\\
s.t& \sum_{i=1}^{3}x_{i,j}=s_{i}\;\;\;\;i = 1, \dots,7&(\text{allocation})\\
&\sum_{i=1}^{7}\sum_{j=1}^{3} t_{i,j}x_{i,j}\geq 40000&(\text{timber})\\
&\sum_{i=1}^{7}\sum_{j=1}^{3} g_{i,j}x_{i,j}\geq5&(\text{grazing})\\
&\frac{1}{788}\sum_{i=1}^{7}\sum_{j=1}^{3} w_{i,j}x_{i,j}\geq 70&(\text{wilderness})\\
&x_{i,j}\geq 0 \;\;\;\;i = 1,\dots,7;\;\;\;\;j = 1,\dots,3;
\end{align*}
Since the LP is not in standard form, we convert the inequalies to equalities adding slack valriables $y_{i,k}$ to the last three constraints, with $i, k = 1, \dots, 3$. The Forest Service Application data used to test the methods are shown in the table \ref{table:timber}.
\begin{table}[]
	\begin{tabular}{cccllll}
		\hline
		\begin{tabular}[c]{@{}c@{}}\\Analysis area, \\ $i$\end{tabular} & \begin{tabular}[c]{@{}c@{}}Acres,\\ $s_{i}$\end{tabular} & \begin{tabular}[c]{@{}c@{}}Prescription,\\ $j$\end{tabular} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}NPV, $p_{i,j}$\\ (per acre)\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Timber, $t_{i,j}$\\ (per acre)\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Grazing, $g_{i,j}$\\ (per acre)\end{tabular}} & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Wilderness\\ Index, $w_{i,j}$\end{tabular}} \\ \hline
		\multirow{3}{*}{1} & \multirow{3}{*}{75} & 1 & 503 & 310 & 0.01 & 40 \\
		&  & 2 & 140 & 50 & 0.04 & 80 \\
		&  & 3 & 203 & 0 & 0 & 95 \\ \hline
		\multirow{3}{*}{2} & \multirow{3}{*}{90} & 1 & 675 & 198 & 0.03 & 55 \\
		&  & 2 & 100 & 46 & 0.06 & 60 \\
		&  & 3 & 45 & 0 & 0 & 0 \\ \hline
		\multirow{3}{*}{3} & \multirow{3}{*}{140} & 1 & 630 & 210 & 0.04 & 45 \\
		&  & 2 & 105 & 57 & 0.07 & 55 \\
		&  & 3 & 40 & 0 & 0 & 60 \\ \hline
		\multirow{3}{*}{4} & \multirow{3}{*}{60} & 1 & 330 & 112 & 0.01 & 30 \\
		&  & 2 & 40 & 30 & 0.02 & 35 \\
		&  & 3 & 295 & 0 & 0 & 90 \\ \hline
		\multirow{3}{*}{5} & \multirow{3}{*}{212} & 1 & 105 & 40 & 0.05 & 60 \\
		&  & 2 & 460 & 32 & 0.08 & 60 \\
		&  & 3 & 120 & 0 & 0 & 70 \\ \hline
		\multirow{3}{*}{6} & \multirow{3}{*}{98} & 1 & 490 & 105 & 0.02 & 35 \\
		&  & 2 & 55 & 25 & 0.03 & 50 \\
		&  & 3 & 180 & 0 & 0 & 75 \\ \hline
		\multirow{3}{*}{7} & \multirow{3}{*}{113} & 1 & 705 & 213 & 0.02 & 40 \\
		&  & 2 & 60 & 40 & 0.04 & 45 \\
		&  & 3 & 400 & 0 & 0 & 95 \\ \hline
	\end{tabular}\caption{\label{table:timber}Forest Service Application Data}
\end{table}

The minimum total net present value is \$ $322515.00$ with the following optimal allocation:
\begin{align*}
x_{1,1}^{*} &=  0 & x_{1,2}^{*}&= 0 & x_{1,3}^{*} &= 75 & x_{2,1}^{*} &= 90 & x_{2,2}^{*} &= 0 & x_{2,3}^{*} &= 0\\
x_{3,1}^{*} &= 140 & x_{3,2}^{*}&= 0 & x_{3,3}^{*} &= 0 & x_{4,1}^{*} &= 0 & x_{4,2}^{*} &= 0 & x_{4,3}^{*} &= 60\\
x_{5,1}^{*} &= 0 & x_{5,2}^{*}&= 154 & x_{5,3}^{*} &= 58 & x_{6,1}^{*} &= 0 & x_{6,2}^{*} &= 0 & x_{6,3}^{*} &= 98\\
 x_{7,1}^{*}&=0 &x_{7,2}^{*} &= 0 & x_{7,3}^{*} &= 113 & & & &  & & \\
\end{align*}
\section{Swedish steel}
As allocation models split a resource, instead blending models combine them. Various applications blend everything from chemicals, to diets, to metals, to animal food: these problems are formulated in a LP model in which you have to decide what mix of ingredients best fulfills specified output requirements. In this section we propose the Swedish steel problem.\\
The steel industry confronts a blending problem when it melts materials in high-temperature furnaces to manufacture new alloys from scrap. Fagersta AB of Fagersta, in Sweden, is one of many companies that have used mathematical programming to plan this steel blending \cite{SSM}.\\
An optimization arises every time a furnace is charged. Scrap in the available inventory is combined with a pure additives to produce a blend having the required percentages of various chemical elements. It is critical to make maximum use of scrap because addittives are much more expensive. In this research we assess that the Swedish steel making will produce a 1000-kilogram furnace charge. The table \ref{table:carbon} with fictitious data shows the much smaller fractions of carbon, nickel, chromium, and molybdenum in the four available supplies of scrap. It also shows the three higher-cost addities that can be used and the acceptable ranges for the resulting blend.\\
\begin{table}\caption{\label{table:carbon}Data for Swedish Steel Example}
\begin{center}
	\begin{tabular}{@{}lllllll@{}}
		\toprule
		& Carbon & Nickel & Chromium & Molybdenum & Available & Cost \\ \midrule
		First scrap   & 0.80   & 18     & 12       & -          & 75        & 16   \\
		Second scrap  & 0.70   & -      & -        & -          & 250       & 10   \\
		Third scrap   & 0.85   & -      & -        & -          & Unlimited & 8    \\
		Fourth scrap  & 0.40   & -      & -        & -          & Unlimited & 9    \\
		Nickel        & -      & 100    & -        & -          & Unlimited & 48   \\
		Chronium      & -      & -      & 100      & 100        & Unlimited & 60   \\
		Molybdenum    & -      & -      & -        & -          & Unlimited & 53   \\ \midrule
		Minimum blend & 0.65   & 3.0    & 1.0      & 1.1        &           &      \\ 
		Maximum blend & 0.75   & 3.5    & 1.2      & 1.3        &           &      \\ \midrule
	\end{tabular}
\end{center}
\end{table}
The principal decision variables in blending models specify how much of each available ingredient to include in the mix. In the Swedish Steel example we define the decision variables $x_{j}$, where $j = \{1, \dots, 4\}$ refers to the four supplies of scrap and $j = \{5, \dots, 7\}$ refer to the pure additives.\\
We have also upper and lower limits on the fraction of carbon, nickel, chromium and molybdenum in the mix. Each constraint will have the form:\\
\begin{center}
$\sum\limits_{j}\Bigg($\begin{tabular}{l}
 fraction in\\
jth\\
ingredient\\
\end{tabular}
$\Bigg)$$\Bigg($\begin{tabular}{l}
 amount of\\
jth\\
ingredient\\
\end{tabular}$\Bigg)$
\begin{tabular}{l}
	$\geq$\\
	or\\
	$\leq$\\
\end{tabular}
	$\Bigg($\begin{tabular}{l}
		allowed\\
		fraction in\\
		the blend\\
	\end{tabular}
	$\Bigg)$
	$\sum\limits_{j}\Big($\begin{tabular}{l}
		blend\\
		total\\
	\end{tabular}
	$\Big)$
\end{center}		
\bigskip
Collecting all the elements, the LP model of the Swedish example is: 
\begin{align*}
\min16x_{1}+10x_{2}+8x_{3}+9x_{4}+48x_{5}+60x_{6}+53x_{7}& &\text{(cost)}&\\
x_{1}+x_{2}+x_{3}+x_{4}+x_{5}+x_{6} + x_{7}&= 1000&\text{(weight)}&\\
0.008x_{1}+0.007x_{2}+0.0085x_{3}+0.004x_{4}x_{7}&\geq 0.0065(1000)&\text{(carbon)}&\\
0.008x_{1}+0.007x_{2} + 0.0085x_{3} + 0.004x_{4}x_{7}&\leq 0.0075(1000)&\\
0.180x_{1}+0.032x_{2} + 1.0x_{5}&\geq 0.030(1000)& \text{(nickel)}&\\
0.180x_{1}+0.032x_{2} + 1.0x_{5}&\leq 0.035(1000)&\\
0.120x_{1}+0.011x_{2} + 1.0x_{6}&\geq 0.010(1000)& \text{(chromium)}&\\
0.120x_{1}+0.011x_{2} + 1.0x_{6}&\leq 0.012(1000)&\\
0.001x_{2} + 1.0x_{7}&\geq 0.011(1000)& \text{(molybdenum)}&\\
0.001x_{2} + 1.0x_{7}&\leq 0.013(1000)&\\
x_{1}&\leq 75&\text{(available)}&\\
x_{2}&\leq 250 &&\\
x_{1},\dots, x_{7}\geq 0\\
\end{align*}
The unique optimal solution of this model is according to \cite{RR} and confirmed by the tests illustrated below:
\begin{align*}
x_{1}^{*} &=  75\text{ kg,} & x_{2}^{*}&=  90.91\text{ kg,} & x_{3}^{*} &= 672.28 \text{ kg,} & x_{4}^{*} &= 137.31 \text{ kg,}\\
x_{5}^{*} &= 13.59 \text{ kg,}& x_{6}^{*}&= 0\text{ kg,}  & x_{7}^{*} &= 10.91 \text{ kg.} &&\\
\end{align*}
\section{Tubular products operations planning}
Another classic LP form deals with operation planning. In organizations ranging from volunteer, to government, to manifacturing, to distribution, planners must decide what to do and when and where to do it.\\
The Tubular Products Division (TP) of Babcock and Wilcox encountered a problem in investigating how work should be reallocated upon opening a new mill \cite{FEM}. TP manifactured steel tubing in a veriety of sizes and for many different uses, including electrical power generation. At the time of the study three mills handled production. The object was to consider how a fourth mill of different configuration would affect the optimal distribution of work (and associated cost) among the mills.\\ The table shows fictional data for existing mills 1 to 3 and one design for new mill 4, versus an array of 16 products. The products comprise all combinations of standard or high-pressure tubing: $\frac{1}{2}-$, $1-$, $2-$ or $8-$inch diameters, and thick or thin tube walls. The table includes the cost (in dollars) per 1000 pounds of each product according to which mill does the work, and the required processing time (in hours) per 1000 pounds produced. Missing values indicate products that cannot be manufactured feasibly at the mill indicated.\\
We have also assumed division-wide demand for each of the 16 products in thousands of pounds per week. At present the three existing mills 1 to 3 have 800, 480 and 1280 hours per week of effective production cpacity, respectively. New mill 4 is planned for 960 hours per week. See table \ref{tab:TP}.\\
Here the problem has two index dimensions: $p\in{1, \dots, 16}$ rappresents the product number and $m\in{1, \dots, 4}$ the mill number. Instead, the decision variables and the constants are:
\begin{itemize}
	\item \textit{i} is the analysis area number and \textit{j} is the prescription number
	\item $s_{i}$ is the size of area $i$ in thousands of acres
	\item $p_{i,j}$ is the net present value (PNV) per acre of all uses in area $i$ if managed under prescription $j$
	\item $t_{i,j}$ is the projected timber yield (in board feet per acre) of analysis area $i$ if managed under prescription $j$
	\item $g_{i,j}$ is the projected grazing capability (in animal unit months per acre) of analysis area $i$ if managed under prescription $j$
	\item $w_{i,j}$ is the wilderness index rating, from 0 to 100, of analysis area $i$ if manages under prescription $j$
\end{itemize}

\begin{center}
\begin{table}[]
	\begin{tabular}{ccccccccccc}
		\hline
		& \textbf{} & \multicolumn{2}{c}{\textbf{Mill 1}} & \multicolumn{2}{c}{\textbf{Mill 2}} & \multicolumn{2}{c}{\textbf{Mill 3}} & \multicolumn{2}{c}{\textbf{Mill 4}} & \textbf{} \\
		&  & Cost, & Hours, & Cost, & Hours, & Cost, & Hours, & Cost, & Hours, & Weekly dem \\ \cline{3-10}
		& \textbf{Product} & \textbf{$c_{p,1}$} & \textbf{$t_{p,1}$} & \textbf{$c_{p,1}$} & \textbf{$t_{p,2}$} & \textbf{$c_{p,2}$} & \textbf{$t_{p,3}$} & \textbf{$c_{p,3}$} & \textbf{$t_{p,4}$} & \textbf{$d_{p}$} \\ \hline
		\textbf{Std} &  &  &  &  &  &  &  &  &  &  \\ \cline{1-1}
		1 & $\frac{1}{2}$in.thick & 90 & 0.8 & 75 & 0.7 & 70 & 0.5 & 63 & 0.6 & 100 \\
		2 & $\frac{1}{2}$in.thin & 80 & 0.8 & 70 & 0.7 & 65 & 0.5 & 60 & 0.6 & 630 \\
		3 & 1in.thick & 104 & 0.8 & 85 & 0.7 & 83 & 0.5 & 77 & 0.6 & 500 \\
		4 & 1in.thin & 98 & 0.8 & 79 & 0.7 & 80 & 0.5 & 74 & 0.6 & 980 \\
		5 & 2in.thick & 123 & 0.8 & 101 & 0.7 & 110 & 0.5 & 99 & 0.6 & 720 \\
		6 & 2in.thin & 113 & 0.8 & 94 & 0.7 & 100 & 0.5 & 84 & 0.6 & 240 \\
		7 & 8in.thick & - & - & 160 & 0.9 & 156 & 0.5 & 140 & 0.6 & 75 \\
		8 & 8in.thin & - & - & 142 & 0.9 & 150 & 0.5 & 130 & 0.6 & 22 \\ \hline
		\textbf{Press.} &  &  &  &  &  &  &  &  &  &  \\ \cline{1-1}
		9 & $\frac{1}{2}$in.thick & 140 & 1.5 & 110 & 0.9 & - & - & 122 & 1.2 & 50 \\
		10 & $\frac{1}{2}$in.thin & 124 & 1.5 & 96 & 0.9 & - & - & 101 & 1.2 & 22 \\
		11 & 1in.thick & 160 & 1.5 & 133 & 0.9 & - & - & 138 & 1.2 & 353 \\
		12 & 1in.thin & 124 & 1.5 & 127 & 0.9 & - & - & 133 & 1.2 & 55 \\
		13 & 2in.thick & 202 & 1.5 & 150 & 0.9 & - & - & 160 & 1.2 & 125 \\
		14 & 2in.thin & 190 & 1.5 & 141 & 0.9 & - & - & 140 & 1.2 & 35 \\
		15 & 8in.thick & - & - & 190 & 1.0 & - & - & 220 & 1.5 & 100 \\
		16 & 8in.thin & - & - & 175 & 1.0 & - & - & 200 & 1.5 & 10 \\ \hline
	\end{tabular}\caption{\label{tab:TP}Tubular products application data}
\end{table}
\end{center}
\section{Ohio National Bank shift scheduling}
Operations planning models decide what work to undertake so that available resources are used efficiently. In Shift scheduling or staff planning models the work is already fixed. We must now plan the resources to accomplish it.\\
The Ohio National Bank (ONB) confronted such a problem in staffing its check processing center \cite{ONB}. Checks received by the bank already have account numbers and other identifying information encoded on them. Machine operators in the check processing center key the dollar  amount of the check, which is then imprinted with the other information for computerized processing.\\Checks arrive through the business day in volumes peaking in the early evening. The fictious version will assume the following arrival (in thousand):
\begin{table}[H]\caption{\label{table:shiftscheduling}Possible ONB arrivals schedule}
	\begin{center}
	\begin{tabular}{ll|ll}
		\hline
		\textbf{Hour} & \textbf{Arrivals} & \textbf{Hour} & \textbf{Arrivals} \\ \hline
		11:00 & 10 & 17:00 & 32 \\
		12:00 & 11 & 18:00 & 50 \\
		13:00 & 15 & 19:00 & 30 \\
		14:00 & 20 & 20:00 & 20 \\
		15:00 & 25 & 21:00 & 8 \\
		16:00 & 28 & - & -   \\ \hline
	\end{tabular}
\end{center}
\end{table}
Uncollected checks cost the bank money in lost interest. Thus it is essential that all checks be processed in time for collection on the next business day. ONB decided to enforce a requirement that all checks be completed by 22:00. Furthermore, the number unprocessed at any hour should not exceed 20 thousand. \\
Two types of employees can perform the check processing task. Full-time employees work an 8-hour shift with a 1-hour lunch break in the middle. Part-time employees work only 4 hour per day with no lunch. Both types of shifts can begin at any hour of the day and full-time employees can be assigned an hour of overtime.\\
In the analysis we assume that full-time employees receive \$ 11 per hour in pay and benefits, plus an extra \$ 1 per hour in "night differential" for time after 18:00 and 150\% pay for daily overtime. Part-time employees are paid \$ 7 per hour, plus \$ 1 per hour night differential after 18:00. Also, to keep overtime under control, we require that no more than half the full-time employees on any shift work overtime and that the total number of scheduled overtime hours not exceed 20 per day.\\
Naturally, full-time employees work faster than part-timers. We will assume that full-time operators process 1000 checks per hour and part-timers only 800.\\
One final complication is encoding stations. The number of machines available limits the number of employees who can work at any one time. Let us assume the center will have 35 machines.\\

\begin{table}[]\caption{\label{table:Shiftscheduling2}Possible Shifts in ONB Example}
	\begin{center}
	\begin{tabular}{llllllllllll}
		\hline\multirow{\textbf{Start}} & \multicolumn{3}{l}{\textbf{Full-time shift}} & \multicolumn{8}{l}{\textbf{Part-time shifts}} \\ \cline{2-12} 
		& \textbf{11} & \textbf{12} & \textbf{13} & \textbf{11} & \textbf{12} & \textbf{13} & \textbf{14} & \textbf{15} & \textbf{16} & \textbf{17} & \textbf{18} \\ \hline
		11:00 & R & - & - & R & - & - & - & - & - & - & - \\
		12:00 & R & R & - & R & R & - & - & - & - & - & - \\
		13:00 & R & R & R & R & R & R & - & - & - & - & - \\
		14:00 & R & R & R & R & R & R & R & - & - & - & - \\
		15:00 & - & R & R & - & R & R & R & R & - & - & - \\
		16:00 & R & - & R & - & - & R & R & R & R & - & - \\
		17:00 & R & R & - & - & - & - & R & R & R & R & - \\
		18:00 & RN & RN & RN & - & - & - & - & RN & RN & RN & RN \\
		19:00 & RN & RN & RN & - & - & - & - & - & RN & RN & RN \\
		20:00 & ON & RN & RN & - & - & - & - & - & - & RN & RN \\
		21:00 & - & ON & RN & - & - & - & - & - & - & - & RN \\ \hline
	\end{tabular}
	\end{center}
\end{table}
The main decisions to be made in shift scheduling models are the number of employees to work various shifts. \\In the ONB case we have all the possibilities in table \ref{table:Shiftscheduling2}. One additional hour may also be worked in overtime.
Using the index $h$ corresponding the shift start time, we define the following decision variables:
\begin{itemize}
	\item $x_{h}$ is the number of full-time employees beginning a shift at hour $h \in \{11, \dots, 13\}$.
	\item $y_{h}$ is the number of full-time employees with shift beginning at hour $h$ who overtime ($h \in \{11, 12\}$).
	\item $z_{h}$ corresponds to the number of part-time employees beginning a shift at hour $h\in\{11, \dots, 18\}$.
\end{itemize}
With the ONB case we have a slight complication in covering requirements. Work arrivals are specified on an hour-by-hour basis, but work completion is limited only by checks being finished at 22:00. To model covering in such a case, we define also $w$ as well:
\begin{itemize}
	\item $w_{h}$ as unclompeted work backlog at hour $h$ (in thousands).
\end{itemize}
\section{A comparative study}
In this section, we give a comparison between the results given by the infeasible prima-dual algorithms and the LPF predictor-corrector described in the previous chapter.\\ We compute the methods to solve the LP problems before illustrated. Then a study of the numerical results will be discussed.


\chapter{Conclusion}
 First point: All variables $(x, \lambda, s)$ change at each iteration and the linear algebra operations which are required to update them have to involve the complete matrix $A$. This makes a single iteration of the interior point method significantly more expensive than that of the simplex method.\\
 Second point: while the neighborhood $\mathcal{N}_{-\infty}$ ensures that some products do not approach zero too early as with the pure affine scaling method, it does not prevent products from becoming too large with respect to the average. Hence, it does not provide a complete picture of centrality of the iterate.

%\begin{appendices}
\chapter*{Appendix}	
 Let us present the codes I have implemented with Python's programming language for the analysis and the study of the algorithms.
 \section{Simplex method code}\label{app:A.1}
 \lstinputlisting[language=Python]{SimplexMethodIIphases.py}
 \section{Affine scaling method code}
 \lstinputlisting[language=Python]{AffineMethod.py}
 \section{LPF method codes}
 With centering parameter $\sigma^{1}$:
 \lstinputlisting[language=Python]{LPFMethod.py}
With centering parameter $\sigma^{2}$:
 \lstinputlisting[language=Python]{LPFMethod2.py}
Long path following method predictor-corrector:
 \lstinputlisting[language=Python]{LPFMethod_PC.py}
\section{MPC method code}
\lstinputlisting[language=Python]{MehrotraMethod.py}
\newpage
\section{Starting points codes}
 \lstinputlisting[language=Python]{starting_point.py}
 \lstinputlisting[language=Python]{starting_point2.py}
	\chapter{Newton's method}
%\end{appendices}
\begin{thebibliography}{9}
	
	% A
	
	\bibitem{MARE} Adler I., Monteiro R. D. C., Resende M. G. C., \emph{ "A polynomial-time primal-dual affine scaling algorithm for linear and convex quadratic programming and its power serier extension."}, Math. of OR, 15, pp: 191-214, (1990).
	\bibitem{ADL} Adler I., Monteiro R. D. C., \emph{ "Limiting behaviour of the affine scaling continuous trajectories for linear programming problems."}, Mathematical Programming, pp: 29-51, (1991).
	\bibitem{2} Andersen E. D., Ye Y.,  \textit{Combining interior-point and pivoting algorithms for Linear Programming}, (1996).
	\bibitem{SPS} D'Apuzzo M., De Simone V., di Serafino D., \emph{ "Starting-point strategies for an infeassible potential reduction method."}, Springer-Verlag, D. Optim Lett, 4, pp: 131-146, (2010).
	\bibitem{DAN1}Dantzig, G. B.,\textit{ "Maximization of a linear function of variables subject to linear
	inequalities"}, Activity Analysis of Production and Allocation, pp: 339-347, (1947).
	\bibitem{1}Dantzig, G. B.,\emph{\;"Linear Programming and Extensions"}, Princeton, University Press, Princeton, NJ, (1963).	
	\bibitem{DAN}Dantzig, G. B.,\emph{\;"Expected number of steps of the simplex method for a linear program with a convexity constraint."}, Technical Report SOL 80-3, Systems Optimization Laboratory, Department of Operations Research, Stanford University, Stanford, CA, (1980).
	%\bibitem{DAN} G. B. Dantzig, A. Orden, P. Wolfe, \emph{ Notes on linear programming: Part I- The generalized simplex method for
	%minimizing a linear form under linear inequality restrictions.} Pacific J Math pp: 183-195, (1955). 
% K
		\bibitem{MINTY} Klee, V., Minty, G., \emph{ "How good is the simplex algorithm?"} in O. Shisha, ed.,
	‘Inequalities–III’, Academic Press, New York, pp: 159–175, (1972).

		\bibitem{ONB}Based on Krajewski L. J., McKenzie P., Ritzman L. P., \textit{ "Shift Scheduling in Banking Operations: A Case Appllication"}, Interfaces, 10:12, (1980).
		\bibitem{Lem} Lemke C.E, \textit{ "The dual method of solving the linear programming problem."} Naval Research Logistics Quarterly, John Wiley and Sons, (1954).
		\bibitem{Kar} Karmarkar N. K.,\emph{ "A new polynomial-time algorithm for linear programming"}, Combinatorica, (1984).
		\bibitem{(Natural)} Kent B., Bare B. B., Field R. C., Bradley G. A., \textit{"Natural Resource Land Management Planning Using Large-Scale Linear Programs: The USDA Forest Service Experience with FORPLAN".}, OR, 39, pp: 13-27, (1991).
		\bibitem{LNP}Luenberger David G., Yinyu Ye, \emph{"Linear and Nonlinear Programming"}, Springer Science+Business Media, 3, pp: 136-140, (2008).
		\bibitem{LMS} Lustig I. J., Marsten E., Shanno D. F., \emph{ Computational experience with a primal-dual interior point method for linear programming}, Linear algebra and its applications, pp. 191-222, (1991).
		\bibitem{ComTeq} Maros I., \emph{ "Computational Techniques of the Simplex Method}, first ed., Kluwer
		Academic Publishers, Boston, (2003).
		\bibitem{meg} Megiddo N., \emph{ "Pathways to the optimal set in linear programming."}, in Progress in Mathematical Programming: Interior-Point and Related Methods, Springer-Verlag, New York, pp. 131-158, (1986).
	\bibitem{MER} Mehrotra S., \emph{ "On the implementation of a primal-dual interior point method."}, SIAM Journal on Optimization. 2, pp: 575-601 (1992).
	\bibitem{MUR} Mehrotra S., \emph{ Advanced Linear Programming: Computation and
	Practice. } McGraw-Hill New York, New York (1981).
		\bibitem{5}Mizuno S., Todd M.J., Y. Ye,\emph{\;On adaptive-step primal-dual interior-point algorithms for linear programming}, Math. of OR, vol. 18, pp. 964-981, (1993). 
	%	
	%N
	%
	\bibitem{W}Nocedal J., Wright J. S., \emph{\;"Numerical Optimization"}, Springer Series in OR, Springer, New York, (2006).

	%\bibitem{Lexico2}  Charnes A. \emph{ Optimality and degeneracy in linear programming}, 1952. pp: 160-170. 

\bibitem{RR} Rardin Ronald L., \textit{" Optimization in operations reseasch"}, Pearson Education (US), Second edition, University of Arkansas, (2017).

\bibitem{ForSer} \emph{"Forest Service planning: accommodating uses, producing outputs, and sustaining ecosystems."}, Congress of the United States-Office of technology assessment.
\bibitem {VAN} Vanderbei J. Robert, \emph{\;"An interior point code for quadratic programming"}, Optim. Methods Software, 1, pp: 451-484, (1999). 
\bibitem {LP} Vanderbei J. Robert, \emph{\;"Linear programming:
Foundations and Extensions"}. Dept. of Operations Research and Financial Engineering
Princeton University, Springer Science + Business Media, (2001).

%W

\bibitem{SSM} Westerberg, C.-H., Bjorklund B., Hultman E., \emph{"An Application of Mixed Integer Programming in a Swedish Steel Mill" }, Interfaces, 7:2, pp: 39-43, (1977).
\bibitem {Wright} Wright J. Stephen, \emph{\;Primal-Dual Interior Point Methods.} SIAM: society for industrial and applied mathematics. Philadelphia, %pag 134.
\bibitem{WWW}Wright M. H.,\textit{ “Interior methods for constrained optimization”}, Acta Numerica, Cambridge Univ. Press, Cambridge, UK, pp: 341–407, (1992).
\bibitem{XY}Xiaojie Xu, Yinyu Ye, \emph{"A generalized homogeneous and self-dual algorithm for linear programming"}, Operations Research Letters, 17, pp: 181-190, (1995).
\bibitem{matlab}Zhang Y., \textit{ "Solving large-scale linear programs by inteior point methods under
the Matlab enviroment"}, Optimization Methods and Software, 10, pp: 1-31, (1999).
\end{thebibliography}



\end{document}
