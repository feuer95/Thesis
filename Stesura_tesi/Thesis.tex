\documentclass[a4paper,10 pt,titlepage,twoside]{book}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{geometry}
\geometry{a4paper,top=3cm,bottom=3cm,left=3.5cm,right=3.5cm,heightrounded,bindingoffset=5mm}
\usepackage{booktabs}
\usepackage{color}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{statrep}
\usepackage{emptypage}
\usepackage{newlfont}
\usepackage{algpseudocode} 
\usepackage{verbatim}
\usepackage[Algorithm]{algorithm}

\newcommand{\numberset}{\mathbb}
\newcommand{\N}{\numberset{N}}\usepackage{amsmath}
\newcommand{\Z}{\numberset{Z}}
\newcommand{\R}{\numberset{R}}
\newcommand{\Q}{\numberset{Q}}
\newcommand{\K}{\numberset{K}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\n}{\mathcal{N}}

\DeclareMathOperator{\ord}{ord}

%aggiunto da me
\theoremstyle{plain} 
\newtheorem{thm}{Theorem}[chapter] 
\newtheorem{cor}[thm]{Corollario} 
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposizione} 
\newtheorem*{theorem*}{Theorem}


\theoremstyle{definition} 
\newtheorem{defn}[thm]{Definition}
\newtheorem{ex}[thm]{Example}
\newtheorem{propr}{Propriet�}

\theoremstyle{remark} 
\newtheorem{oss}[thm]{Osservazione} 


%per gli spazi:
\usepackage{setspace}
\singlespacing


%\renewcommand{\rmdefault}{phv} % Arial
%\renewcommand{\sfdefault}{phv} % Arial
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\theoremstyle{definition}
%\newtheorem{definizione}{Definizione}

%\theoremstyle{plain}
%\newtheorem{teorema}{Teorema}

%\linespread{1.525}\selectfont

\begin{document}
\thispagestyle{empty}

\centerline {\huge{\textsc{Università degli Studi di Torino}}}
\vskip 27 pt

\centerline {\Large{\textsc{Dipartimento di Matematica Giuseppe Peano}}}

\vskip 20 pt

\centerline {\Large{\textsc{Scuola di Scienze della Natura}}}

\vskip 20 pt

\centerline {\Large{\textsc{Corso di Laurea Magistrale in Matematica}}}


\vskip 60 pt





%\begin{tabular}{ccc}
\centerline {\includegraphics[width=7cm]{logo.jpg}}
%\end{tabular}
\vskip 1.2cm
\centerline {\normalsize {Tesi Magistrale}} 

\vskip 0.7cm

\centerline {\Large {\bf Title}}

\vskip 1.7cm

\noindent Thesis supervisor: Prof.ssa Paola Lamberti
\hfill  {Candidate: Elena Scotto }\\





\vskip 2.7cm


\centerline{2018/2019}

\tableofcontents

% 
%
% CAPITOLO 0
\chapter*{Abstract}
This thesis discusses the Simplex method and the Interior-Point methods (IPM) for linear programming.\\
%These algorithms
%are finite and . 
First of all, it is given a brief description of these methods: the simplex method, that is known to be very efficient practically, and the primal-dual interior-point
methods. Then, we outline a comprehensive convergence analysis of two important IPM: the primal-dual affine scaling method and the long-step path-following method. \\
After having presented a basic theoretical framework, the main goal is to exhibit a comparison of these competitors, testing them on some real models.
In conclusion, it is illustrated the efficacy of the algorithms used for solving large scale linear programs: in this research we obtain an optimal solution of an isogeometric shape optimization problem.\\
The aim is to show that the significant difference between interior point and simplex methods is reflected not only on the theoretical background but also in the practical implementation and to point out the powerful of the IPMs, owing to their vast applicability. 
%\addcontentsline{toc}{chapter}{Abstract}  % se non si vuole numerare l'introduzione, ma farla comparire nell'indice


\chapter{Introduction to the linear programming}
Optimization is a fundamental tool for understanding nature, science, engineering, economics and mathematics: a large number of real world problems can be treated as optimization problems, in which the goal is to select values that maximize or minimize a given \textit{objective function}, subject to certain \textit{constraints}.\\ The process of identifying objective, variables and constrains for a given problem is knows as \textit{modeling}. Construction of an appropriate model is the first step and, once it is formulated, an optimization algorithm can be used to find its solution. There is a collection of algorithms, each of them is tailored to a particular type of optimization problem. Linear Programming problem (LP) remains one of the most well-studied optimization problems: it consists in maximizing or minimizing a linear function over a certain domain, defined by a set of linear constraints.\\
Linear programming has been dominant paradigm in optimization since Dantzig's development of the simplex method in the 1940s. Regarding the theoretical complexity of this method, it has proved that the expected number of iterations in the solution of a linear problem is polynomial. Furthermore, the worst case complexity has exponential behavior. It has been observed that the simplex algorithm performs sufficiently well in practice, especially on small or medium sized LPs, but its performance is not satisfactory in large-scale LPs. This weakness of simplex algorithm due to the stalling and cycling problem.[\textit{Non è ancora certo uno studio a larga scala su un problema di ottimizzazione della forma.}]\\
Many anti-cycling pivoting rules have been introduced in the past.
Since Dantzig's initial contribution, researchers have made many efforts in order to enhance the performance of simplex algorithm. In the 1980s the monopoly of the simplex algorithm in the solution of the LP has been challenged. Interior point methods were the result of subsequent research and their performance has been more than satisfactory compared to the simplex algorithm. The main idea of IPMs is that the computation of the optimal solution can be achieved by moving inside the feasible region, defined by the constraints. \\
%The next research step was the attempt to combine the simplex algorithm and IPMs in order to enhance the computational behavior of software packages~\cite{2}. \\ 
The thesis is organized as follow:
an introductory section summarizes the basic theory of the linear programming. In the chapter 2 we delineate the simplex method. The chapter 3 is dedicated to the primal-dual interior point methods, taking particular attention to the affine-scaling and the long-path following methods. It is also defined the Mehrotra's predictor-corrector algorithm, which is the basis of much of the current generation of software, even if no convergence theory is available for this algorithm.\\After a theoretical convergence analysis, the implementation illustrates the numerical results that we obtained for the considered physical problems and a comparison is performed.
Concluding, in the last chapter we give an overview of the work realized in this thesis and
suggest possible next steps. 

(\textit{La mia proposta è quella di testare i metodi del punto interno su un problema a larga scala di ottimizzazione della forma (SO), illustrando così la varietà delle applicazioni degli IPM})
%
% CAPITOLO 1
\chapter{Basic theory}

In this first chapter it is presented the standard formulations of a linear programming problem and it is given a brief overview of the LP theory. 
\section{First definitions}
A linear programming problem has a linear objective function and linear constraints that consist of equalities and inequalities.\\
The feasible set satisfying the constraints is a polytope, a convex and connected set with polygonal faces. We say that the linear program is \textit{infeasible} if the feasible set is empty and \textit{unbounded} if the objective function is unbounded below on the feasible region.\\
In general, any linear program can be formulated in the following \textit{standard form}:
\begin{alignat*}{1}\label{eq:stdform}
\text{minimize\;}\; &c_1 x_1 + c_2 x_2+ ... c_m x_m\\[2mm]
\text{subject\;to\;} &a_{11} x_1 + a_{12} x_2+ ... +a_{1m}x_m = b_1\\
&a_{21} x_1 + a_{22} x_2 + ... + a_{2m} x_m= b_2\\
&\vdots\\
&a_{n1} x_1 + a_{n2} x_2 + ... + a_{nm} x_m= b_n\\
\text{and}\; & x_1 \geq 0 , x_2 \geq 0, ... , x_m \geq 0
 \end{alignat*}


where the $b_{i}$, $c_{i}$ \text{and} $a_{ij}$ are fixed real costants.\\ In more compact vector notation, this standard problem becomes 
\begin{equation}\label{Prim}
 \begin{split}
\min\; &c^{T}x\\
\text{subject\;to\;}&Ax = b\;\text{and\;}x\geq0
 \end{split}
\end{equation}

with $x$ an \textit{m}-dimensional column, $c^
{T}$ an \textit{m}-dimensional row vector, \textit{A} an $n \times m$ matrix, and \textit{b} an \textit{n}-dimensional column vector.\\
In the case the constraints set is determined entirely by linear inequalites $Ax \leq b$, hence in a \textit{canonical form}, the problem may be alternatively expressed as:
\begin{alignat*}{3}
\text{minimize\;}&c_1 x_1 + c_2 x_2+ ...+c_m x_m&&&\\[2mm]
\text{subject\;to\;}&a_{11} x_1 +a_{12}x_2 + ... +a_{1m}x_m +y_{1}&&&= b_1\\
		   	&a_{21}x_1+a_{22}x_2+ ... +a_{2m}x_m&+y_{2}&&= b_2\\
&&\;\;\;\vdots&&\\
&a_{n1}x_1+a_{n2}x_2+ ... +a_{nm}x_m+&&&y_{n}=b_n\\
\text{and} \;& x_{i} \geq 0;\;\; y_{j} \geq 0; \text{\;\;for }i \in\left\lbrace 1,...,m\right\rbrace&\text{ and }j&\in&\left\lbrace 1,...,n\right\rbrace.
\end{alignat*}
The new positive variables $\mathit{y_{i}}$, introduced to convert the inequalities, are called \textit{slack variables} and the problem takes the standard form with $n+m$ unknowns variables \begin{itshape}$x_{i}, y_{i}.$\end{itshape}\\ The $n\times(m+n)$ matrix that now describes the linear equality constraints assumes the form $\left[\begin{matrix}A\;\vert\; I\;\end{matrix}\right]$.\\
Considering the system of equalities (2.1) and selecting a set of \textit{n} linearly independent columns from the \textit{m} columns of  $A$, we create a $n \times n$ matrix denoted  by $A_{B}$ and called \textit{basis matrix}. This matrix is nonsingular and we may uniquely solve the equation $A_{B}x_{B} = b$. \\
Recalling $x =\left(x_{B},0_{[m-n]}\right)$, we obtain a solution of the original equality system. This led to the following definition:
\begin{defn}
	The solution $x$ defined above is called \textit{basic solution} with respect to the basis B, it is \textit{feasible} if $x_{B}\geq 0$. \\The components of $x$ associated with columns of B are called \textit{basic variables}. Instead the components associated to $N  = \left\lbrace 1...m\right\rbrace  \backslash B$ are \textit{nonbasic variables}.\\
	A basis B is \textit{degenerate} if $x_{i}= 0$ for some $i\in B$.
	A LP is said to be \textit{degenerate} if has at least one degenerate basis.
\end{defn}
If the $n \times m$ matrix $A$ has $n \leq m$ and the $n$ rows are linear indipendent, then there is at least one basic solution and, accordingly, one solution of the standard problem. Certainly, when we have a canonical form problem, then the extended $n \times (n+m)$ matrix [A | I ] satisfies this statement.

Another important issue is the fundamental theorem of linear programming, that is the primary importance for basic feasible solutions.\\ (The method to prove the theorem is in many respects as important as the result itself, since it represents the beginning of the development of the simplex
method.)
\begin{thm}[\textbf{Fundamental theorem of liner programming}] \ \\
Given a linear program in standard form where A is an $n \times m$ matrix of rank $n$
\begin{enumerate}
\item if there is a feasible solution, there is a basic feasible solution
\item if there is an optimal feasible solution, there is an optimal basic feasible solution.
\end{enumerate}
\end{thm}
The theorem shows that we can only consider basic feasible solutions when seeking an optimal solution, because the optimal value is always achieved at such points.
Thus, it describes a peculiar feature of the linear programming: it reduces the task of solving a linear problem to that of searching over basic feasible solutions. Since for a problem having $m$ variables and $n$ constraints there are at most ${m}\choose{n}$ basic solutions (corresponding to the number of ways of selecting m of n columns), there are only a finite number of possibilities. 

\subsection*{A geometric viewpoint}
The linear programming problem is simple to state and visualize. The set of the linear constraints defines  \textit{polyhedron}, that constitutes the \textit{feasible region} and the \textit{vertices} of this polyhedron are the points that do not lie on a stright line between two other points in the set. Algebraically, the vertices of the feasible set $\mathcal{P}=\lbrace x\; |\; Ax = b , x \geq0\rbrace$ are exactly the basic feasible points.\\ According to the Fundamental theorem, we can restrict our attention to the vertices of this polyhedron and it implies that we can explore only at most  ${m}\choose{n}$ points. 
\begin{ex}
The feasible set of a standard form linear programming problem is defined by the following constraints:
\begin{alignat*}{3}
-x_{1}+&x_{2}-x_{3}&\;&\;&= 0\\
 x_{1}+&\;&+x_{4}\;&\;&= 2\\
 &x_{2}&\;&+x_{5}&= 3\\
x \geq 0&\;&\;&\;&\\
\end{alignat*}
\end{ex}
 [\textit{con una illustrazione grafica del poliedro si mostra l'insieme dei vertici presi in considerazione e candidati punti ottimali}]

\section{Optimality and duality}
Optimality conditions for the LP can be derived from the theory of the constrained optimization related to a general non linear problem NLP, defined as follow:

\begin{equation}
\min f(x)\text{\;subject\;to\;}\begin{cases} c_{i}(x) = 0 &i \in \mathcal{E}\\ c_{i}(x)\leq 0 &i\in \mathcal{I}\end{cases}
\end{equation}
\\
where $f$ and $c_{i}$ are smooth, real-valued functions on subset of $\mathbb{R}^{n}$, and $\mathcal{E}$ and $\mathcal{I}$ are two finite sets of indices.\\ We recall only the first-order conditions, that are needed to explain the duality results for the linear case.\\
As a preliminary to stating the necessary conditions, we define the \textit{Lagrangian function} for the general problem formulated above 
\begin{equation*}
\mathcal{L}\left(x,\lambda\right)=f(x)-\sum_{i\in\mathcal{E}\cup\mathcal{I}}\lambda_{i}c_{i}(x)
\end{equation*}

and the \textit{LICQ conditions}:
\begin{defn}
	Given a point x, $\mathcal{A}(x)= \mathcal{E}\cup\left\lbrace i\in\mathcal{I}\;|\;c_{i}(x) =0\right\rbrace$ is called active set and we say that the linear independence constraint qualification, $LICQ$, holds if the set of active constraint gradients $\left\lbrace \nabla c_{i}(x),,i\in\mathcal{A}(x)\right\rbrace$ is linear indipendent.
\end{defn}
The necessary conditions, defined in the following theorem, are called \textit{first-order conditions} because they are concerned with properties of the gradients of the objective and constraint functions.
\begin{thm}
Suppose that $x^{*}$ is a local solution of (1.1), that f and $c_{i}$ are continuously differentiable, and the LICQ holds at $x^{*}$. Then there is a Lagrange multiplier vector $\lambda^{*}$, such that 
\begin{alignat*}{2}
\mathcal{L}(x^{*},\lambda^{*})&=0&\\
c_{i}(x^{*})&=0, &\forall i\in\mathcal{E}\\
c_{i}(x^{*})&\geq 0, &\forall i\in\mathcal{I}\\
\lambda&\geq 0, &\forall i\in\mathcal{I}\\
\lambda^{*} &\geq 0 & \forall \in\mathcal{I}\\
\lambda^{*}c_{i}(x^{*})&= 0,\;\forall i&\in\mathcal{E}\cup\mathcal{I}.\\
\end{alignat*} 
\end{thm}

These equalites are called \textit{Karush-Kuhn-Tucker} conditions, or \textit{KKT} conditions for short and the last condition is the \textit{complementary condition}.\\ Though this theorem requires LICQ, the result continues to hold for \textit{dependent} constraints provided they are linear, as in the case of the standard LP \cite{W}. The LP Lagrangian function is:\\
\begin{equation}
\mathcal{L}(x,\lambda,s)=c^{T}x-\lambda^{T}\left(Ax-b\right)-s^{T}x.
\end{equation}
Now we illustrate the first-order necessary conditions: let us assume that the matrix $A\in\mathbb{R}^{n,m}$, the vectors $b\in\mathbb{R}^{n}$ and $c\in\mathbb{R}^{m}$ construct a standard LP. A vector $x^{*}$ is a solution if and only if exist Lagrange multipliers $\lambda^{*},\;s^{*}$ such that the primal-dual solution $\left( x^{*},\lambda^{*},s^{*}\right)\in\mathbb{R}^{n}\times\mathbb{R}^{m}\times\mathbb{R}^{n}$ satisfies these conditions, 
\begin{align}
A^{T}\lambda+s&=c\\ \label{(Cost)}
Ax&=b\\ \label{SF}
x&\geq 0\\
s&\geq 0\\
x_{i}s_{i}&=0,\; for\;i= 1,2,...,m. \label{CC}
\end{align} 
The complementary conditions show that at least one of the components $x_{i}$ and $s_{i}$ must be zero for each $i=0,1,2,...,n$.\\
 Convexity of the problem ensures that these conditions are also sufficient for a global minimum, hence the KKT conditions are also \textit{sufficient}: if we have a primal feasible vector $x$, and another vector $(\lambda, s)$ such that the equations are satisfied, then $x$ is the solution of the \textit{primal} problem. We can prove this claim directly by taking an arbitrary primal feasible vector $\bar{x}$ and showing that its objective value is no smaller than $c^{T}x$:
\begin{equation*}
c^{T}\bar{x}=(A^{T}\lambda+s)^{T}\bar{x}=b^{T}\lambda+s^{T}\bar{x}\geq b^{T}\lambda= c^{T}x.
\end{equation*}
We conclude that the KKT conditions are both necessary and sufficient for optimality in the LP. Besides, we find that
\begin{equation*}
	c^{T}x^{*}=\left(A^{T}\lambda^{*}+s^{*}\right)^{T}x^{*}=\left(Ax^{*}\right)^{T}\lambda^{*}=b^{T}\lambda^{*}.
\end{equation*}
With this equality, we can formulate the \textit{dual problem} of (2.1)
\begin{equation}
\begin{split}
&\text{maximize\;} b^{T}\lambda\\
&\text{subject\;to\;}A^{T}\lambda \leq c
\end{split}
\end{equation} 
We can restate this problem in a standard form introducing the slack variables as following:
\begin{equation}\tag{D}
\begin{split}
&\text{maximize\;}b^{T}\lambda\\
&\text{subject\; to\;}A^{T}\lambda+s=c\\ &\text{and\;} s\geq0
\end{split}
\end{equation}
The primal-dual relationship is symmetric: by taking the dual of the dual problem, we recover the primal problem \ref{Prim} that we label briefly with (P).\\
Given a feasible positive vector $x$ satisfying $Ax=b$ and a feasible point $\left(\lambda,s\right)$ for the dual, we have that: $c^{T}x-b^{T}\lambda=\left(c-A^{T}\lambda\right)^{T}x=s^{T}x \geq0$.\\
Therefore we have $c^{T}x\geq b^{T}\lambda$ when both primal and dual variables are feasible, and this result is known as \textit{dual gap}.\\

\begin{thm}[\textbf{Strong duality}] \
\begin{itemize}
\item If either the primal or the dual problem has a finite solution, then so does the other, and the objective values are equal.
\item If either the primal or the dual problem is unbounded, the the other problem is infeasible.
\end{itemize}
\end{thm}
(\textit{le dimostrazioni ancora da scrivere. Riferimento: in [1] capitolo 12}).\\
Hence, for every solution $(x^{*}, \lambda^{*}, x^{*})$ we have $x_{j}^{*}= 0$ and/or $s_{j}^{*}= 0$ for all $j=0,1,\dots,m$.\\
We can define two index sets $\mathcal{B}$ and $\mathcal{N}$ as follows:
\begin{equation}
\mathcal{B} =\{j\in\{1,\dots,m\}|\; x^{*} \not= 0\}, \;
\mathcal{N} =\{j\in\{1,\dots,m\}|\; s^{*} \not= 0\}
\end{equation}  
Obviously, $\mathcal{B}$ and $\mathcal{N}$ are disjoint and form a partition of the indices. Now we state an important theorem:
\begin{thm}[Goldman-Tucker]
	There is at least one solution $(x^{*}, \lambda^{*}, x^{*})$ such that $x^{*}+s^{*}\geq0$.
\end{thm}
The set $\mathcal{B}$ does not necessarily contain $n$ elements, that is the number of the rows of the matrix $A$. This set must not be confused with the set of the basic variables $B$, by the definition (2.1). In the following example, for istance, we have $|\mathcal{B}|= 2$ and three basis sets $B = \{1\}, \{2\}, \{3\}$.
\begin{ex}
Consider
\begin{center} $\min\limits_{x\in\mathbb{R}^{3}} x_{1} \text{\;subject to\;} x_{1}+x_{2}+x_{3} = 1, x\geq 0$.\end{center}
The primal solution is $x^{*}=(0, t, 1-t)$, for $t\in(0,1)$. 	
\end{ex} 

The multipliers $(\lambda,s)$ indicate the sensitivity of the optimal objective value  to perturbations in the constraints and the process of finding them is called \textit{sensitivity analysis}. \\ In fact, let we assume a small perturbation of input data, for example $b + \Delta b$. If $\Delta x$ and $\Delta s$ have zero in the same entries as $x$ and $s$ respectively, then
\begin{equation*}
0=x^{T}s=x^{T}\Delta s= \left( \Delta x\right)^{T}s=\left( \Delta x\right)^{T}\Delta s
\end{equation*}
and by the theorem we have that the optimal objectives of the primal and dual problems are equal, for both the original and perturbated problems, so

\begin{align*}
&c^{T}x=b^{T}\lambda  &c^{T}(x + \Delta x)=\left(b+\Delta b\right)^{T}\left(\lambda+\Delta \lambda\right).
\end{align*}
with, by the feasibility of $x + \Delta x$ and $\lambda+\Delta \lambda$:
\begin{align*}
&A(x + \Delta x)=b+\Delta b
&A^{T}\Delta\lambda=-\Delta s.
\end{align*}
Hence, the change in optimal objective due to the perturbation is as follows:
\begin{align*}
c^{T}\Delta x&=\left(b+\Delta b\right)^{T}\left(\lambda+\Delta \lambda\right) - b^{T}\lambda\\
&=\left(b+\Delta b\right)^{T}\Delta \lambda+\left(\Delta b\right)^{T}\lambda\\
&=\left(x+\Delta x\right)^{T}A^{T}\Delta \lambda+\left(\Delta b\right)^{T}\lambda\\
&=\left(x+\Delta x\right)^{T}\Delta s+\left(\Delta b\right)^{T}\lambda\\
&=\left(\Delta b\right)^{T}\lambda.\\
\end{align*} 
In particular, if $\Delta b = \epsilon e_{j}$, we have that $c^{T}\Delta x+\epsilon \lambda_{j}$ and it shows that the change in optimal objective is $\lambda_{j}$ times the perturbation to $b_{j}$.
\begin{thm}[\textbf{Complementary slackness}] \ \\
	Let $x^{*},(\lambda^{*},s^{*})$ be feasible for the primal and the dual problems. The following are equivalent:
	\begin{itemize}
		\item $x^{*}$ is an optimal solution to (P) and $(\lambda^{*},s^{*})$ is an optimal solution to (D).
		\item $(x^{*})^{T}s^{*}=0$
		\item $x^{*}_{j}s^{*}_{j}=0,\;\forall\; j=0,...,m$
		\item If $s^{*}_{j} > 0$ then $x^{*}_{j}= 0$.
	\end{itemize}
\end{thm}

After having delineated the basic tools of the multipliers in terms of sensitivity, the sensitivity analysis is developed later, examining the optimal results obtained by the methods designed.\\

[\textit{Ci sono altri due teoremi che completano il capitolo sulla dualita', ma non utilizzati nella ricerca. Capitolo da perfezionare. L'analisi di sensitività verrà svolta dopo aver introdotto i metodi.}]
%
%  CAPITOLO 2
%
\chapter{The simplex method}
The simplex method was introduced in 1947 by George Dantzig. The discover of this method happened simultaneously with the realization of linear programming as an efficient modeling tool for practical decision making.\\
The method exploits the insight provided by the fundamental theorem
of linear programming, which states that if it exists an optimal solution, it is at one of the vertices of the feasible polyhedron. The simplex method's strategy is checking only basic feasible point and, since the number of vertices is finite, the termination is guaranteed.\\
We begin the simplex method making a partition of the m-elements vectors $x$ and $c$ and the matrix $A$, with \textit{B} the basis set:
\begin{equation}
\begin{split}
\text{minimize\;} &c^{T}_{B}x_{B}+c^{T}_{N}x_{N}\\
\text{subject\;to\;}&A_{B}x_{B}+A_{N}x_{N} = b\text{\;and\;}x_{B}, x_{N}\geq0
\end{split}
\end{equation}
 %with \textit{n} elements corresponding to the basic feasible point we are starting from.
 \\Note that for any $x$ we have $x_{B}=A_{B}^{-1}b-A_{B}^{-1}A_{N}x_{N}$ and the cost function becames $c^{T}x=c_{B}^{T}A_{B}^{-1}b+(c_{N}-A_{N}^{T}A_{B}^{-T}c_{B})^{T}x_{N}$, denoting the \textit{reduced cost} by $\widetilde{c}=c_{N}-A_{N}^{T}A_{B}^{-T}c_{B}$.\\ Since we are dealing only with basic feasible points, we consider the relative basic feasible point $x$ with $x_{N}= 0$ and the cost value it is exactly $\widetilde{c}$.\\
 We can choose the dual points $(\lambda,s)$ such that $(x, \lambda, s)$ satisfies the KKT condition as well: we set $s_{B}= 0$ for the complementary condition, therefore we get $s_{N}= c_{N}- A_{N}^{T}\lambda$ from \ref{(Cost)}. Since $A_{B}$ is not singular, \ref{(Cost)} uniquely defines $\lambda$ as $\lambda = A_{B}^{-T}c_{B}$, then, we can state that the reduced cost is identical to $s_{N}$.\\  
 
 If there exists a $j \in N$ such that $\widetilde{c}_{j} \leq 0$, then by increasing $x_{j}$ up from zero, we will decrease the value of the objective function.\\
So, in a step of the method, we find a $s \in N$ such that $\widetilde{c}_{s} \leq 0$, and increase it as much as possible while keeping $x_{B} \geq 0$. We enforce that this non-basic variable $x_{s}$ is now positive and we include it in the basis $B$.
In the next step we keep increasing $x_{s}$ until one of the components of $x_{B}$, for istance $x_{r}$, is driven to zero: the index $r$ is removed from $B$ and replaced it with $s$. This process of selecting entering and leaving indices is called \textit{pivoting rule}. \\
On the other hand, if there is no $j \in N$ such that $\widetilde{c}_{j} \leq 0$, then we stop and the current basic feasible solution is an optimal solution. \\
Formalizing the pivoting rule in algebraic terms, we have the new iterate $\bar{x}$ and the current $x$ feasible points such that $\bar{x}_{i} = 0$ for $i \in N\backslash\{s\}$, then we have 
\begin{align*}
	A\bar{x} = A_{B}\bar{x}_{B} +A_{s}\bar{x}_{s} = A_{B}x_{B} = Ax \text{  then }
	\bar{x}_{B} = x_{B} - A_{B}^{-1}A_{s}\bar{x}_{s}.
\end{align*}
Geometrically speaking, $\bar{x}_{B}$ is a move along an edge of the feasible polyhedron that decreases $c^{T}x$. We continue to move along the edge until a new vertex is encountered. At this vertex, we have $x_{s}\geq0$ and one of the components $x_{r}\in B$ decreased to zero.\\
It is possible that we can increase $x_{s}$ to $\infty$ without encountering a suitable $x_{r}$, that means the contraint $x_{\bar{B}} = x_{B} - A_{B}^{-1}A_{s}\bar{x}_{s} \geq0$ holds for all positive values of $\bar{x}_{s}$. When it happens, the LP is \textit{unbounded}: the cost value $c^{T}x$ decreases to $-\infty$.\\
The computational procedure is the following:
\begin{algorithm}
	\caption{Simplex algorithm}
	\begin{algorithmic}[1]
		\State \textbf{Given} $B, N, x_{B} = A_{B}^{-1}b\geq 0$ with $x_{N}=0$;
		\State Solve $A_{B}^{T}\lambda = c_{B}, \text{ for }\lambda$
		\State Compute $\widetilde{c}_{N}=c_{N}-A_{N}^{T}\lambda$
		\If {$\widetilde{c}_{N}\geq 0$} optimal solution found \textbf{stop}; 
		\Else
		\State 	Select $s\in N\;|\;\widetilde{c}_{s}\leq 0$ as the entering index;
		\State Solve $A_{B}d = A_{s}$ for $d$;
		\If {$d \leq 0$} the problem is unbounded \textbf{stop};
		\Else 
		\State Calculate the ratio test $\bar{x}_{r} = \min_{i | d_{i} > 0}(x_{B})_{i}/d_{i}$, and \State use $t$ to denote the minimizing $r = B[t]$;
		
		\State Update $\bar{x}_{B} = x_{B}-d\bar{x}_{r}$
		\State $\;\;\;\;\;\;\;\;\;\;\;\;\bar{x}_{N} = (0,...,0_{[s-1]},\bar{x}_{r},0_{[s+1]},...,0)$
		\State Update sets: $\bar{B} = B \ B[t] + \{s\}$ and $\bar{N} = N - \{s\} + B[t]$	
		\End
	\end{algorithmic}
\end{algorithm}
\\
Summarizing, the simplex algorithm moves from basic feasible solution to another one and it moves from one vertex to an adjacent one, for which the basis $B$ differs inexactly one component. Each iteration begins by checking the sign of the coefficients of the objective function $\widetilde{c}$ on non-basic variables: if none is negative, then the current basic solution is optimal. \\
As we see, it is required a basic feasible staring point $x$ and a corresponding initial basis $B \in \left\{ 1,2,..., m \right\}$ with $|B|=n$ such that $A_{B}$ is non singular, $A_{B}^{-1}b=x_{B} \geq 0$ and $x_{N}=0$.\\
A basic feasible solution is sometimes immediately available for linear programs. For example, in problems with constraints in canonical form and with $b \geq 0$, we have a basic feasible solution corresponding to the standard form is provided by the slack variables and this provides a means for initiating the
simplex procedure.\\Sometimes the problem of finding an initial point and a basis may itself nontrivial but the \textit{two-phase} method deals with this difficulty. The idea is to add artificial variables in order to give a basic feasible initial point for a second phase in which we can extract easily the solution of the original problem.\\
In \textit{phase I} we solve the following problem:
\begin{equation}
\begin{split}
\min &\;1^{T}u\\
\text{subject\;to\;}&A_{B}x_{B}+A_{N}x_{N} + \textbf{Eu} = b\;\text{and\;} u\geq 0\\
\text{with\;} E_{jj}& =\begin{cases} -1\;\text{if\;} b_{j} \leq 0\\
0\;\; \text{otherwise}
\end{cases}   
\end{split}
\end{equation} \\
Using artificial variables in each violated constraint, it is easier to complete a starting feasible point. Since they are restricted to be nonnegative, the objective value is as well. If this last one is zero, then the \textit{phase I} terminates and we compute a second linear program (\textit{Phase II}).\\
The point $(x,z)$, defined by $x = 0$ and $z_{j} = |b_{j}| \text{\;with\;}j =\{1,2,...,n\}$, is a basic initial feasible point, corresponding to the basis $B = \{m-n,...,m\}$. At any feasible point for (3.2), the artificial variable $u$ represents the amounts by which the constraints $Ax = b$ are violated by the $x$ component and the objective function is the sum of these violations. \\
The \textit{phase I} minimizes this sum and it has an optimal objective value of zero if and only if the original LP is feasible. \newpage In fact we have two cases at the optimal solution $\bar{u}$: 
\begin{itemize}
	\item[-]$1^{T}\bar{u}$ is zero: the simplex method finds a solution $(\bar{x},\bar{u})$ with $\bar{u}=0$ and it starts the \textit{phase II} step with initial point $\bar{x}$.
	\item[-]$1^{T}\bar{u}$ is positive and the original problem is unfeasible.
\end{itemize}
If we get in the first case, after dropped all the artificial variables $\bar{u}$, we proceed with the second phase: it consists on an implementation of the simplex method, with starting feasible point $\bar{x}$.\\ 
While two-phases method deals with feasibility and optimality separately, the \textit{Big-M} method combines these activities in a single search and the key is a composite objective function: the original one added the artificial variable sum times  large positive multiplier M:\\
\begin{equation}
\text{minimize\;}\mathbf{c^{T}x+M \sum_{i}{u}_{i}}\\
\end{equation}  
 \section{Degenerate steps}
The simplex method may encounter situations in which $-d_{r} = \left( A_{B}^{-1}A_{s}\right)_{r} < 0$ but $(A_{B}^{-1}b)_{s}= 0$. At this step, called \textit{degenerate step}, the objective function $c^{T}x$ may not decrease and, after a number of successive degenerate steps, we may return to the original basis $B$. \\
A. Charnes \cite{Lexico2} developed a technique of perturbation, that resulted in a finite simplex algorithm. This algorithm turned out to be equivalent to the lexicographic rule. The \textit{perturbation strategy} avoids this cycling: it consists on adding a small perturbation to the right-hand side of constraints, as follows:
\begin{equation*}
b(\epsilon) \vcentcolon= b + A_{B}
\begin{bmatrix}
\epsilon\\\epsilon^{2}\\\vdots\\\epsilon^{m}
\end{bmatrix}
\end{equation*}
where $\epsilon$ is a very small positive number. This perturbation in the components of the basic solution vector; we have
\begin{equation*}x_{B}(\epsilon) \vcentcolon= x_{B} + A_{B}
\begin{bmatrix}
\epsilon\\\epsilon^{2}\\\vdots\\\epsilon^{m}
\end{bmatrix}
\end{equation*}
Hence, we have that for all $\epsilon$ sufficiently small, $(x_{B^{+}})>0$. The basis is nondegenerate for the perturbed problem, and we can perform a step of the simplex method that produces a nonzero decrease of the object value.\\
The question remains of how to choose $\epsilon$ small enough at the point at which the original degenerate basis B is encountered. The \textit{lexicographic strategy} finesses this issue by not making an explicit choice of $\epsilon$, but rather keeping track of the dependence of each basic variable on each power of $\epsilon$. When it comes to selecting the leaving variable, it chooses the index $s$ that minimizes $x_{B}(\epsilon)_{i}/d_{i}$ over all variables in the basis, for a sufficient small $\epsilon$.\\
Another method that avoids this cycling is the \textit{Bland's rule}. In the algorithm it selects:
\begin{itemize}
	\item the index that leaves the nonbasis $s$ such that $\min\limits_{i}\{c_{i}\leq0\}$
\item the index that leaves the basis $r$ such that $\bar{x}_{r} = \min\limits_{q}\{\bar{x}_{q}\;|\;\bar{x}_{q}^{+} \text{\;satisfies the ratio test} \}$ \end{itemize} 
\begin{theorem*}
	The simplex method always terminates provided that both the entering and the leaving variable are chosen according to the Bland's rule.
\end{theorem*}
\begin{proof}
to write ~\cite{LP} pagg. 36-37	
\end{proof}
In the implementation of the simplex method it is implemented the Bland's rule and in the following example is illustrated the results:
\begin{ex}
	We apply the method to the Beale's problem (1955): %~\cite{}:
	\begin{alignat*}{4}
	\min -\frac{3}{4}x_{1}&+150x_{2}&-\frac{1}{50}x_{3}&+6x_{4}&\\
	\text{such that\;}\frac{1}{4}x_{1}&-60x_{2}&-\frac{1}{25}x_{3}&+9x_{4}&\leq 0\\
	\frac{1}{2}x_{1}&-90x_{2}&-\frac{1}{50}x_{3}&+3x_{4}&\leq 0\\
	&\;&x_{3}&\;&\leq 1\\
	x&\;&\;&\;&\geq 0\\
	\end{alignat*}
	
Applying Bland's rule, we find optimal solution at $x^{*} = [0.04, 0,  1,   0,  0.03, 0,   0  ]$ in the basis $B = [0, 2, 4]$ after 7 iterations: the optimal cost value is $c^{T}x^{*} = -0.5$.\\
\begin{center}
\begin{array}{ | l | l | l | l | }
	\hline
	\text{iteration} & \text{Current Basis} & \text{Current x} & \text{Current cost value} \\ \hline
	1 & [4, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	2 & [0, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	3 & [0, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	4 & [2, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	5 & [2, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	6 & [2, 3, 0] & [0.016 0.    1.    0.004 0.    0.    0.   ] & -0.008 \\ \hline
	7 & [2, 4, 0] & [0.04 0.   1.   0.   0.03 0.   0.  ] & -0.050 \\ \hline
\end{array}

\end{center}
Instead without the rule, after 18 iterations the simplex method returns to the same basis sequence, entering in a cycle: the original simplex method repeats the same sequence of six pivotis indefinitely, making no progress toward the solution.
\begin{center}
\begin{array}{ | l | l | l | l | }
	\hline
	\text{iteration} & \text{Current Basis} & \text{Current x} &\text{Current cost value} \\ \hline
	1 & [4, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	2 & [0, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	3 & [0, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	4 & [2, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	5 & [2, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	6 & [4, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	7 & [4, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	8 & [0, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	9 & [0, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	10 & [2, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	11 & [2, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	12 & [4, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	13 & [4, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	14 & [0, 5, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	15 & [0, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	16 & [2, 1, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	17 & [2, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
	18 & [4, 3, 6] & [0. 0. 0. 0. 0. 0. 1.] & 0 \\ \hline
\end{array}
\end{center}
\end{ex} 

\section{The revised method}
If the matrix A has far fewer rows than column, ($n$ is much smaller than $m$), the implementation $A_{B}^{-1}A_{N}$ requires useless memory. The revised simplex method is a scheme reduces this big amount of calculations, replacing only one column of the old matrix $A_{B}$ by the new column from $A_{N}$.\\

 \section{The dual simplex method}
%Leke~\cite{Lem} developed the dual simplex method in 1954 but it was not found to be an alternative to the primal simplex method for nearly 40 years. This changed in
%due to the contributions of Forrest and Goldfarb.
After discussing the Karush-Kuhn-Tucker optimality conditions for linear programming, we derive the \textit{dual simplex method} by applying the simplex method to the dual formulation of the standard form LP. 
\\
(\textit{I metodi simplesso rivisto e simplesso primale duale sono ancora da implementare e studiare. Essi possono essere approfonditi eventualmente dopo aver completato la parte dello studio degli IPM})


\chapter{Interior point methods}
In the 60 years of research since the introduction of the simplex method, this algorithm has been carefully optimized to perform extremely well in practice. However, a problem arose in the 1970s: it turns out that we cannot guarantee that it will work well on all possible linear programs~\cite{3}.
This problem led to the introduction of the interior point methods for solving linear programs, which is the argument of this chapter.\\The interior point methods is a family of algorithms solving linear programs which come along with an efficient performance guarantee. They share common features that distinguish them from the simplex method. Each interior point iteration is expensive to compute but can make significant progress toward the solution, while the simplex method usually requires a larger number of inexpensive iterations. Geometrically, the simplex method works around the boundary of the feasible polytope, testing a sequence of vertices in turn until it finds the optimal one. Instead, interior point methods approach the boundary of the feasible set only in the region, but they never actually lie on the boundary of the feasible set.\\
The first commercial interior point method for linear programming was N. Karmarkar's  \textit{projective transformation} procedure \cite{Kar} and developments have continued to these days. 
%The new algorithms can be divided in two main classes, \textit{affine-scaling} and \textit{projective-scaling} algorithms.
%The first ones are easy to describe but hard to analyze, in fact they have very simple, geometrically descriptions, but they don't have a strong convergence theory behind.
%Instead, the second class, that includes the original algorithm studied by Karmakar, involves technicalities such as logarithmic barrier functions and the analysis proceeds to a proof of polynomial-time convergence~\cite{4}.
By the early 1990s, a subclass of IPMs called \textit{primal-dual methods} had distinguished themselves as the most efficient practical approaches. The primal-dual interior point algorithm was introduced by Megiddo \cite{meg}  who used logarithmic barrier methods to solve
the primal and dual problems simultaneously. An efficient
high-order method was proposed by Mehrotra: his second-order predictor-corrector
strategy, that has been incorporated in all primal-dual type implementations \cite{MER} .\\ 
After a brief introduction of the primal-dual methods, we present in this research three important algorithms: the \textit{primal-dual affine scaling}, the \textit{long-path following} and the \textit{Mehrotra predictor-corrector} method.\\
An overview of the details of the first two interior-point algorithms are given in the following chapter, instead no convergence thoery is availabe for the third one. With practical implementations a comparison will be discussed.
%The lack of theoretical analysis of the Mehrotra's algorithm leads to a study  their reliability both in theory and in practice will be shown 

\newpage
\section{Introduction to primal-dual methods}
We consider the linear programming problem formulated in a standard form. \\
Following a fundamentally different approach from the simplex method, the interior-point methods avoid the boundary of the polytope until optimality, and focus on the KKT conditions, solving the primal and dual LP currently.
Primal and dual variables  $x^{k}$ and $s^{k}$ , that are required to be nonnegative at the solution, are kept strictly positive at each iteration and this property is the origin of the term \textit{interior point}.\\
The primal-dual methods find primal-dual solutions $(x^{*},\lambda^{*},s^{*})$ by applying variants of Newton's method to the three equality conditions \ref{(Cost)}, \ref{SF}, \ref{CC}, and modifying the search directions and the step lengths so that the inequality $(x,s)>0$ is satisfied.\\
 Let restate the optimality conditions by a mapping $\mathit{F}$ from $\mathbb{R}^{2n+m}$ to $\mathbb{R}^{2n+m}$:
\begin{center}\label{F}
	$\mathit{F}(x,\lambda,s)= \begin{bmatrix}
	A^{T}\lambda+s-c \\Ax-b \\XSe
	\end{bmatrix}=0$, with $(x,s)\geq0.$
\end{center}
where $X = diag(x_{1}, x_{2},...,)$ and $S = diag(s_{1}, s_{2},...,)$.\\ Note that $\mathit{F}$ is linear in the first two equations and mildly nonlinear in the last equation. \\ All primal-dual methods generate iterates $(x^{k},\lambda^{k},s^{k})$ with\\
If we define the primal-dual \textit{feasible set} $\mathcal{F}$ and \textit{strictly feasible set} $\mathcal{F}^{o}$ by
\begin{align*}
\mathcal{F} = \left\lbrace(x,\lambda,s)\;|\;Ax = b, A^{T}\lambda+s =c,\;(x,s)\geq0\right\rbrace \\
\mathcal{F}^{o} = \left\lbrace(x,\lambda,s)\;|\;Ax = b, A^{T}\lambda+s =c,\;(x,s)>0\right\rbrace 
\end{align*}

the strict feasibility condition can be written concisely as $(x,\lambda,s)\in\mathcal{F}^{o}$.\\
However, many LP have \textit{no} strictly feasible points, that is $\mathcal{F}^{o}=\emptyset$, although hey still may be feasible $(\mathcal{F}=0)$ and still my have finite optimal solutions.
\begin{ex}
	\begin{equation*}
	\min\limits_{x\in\mathbb{R}^{3}} x_{1} \text{subject to }x_{1} + x_{3} = 0, x\geq0
	\end{equation*}
\end{ex}
Although many primal-dual algorithms require a strictly feasible starting point...
The Newton's method forms a linear model for $\mathit{F}$ around the current point and obtains the search direction $(\Delta x,\Delta \lambda,\Delta s)$ by solving the following system of linear equations:
\begin{center}
	$\mathit{J}(x,\lambda,s)\begin{bmatrix}
	\Delta x\\\Delta\lambda \\\Delta s
	\end{bmatrix}=-\mathit{F}(x,\lambda,s)$,
\end{center}
where $\mathit{J}$ is the Jacobian of $\mathit{F}$. If the current point is strictly feasible, the Newton step equations becomes

\begin{equation}\label{(5.1)}
	\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
	\end{bmatrix}\begin{bmatrix}
	\Delta x\\\Delta\lambda \\\Delta s
	\end{bmatrix}=-\begin{bmatrix}
	0\\0\\XSe
	\end{bmatrix}.
\end{equation}

A full step along this direction usually is not permissible, since it would violate the bound $(x,s)>0$. To avoid this difficulty, we perform a line search along the Newton direction so that the new iterate is
\begin{equation*}
	(x,\lambda,s) +\alpha (\Delta x,\Delta \lambda,\Delta s)
\end{equation*} 
for some line search parameter $\alpha \in (0,1]$. \\We maintain positivity conditions of $(x,s)$ at all iterates for two reasons. First, vectors that solve $\mathit{F}$ that have negative components are of no interest in terms of solving the primal and dual problems (2.1) and (2.10). Second, when the matrix $A$ has linearly indipendent rows, the Jacobian $J$ is guaranteed to be nonsingular whenever $x>0$ and $s>0$ hold, and so the solution is guaranteed.

\section{Affine-scaling method}

The simplest primal-dual approach is to apply Newton's method directly to the function $F$, using a step length $\alpha_{k}$ of less than one in order to have $(x^{k+1},\lambda^{k+1},s^{k+1})\in \mathcal{F}^{o}$. There are different ways to do this, and the resulting algorithms are called \textit{primal-dual affine-scaling methods}.\\ 
 The general primal-dual affine-scaling algorithm takes the following form:
\begin{tabbing}
	\textbf{Given} $(x^{o}, \lambda^{o}, s^{o})\in\mathcal{F}^{o}$ \\
	\textbf{for} \= $k = 0, 1, 2,...$ \\
	\> Solve
\end{tabbing}
\begin{equation}\label{(AS)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
\end{bmatrix}\begin{bmatrix}
\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\X^{k}S^{k}e
\end{bmatrix}
\end{equation}
\begin{tabbing}
	\\
	\textbf{Set} \=$(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$\\
	\> choosing $\alpha_{k}$ so that $(x^{k+1},\lambda^{k+1}, s^{k+1})\in\mathcal{F}^{o}$ \\
	\textbf{end}
\end{tabbing}
(\textit{Questo metodo è analizzato solo dal punto di vista teorico. Dal punto di vista applicativo verranno messi a confronto: metodo del simplesso, metodo LPF e algoritmo di Mehrotra})


The solution of this system $\left(\Delta x^{k},\Delta\lambda^{k},\Delta s^{k}\right)$ has either $\Delta x_{i}^{k}<0$ or $\Delta s_{i}^{k}<0$, or both because $x^{k}>0$ and $s^{k}>0$ and $s^{k}_{i}\Delta x^{k}_{i} + x^{k}_{i}\Delta s^{k}_{i} = - x^{k}_{i}s^{k}_{i}$, by the last block row of this system.\\
Then, we need to choose $\alpha_{k}$ such that
\begin{align*}
x^{k}_{i} + \alpha_{k} \Delta x^{k}_{i} >0 \\
s^{k}_{i} + \alpha_{k} \Delta s^{k}_{i} >0 \\	\text{for\;} i = 1,...,n.
\end{align*}
and the largest value of $\alpha_{k}$ that satisfies these inequalities is computed by the following formula, which is similar to the ratio test used by the simplex method. 
\begin{align*}
\alpha_{\max} = \min\bigg(\min_{i|\Delta x^{k}_{i}<0}\frac{x^{k}_{i}}{\Delta x^{k}_{i}}, \min_{i|\Delta s^{k}_{i}<0}\frac{s^{k}_{i}}{\Delta s^{k}_{i}}\bigg)
\end{align*} 

We can step back from this maximum value, and prevent each $x_{i}$ and $s_{i}$ from being too close to zero, by defining $\alpha_{k} = min\left(1,\eta_{k}*\alpha_{max}\right)$, with $\eta_{k}$ usually $0.999$.\\
We then define the new iterate $(x^{k},\lambda^{k},s^{k}) +\alpha^{k} (\Delta x^{k},\Delta \lambda^{k},\Delta s^{k})$.\\
This approach is called \textit{primal-dual affine scaling} and often does not allow us to make much progress toward a solution. Even though, the search direction steps are used to find the predictor directions in the predictor-corrector algorithms, explained in the next pages. 
Most primal-dual methods use less aggressive Newton search direction, making a perturbation of the system $F$, and they are presented in the next section.

\section{Path-following methods}

Another strategy for solving a linear program is to follow a central path from a given initial primal-dual solution point.\\ Assuming $\mathcal{F}^{o}\neq \varnothing$, the \textit{central path} $\mathcal{C}$ is an arc of strictly feasible points that play an important role in the following primal-dual algorithm. It is parametrized by a scalar $\tau  > 0$ and each point $(x_{\tau}, \lambda_{\tau}, s_{\tau})\in \mathcal{C}$ satisfies the following equations:
\begin{align}
A^{T}\lambda+s&=c\\
Ax&=b\\
x&\geq 0\\
s&\geq 0\\
x_{i}s_{i}&= \tau,\; \text{for}\;i= 1,2,...,n.\label{(Tao)}
\end{align} 
The conditions (5) are also the optimality conditions for  logarithmic-barrier formulation of the original problem:
\begin{equation}
\begin{split}
\text{minimize\;} &c^{T}x + \tau\sum_{i=0}^{n}\ln{x_{i}}\\
\text{subject\; to\;}&Ax = b\;\text{and\;} x\geq0
\end{split}
\end{equation}
In fact, the KKT conditions for this problem, with Lagrange multiplier $\lambda$ for the equality constraint, are
\begin{equation*}
c_{i} - \dfrac{\tau}{x_{i}} - A^{T}_{i}\lambda,\; \text{for}\;i = 1,2,...,n.
\end{equation*}  
Since the objective function is strictly convex, these conditions are sufficient as well as necessary for optimality. Besides, defining $s_{i} = \dfrac{\tau}{x_{i}}$, we recover the last KKT equation.
\\
\\
Let $(x(\tau), \lambda(\tau), s(\tau))$ be on the primal-dual path $\mathcal{C}$, then the non negative dual gap assumes this value: $c^{T}x-b^{T}\lambda=\left(c-A^{T}\lambda\right)^{T}x=s^{T}x=\tau$.\\
Then, the dual gap provides a measure of closeness to optimality. It is clear that as $\tau\to0$ the duality gap goes to zero, and hence both $x(\tau)$ and
 $(\lambda(\tau), s(\tau))$ approach to optimality for the primal and dual, respectively. The central path guides us to a solution along a route that maintains positivity of the $x$ and $s$ components and decreases the pairwise products $x_{i}s_{i},\;i = 1,2,...,n$ to zero at the same rate.\\
Most primal-dual methods define $\tau$ as the average value of the point $(x_{1}s_{1},x_{2}s_{2}...,x_{n}s_{n})$. Precisely, they compute the Newton step toward a point $(x_{k}, \lambda_{k},s_{k})$ such that $x_{i}s_{i}=\sigma\mu$, where $\mu$ is the \textit{duality measure} and $\sigma\in[0,1]$ is the \textit{centering parameter}. The general path-following algorithm is:
\begin{tabbing}
\textbf{Given} $(x^{o}, \lambda^{o}, s^{o})$ with $(x^{o}, s^{o})>0$;\\
\textbf{for} \= $k = 0, 1, 2,...$ \\
\> Choose $\sigma_{k}\in[0,1]$ and solve
\end{tabbing}
\begin{equation}\label{(5.8)}
	\begin{bmatrix}\label{P}
	0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
	\end{bmatrix}\begin{bmatrix}
	\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
	\end{bmatrix}=-\begin{bmatrix}
	A^{T}y^{k}+s^{k}-c\\Ax^{k}-b\\-X^{k}S^{k}e + \sigma_{k}\mu_{k}e
	\end{bmatrix}.
\end{equation}
\begin{tabbing}
	\\
	\textbf{Set} \=$(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$\\
	\> Choosing $\alpha_{k}$ so that $(x^{k+1}, s^{k+1})>0$ \\
	\textbf{end}
\end{tabbing}
A path-following algorithm explicity restricts the iterates to a neighborhood of the central path $\mathcal{C}$: if $\sigma = 1$, the equations define a \textit{centering direction}, a Newton step toward the point $(x_{\sigma\mu},\lambda_{\sigma\mu}, s_{\sigma\mu})\in\mathcal{C}$, if $\sigma = 0$ then we have the \textit{affine-scaling method}.\\ Many algorithms use intermediate values of $\sigma$ in $(0,1)$ to trade off between the twin goals of reducing $\mu$ nd improving centrality. The neighborhood excludes points $(x, s) $ that are too close to the boundary of the nonegative orthant. Therefore, search directions calculated from any point in the neighborhood make at least minimal progress toward the solution set.
 We define the two most interesting neighborhoods of the central path as given
by Mizuno et al~\cite{5}:\\
\begin{equation*}
\mathcal{N}_{2}(\theta) =\{(x, \lambda,s)\in\mathcal{F}^{o} \;|\;\lVert XSe - \mu e \rVert \leq \theta \mu \}, \text{\;for some\;} \theta \in [0,1)
\end{equation*} 
\begin{equation*}
\mathcal{N}_{-\infty}(\gamma) =\{ (x, \lambda,s)\in\mathcal{F}^{o} \;|\; x_{i}s_{i} \geq \gamma \mu \}, \text{\;for some\;} \gamma \in [0,1),
\end{equation*} 
It is important to underline the importance of the first set: it is more restrictive, since $\mathcal{N}_{2}(\theta) \subset\mathcal{F}^{o}$, for all $\theta\in[0,1)$.\\
In this research it will be proposed the \textit{long-step path-following algorithm}, that combines flexibility in the choice of step length with the use of $\mathcal{N}_{-\infty}(\gamma)$, for some $\gamma$ close to zero. It depends on two parameters $\sigma_{min}$, $\sigma_{max}$, which are lower and upper bounds on the centering parameter $\sigma_{k}$. After computed the search direction with the Newton method, the step length $\alpha_{k}$ is chosed as the maximum value subject to staying inside $\mathcal{N}_{-\infty}(\gamma)$.
%\begin{tabbing}
%	\textbf{Given} $\gamma, \sigma_{min}, \sigma_{max}$ and $(x^{o}, \lambda^{o}, s^{o})\in\mathcal{N}_{-\infty}(\gamma)$ with $(x^{o}, s^{o})>0$;\\
%	\textbf{for} \= $k = 0, 1, 2,...$ \\
%	\> Choose $\sigma_{k}\in[\sigma_{min},\sigma_{max}]$ and solve
%\end{tabbing}
%\begin{equation}\label{(5.9)}
%\begin{bmatrix}
%0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
%\end{bmatrix}\begin{bmatrix}
%\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
%\end{bmatrix}=-\begin{bmatrix}
%0\\0\\-X^{k}S^{k}e + \sigma_{k}\mu_{k}e
%\end{bmatrix}
%\end{equation}
%\begin{tabbing}
%	\textbf{Set} \=$(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$\\
%	\> Choosing the largest value in $\alpha_{k}\in[0,1]$ so that $(x^{k+1}, \lambda^{k+1}, s^{k+1})\in\mathcal{N}_{-\infty}(\gamma)$\\
%	\textbf{end}
%\end{tabbing}
\begin{algorithm}
	\caption{Long-path following algorithm}
	\begin{algorithmic}[1]		
		\State Given: $\gamma, \sigma_{min}, \sigma_{max}$ and $(x^{o}, \lambda^{o}, s^{o})\in\mathcal{N}_{-\infty}(\gamma)$ with $(x^{o}, s^{o})>0$;
	\For{$k = 1,\dots$}
		\State Choose $\sigma_{k}\in[\sigma_{min},\sigma_{max}]$ and solve
		\State $\begin{bmatrix}
			0&A^{T}&I \\A&0&0\\X^{k}&0&S^{k}
			\end{bmatrix}\begin{bmatrix}
			\Delta x^{k}\\\Delta\lambda^{k} \\\Delta s^{k}
			\end{bmatrix}=-\begin{bmatrix}
			0\\0\\-X^{k}S^{k}e + \sigma_{k}\mu_{k}e
			\end{bmatrix}$
		\State $(x^{k+1}, \lambda^{k+1}, s^{k+1}) = (x^{k}, \lambda^{k}, s^{k})+ \alpha_{k}(\Delta x^{k}, \Delta\lambda^{k}, \Delta s^{k})$
		\State Choosing the largest value in $\alpha_{k}\in[0,1]$ so that $(x^{k+1}, \lambda^{k+1}, s^{k+1})\in\mathcal{N}_{-\infty}(\gamma)$	
\textbf{end}
	\end{algorithmic}
\end{algorithm}\\
The following lemma shows properties of the points in $\mathcal{N}_{-\infty}(\gamma)$ that are used in the analysis section.
\begin{lem}
	Let $\mu_{0}\geq 0$ and $\gamma\in(0,1)$. Then for all points $(x,\lambda,s)$ with
	\begin{equation*}
	(x,\lambda,s)\in\mathcal{N}_{-\infty}(\gamma)\subset\mathcal{F}^{o}, \;\; \mu \leq \mu_{0}
	\end{equation*}
	there are constants $C_{0}$ and $C_{1}$ such that
\begin{align*}
\lVert(x,s) \rVert&\leq C_{0}\\0< x_{i}&\leq \mu/C_{1}\;\; (i \in\mathcal{N}),\\
0< s_{i}&\leq \mu/C_{1}\;\; (i \in\mathcal{B}),\\ 
s_{i}&\geq C_{1}\gamma \;\; (i \in\mathcal{N}),\\
x_{i}&\geq C_{1}\gamma \;\; (i \in\mathcal{B}).\\
\end{align*}
\end{lem}
\begin{proof}
~\cite{Wright} pag. 101
\end{proof}
\newpage
\section{Mehrotra's method}
Most interior-point software written since 1990 has been based on Mehrotra's predictor-corrector algorithm.\\
Since Karmarkar's landmark paper \cite{Kar}, IPMs became one of the most active research area that produced a large amount of research results. Moreover, several powerful methods have been developed: predictor-corrector methods are among the most efficient and most implementations are based on a variant of Mehrotra's algorithm. \\
Mehrotra's contribution was to combine the work developed by Montiero, Adles and Resende \cite{MARE} and the infeasible-interior-point path-following approach implemented by Lustig, Marsten and Shanno \cite{LMS}.\\ 
\\
The algorithm concerned generates sequence of infeasible iterates $(x^{k},\lambda^{k},s^{k})$ for which $(x^{k},s^{k})>0$. The search direction at each iteration consists of three components:
\begin{enumerate}
	\item an affine-scaling "predictor" direction.
	\item a centering term whose size is governed by the adaptively chosen centering parameter $\sigma$.
	\item a "corrector" direction that attempts to compensate for some of the nonlinearity in the affine-scaling direction.
	\end{enumerate}
The first two components, the affine-scaling step and the centering term, combine to generate the standard infeasible-interior-point step from the generic equations. However, the affine-scaling component is calculated before the centering component. By arranging the computations in this way, we gain a key advantage: the ability to choose the centering parameter $\sigma$ adaptively rather then a priori, as in the algorithm LPF.\\
If the affine-scaling direction makes good progress in reducing the duality measure $\mu$ while remaining inside the positive orthant defined by $(x,s)>0$, we conclude that little centering is needed, so we choose $\sigma$ close to 1.
\subsection*{The algorithm}
Given a point $(x, \lambda, s)$ with $(x, s)> 0$, we compute the affine-scaling direction:
\begin{equation}\label{(A)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{aff}}\\\Delta\lambda^{\text{aff}}\\\Delta s^{\text{aff}}
\end{bmatrix}=-\begin{bmatrix}
A^{T}\lambda+s-c\\Ax-b\\XSe
\end{bmatrix}.
\end{equation}
Now we find the step lengths to the boundary along this direction, performing separate calculations for the primal and dual components as follow
\begin{align*}
\alpha_{\text{aff}}^{\text{pri}}=\arg\max\{\alpha\in[0,1]\;|\;x +\alpha\Delta x^{\text{aff}}\geq 0\}\\
\alpha_{\text{aff}}^{\text{dual}}=\arg\max\{\alpha\in[0,1]\;|\;s +\alpha\Delta s^{\text{aff}}\geq 0\}
\end{align*}
To measure the efficacy of the affine-scaling direction, we define $\mu_{\text{aff}}$ as the hypothetical value of $\mu$ resulting from a full step to the boundary, that is,
\begin{equation*}
	\mu_{\text{aff}}= (x+\alpha_{\text{aff}}^{\text{pri}}\Delta x^{\text{aff}})^{T}(s+\alpha_{\text{aff}}^{\text{dual}}\Delta s^{\text{aff}})/n
\end{equation*}
If $\mu_{\text{aff}}\ll\mu$, the affine-scaling direction is a good search direction that permits significant progress to be made in reducing $\mu$, so we choose the centering parameter close to 0. If $\mu_{\text{aff}}$ is just a little smaller than $\mu$, we choose $\sigma$ closer to 1. This choice has the effect of moving us closer  to the central path $\mathcal{C}$, so that the algorithm is in a better position to achieve a substantial decrease in $\mu$ on the next iteration.\\
Mehrotra \cite{MER} suggests the following heuristic, which has proved to be effective in exhaustive computational testing:
\begin{equation*}
\sigma = \bigg(\frac{\mu_{\text{aff}}}{\mu}\bigg)^{3}.
\end{equation*}
The centering step component is computed solving a linear system with the same coefficient matrix as in \ref{(A)} and right-hand side $(0, 0,\sigma\mu e)$: actually it is combined with the corrector step, as we see later.\\
Then, to motivate the corrector step, we see how the $i$th pairwise product $x_{i}s_{i}$ is affected by a full step in the affine-scaling direction:
\begin{equation*}
(x_{i}+\Delta x_{i}^{\text{aff}})(s_{i}+\Delta s_{i}^{\text{aff}})= x_{i}s_{i}+ x_{i}\Delta s_{i}^{\text{aff}}+s_{i}\Delta x_{i}^{\text{aff}}+\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}} =\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}}.
\end{equation*}
When a full step is taken, the pairwise product $x_{i}s_{i}$ transforms to $\Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{aff}}$, instead of 0. The corrector component $(\Delta x^{\text{cor}}, \Delta \lambda^{\text{cor}}, \Delta s^{\text{cor}})$ tries to compensate for this deviation from linearity, modifying the search direction so that the pairwise products come closer to their target value to 0. This step satisfies the following system:
\begin{equation}\label{(B)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{cor}}\\\Delta\lambda^{\text{cor}} \\\Delta s^{\text{cor}}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\\Delta X^{\text{aff}}\Delta S^{\text{aff}}e
\end{bmatrix}.
\end{equation}
where
\begin{align*}
\Delta X^{\text{cor}}& = \text{diag}(\Delta x_{1}^{\text{aff}}, \Delta x_{2}^{\text{aff}},\dots,\Delta x_{n}^{\text{aff}})\\
\Delta S^{\text{cor}}& = \text{diag}(\Delta s_{1}^{\text{aff}}, \Delta s_{2}^{\text{aff}},\dots,\Delta s_{n}^{\text{aff}}).
\end{align*}
To assess the effect of the corrector component, we examine the pairwise product obtained from a full step along the combined affine-scaling/corrector direction. From \ref{(B)}:
\begin{equation*}
(x_{i}+\Delta x_{i}^{\text{aff}}+\Delta x_{i}^{\text{cor}})(s_{i}+\Delta s_{i}^{\text{aff}}+\Delta s_{i}^{\text{cor}})= \Delta x_{i}^{\text{aff}}\Delta s_{i}^{\text{cor}}+\Delta x_{i}^{\text{cor}}\Delta s_{i}^{\text{aff}}+\Delta x_{i}^{\text{cor}}\Delta s_{i}^{\text{cor}}.
\end{equation*}
This result yelds to a better reduction of the duality measure: in fact we have \\$\lVert(\Delta x^{\text{aff}},\Delta s^{\text{aff}}) \rVert = \mathcal{O}(\mu)$ and $\lVert(\Delta x^{\text{cor}},\Delta s^{\text{cor}}) \rVert = \mathcal{O}(\mu^{2})$.
\\
When the limiting matrix is singular, the corrector step may no longer be smaller in norm than the affine-scaling step, ideed, it is often larger. Even in this situation, the use of the corrector component usually enhances the overall efficiency of the algorithm in practice.\\
Since the centering and corrector components are obtained by solving linear system with the same coefficient matrix and they are indipendent each other, we can merge them into a single direction by adding their corresponding right-hand sides and compute the combined direction. 
We obtain the combined centering-corrector step $(\Delta x^{\text{cc}}, \Delta \lambda^{\text{cc}}, \Delta s^{\text{cc}})$ solving the following system:
\begin{equation}\label{(C)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x^{\text{cc}}\\\Delta\lambda^{\text{cc}} \\\Delta s^{\text{cc}}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\\Delta X^{\text{aff}}\Delta S^{\text{aff}}e - \sigma\mu e
\end{bmatrix}.
\end{equation}
Although we need to solve at each iteration two linear systems instead of one, the marginal cost is not great because the systems have the same coeffifient matrix and then we need only modify the right-hand side. Having described the essential elements of Mehrotra'a approach, the algorithm is structured as following:
\begin{algorithm}
	\caption{Predictor-corrector Mehrotra algorithm}
	\begin{algorithmic}[1]		
		\State Given: $(x^{0}, \lambda^{0}, s^{0}) > 0$
		\For{$k = 1,\dots$}
		\State set $(x,\lambda,s)=(x^{k},\lambda^{k},s^{k})$ and solve \ref{(A)} for $(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})$;
		\State calculate $\alpha_{\text{aff}}^{\text{pri}}$, $\alpha_{\text{aff}}^{\text{dual}}$ and $\mu_{\text{aff}}$
		\State set sentering parameter to $\sigma = (\mu_{\text{aff}}/{\mu})^{3}$
		\State solve \ref{(C)} for $(x^{cc},\lambda^{cc},s^{cc})$
		\State compute search direction and step to boundary from:
		\State $\;\;\;\;\;\;\;(\Delta x^{k},\Delta \lambda^{k},\Delta s^{k})=(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+(\Delta x^{cc},\Delta  \lambda^{cc},\Delta s^{cc})$;
		\State $\;\;\;\;\;\;\;\alpha_{\text{max}}^{\text{pri}}=\arg\max\{\alpha\geq0\;|\;x^{k} +\alpha\Delta x^{k}\geq 0\}$
		\State $\;\;\;\;\;\;\;\alpha_{\text{max}}^{\text{dual}}=\arg\max\{\alpha\geq0\;|\;s^{k} +\alpha\Delta s^{k}\geq 0\}$\\
		\State set $\alpha_{k}^{\text{pri}}=\min(0.99\ast\alpha_{\text{max}}^{\text{pri}},1)$ and $\alpha_{k}^{\text{dual}}=\min(0.99\ast\alpha_{\text{max}}^{\text{dual}},1)$;
		\State set
		\State$\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;x^{k+1} = x^{k} + \alpha_{k}^{\text{pri}}\Delta x^{k}$;
		\State$\;\;\;\;\;\;(\lambda^{k+1},s^{k+1}) = (\lambda^{k},s^{k}) + \alpha_{k}^{\text{dual}}\Delta (\lambda^{k},\Delta s^{k})$;		
		\EndFor
	\end{algorithmic}
\end{algorithm}\\
\textit{ Capitolo da completare, proponendo due metodi di inizializzazione}

%\lstinputlisting[language=py,caption=applicationContext.py]{Forest.py}
\chapter{Convergence analysis}
In this section it is delineated a complete convergence analysis, using important theoretical results.
\subsection*{Affine-scaling method convergence}
We examine the asymptotic behavior of this method, that is of significant theoretical interest, recalling the matricial system.\\
\begin{equation}\label{(Q)}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
\Delta x\\\Delta\lambda \\\Delta s
\end{bmatrix}=-\begin{bmatrix}
0\\0\\XSe
\end{bmatrix}.
\end{equation}\\	
 We first obtain a bound of the direction vector $(\Delta x,\Delta \lambda, \Delta s)$ for the feasibility case: more precisely we assume that $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$.
\begin{lem}
Suppose that $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$ and that the affine-scaling direction $(\Delta x,\Delta \lambda, \Delta s)$ is calculated. Then there is a costant $C$ such that
\begin{equation*}
	\lVert \Delta x_{\mathcal{B}} \rVert \leq C \mu \text{\;and\;} \lVert \Delta s_\mathcal{B} \rVert \leq C \mu,
\end{equation*}
with the set $\mathcal{B}$ defined previously in (2.11). 
\end{lem}
\begin{proof}
	Let us define the positive diagonal matrix $D = X^{1/2}S^{-1/2}$. Multiplying the last block row of (5.2) by $(XS)^{-1/2}$, we obtain 
	\begin{equation*}
	D^{-1}\Delta x + D \Delta s = -(XS)^{1/2}e.
	\end{equation*}
	Taking inner products of both sides of this expression, we have
		\begin{equation*}
	\lVert D^{-1}\Delta x \rVert^{2} + 2\Delta x^{T}\Delta s+ \lVert D^{-1}\Delta s \rVert^{2}= \lVert(XS)^{1/2}e\rVert^{2}= x^{T}s= n\mu.
	\end{equation*}
	Because $\Delta x^{T}\Delta s= 0$ and the other two terms are positive, we can write
	\begin{equation*}
	\lVert D^{-1}\Delta x\rVert^{2}\leq n\mu, \;\;\lVert D^{-1}\Delta s\rVert^{2}\leq n\mu
	\end{equation*}
	Since $D_{i,i}= \sqrt{x_{i}/s_{i}}$, we have for any $i$ that
	\begin{equation*}
	\frac{s_{i}}{x_{i}}(\Delta x_{i})^{2}\leq\lVert D^{-1}\Delta x\rVert^{2}\leq n\mu.
	\end{equation*}
	Hence, choosing $i\in\mathcal{N}$ and using $x_{i}s_{i}\geq\gamma\mu$, we find that
	\begin{equation*}
	(\Delta x_{i})^{2}\leq\frac{n\mu x_{i}}{s_{i}}=\frac{n\mu x_{i}^{2}}{x_{i}s_{i}}\leq\frac{n\mu^{3}}{\gamma\mu C^{2}}\mu^{2}.
	\end{equation*}
	Therefore, we have 
	\begin{equation*}
	\lVert \Delta x_{\mathcal{N}}\rVert \leq \sqrt{n}\max\limits_{i \in \mathcal{N}}|\Delta x_{i}|\leq\frac{n}{\gamma^{1/2}C}\mu.
	\end{equation*}
	To argument for $\lVert \Delta s_{\mathcal{B}}\rVert$ is identical.
\end{proof}
Now we show that $\lVert \Delta x_{\mathcal{B}}\rVert$ and $\lVert \Delta s_{\mathcal{N}}\rVert$ are also $\mathcal{O}(\mu)$ with the following two technical lemmas and an important theorem.
\begin{lem} \label{(T)}
	Let the matrix $H\in\mathbb{R}^{p,q}$ be given. Then there exists a nonnegative constant $\bar{C}$ depending only on $H$ with the following property: for any vector $h\in Range(H)$ and any nonsingular diagonal matrix $\Sigma$, the unique solution $\bar{w}$ of the problem
	\begin{align*}
	\min\limits_{w}\frac{1}{2}\lVert\Sigma\rVert^{2} \text{\;subject to\;} Hw = h\\\text{satisfies\;} \lVert\bar{w}\rVert\leq \bar{C}\lVert h\rVert.
	\end{align*}
\end{lem}
In the next lemma $A_{\mathcal{B}}$, $A_{\mathcal{N}}$,$D_{\mathcal{B}}$ and $D_{\mathcal{N}}$ denote a column partition of the matrices respectively $A$ and $D$, according to the sets $\mathcal{B}$ and $\mathcal{N}$.
\begin{lem}
	Suppose that the assumption of the lemma (5.2) hold. Then
	\begin{enumerate}
		\item $u = \Delta x_{B}$ is the unique solution of the following convex quadratic problem
		\begin{align} \label{(U)}
			\min\limits_{u}\frac{1}{2}\lVert D_{\mathcal{B}}^{-1}u\rVert^{2} \text{subject to }A_{\mathcal{B}u} = -A_{\mathcal{N}}\Delta x_{\mathcal{N}}
		\end{align}
			\item $(v, \pi) = (\Delta s_{N}, \Delta \lambda)$ is a solution of the convex quadratic problem
	\begin{align}
		\min\limits_{(v, \pi)}\frac{1}{2}\lVert D_{\mathcal{N}}v\rVert^{2} \text{ subject to } &A_{\mathcal{B}u} = -A_{\mathcal{N}}\Delta x_{\mathcal{N}}\\
		&A_{\mathcal{N}^{T}\pi}+ v =0		 
	\end{align}
		With the unicity of $\Delta s_{\mathcal{N}}$
	\end{enumerate} 
\end{lem} 
\begin{proof}
	\textit{1}. From KKT conditions, we say that $\Delta x_{\mathcal{B}}$ is a solution if there exists a vector $\hat{\pi}$ such that
	\begin{align*}
	D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}}-A_{\mathcal{B}}^{T}\hat{\pi}&= 0\\
	A_{\mathcal{B}}\Delta x_{B}&= -A_{\mathcal{N}}\Delta x_{\mathcal{N}}
	\end{align*}
	The second equation is satisfied from (5.11). Combining the first and the third block rows in (5.11), we have for the indices $\mathcal{B}$:
	\begin{equation*}
	-D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}} + A_{\mathcal{B}}^{T}\Delta \lambda = s_{\mathcal{B}}
	\end{equation*}
	Since $(x, \lambda, s)$ is feasible, we have $s_{\mathcal{B}}= -A_{\mathcal{B}}^{T}\lambda+ c_{\mathcal{B}}$, whereas for any solution $(x^{*}, \lambda^{*}, s^{*})$, we have $c_{\mathcal{B}}= A_{\mathcal{B}^{T}\lambda^{*}}$. Then, we have
	\begin{equation*}
	-D_{\mathcal{B}}^{-2}\Delta x_{\mathcal{B}} + A_{\mathcal{B}}^{T}\Delta \lambda = -A_{\mathcal{B}}^{T}\lambda+ c_{\mathcal{B}} = -A_{\mathcal{B}}^{T}(\lambda - \lambda^{*}) 
	\end{equation*}
	If we set $\hat{\pi} = \lambda + \Delta\lambda + \lambda^{*}$, then also the first KKT condition holds.\newline
	 \textit{2.} We recall again the KKT conditions and $(v,\pi)=(\Delta s_{N},\Delta\lambda)$ is a solution if there exist vectors $\hat{u}_{\mathcal{B}}$ and $\hat{u}_{\mathcal{N}}$ such that
	 \begin{align*}
	 D_{\mathcal{N}}^{2}\Delta s_{N}-\hat{u}_{N}&=0\\
	 -A_{\mathcal{B}}^{T}\hat{u}_{\mathcal{B}}-A_{\mathcal{N}}^{T}\hat{u}_{N}&=0\\
	 A_{\mathcal{B}}^{T}\Delta \lambda &= -\Delta s_{\mathcal{B}}\\
	 A_{\mathcal{N}}^{T}\Delta\lambda + \Delta s_{\mathcal{N}} &=0 
	 \end{align*}
	 The last two equations follow immediately from the first block row of (5.11).\\
	 Then, it is easy to show that the choices $\hat{u}_{N}= x_{\mathcal{N}}+\Delta x_{\mathcal{N}}$ and $\hat{u}_{\mathcal{B}}=x_{\mathcal{B}}+\Delta x_{\mathcal{B}}-x_{\mathcal{B}}^{*}$, satisfy the first and the second equations, where $x^{*}$ is the primal solution.\\
	 Now we prove the uniqueness of the $\Delta s_{\mathcal{B}}$.\\
	 If we multiply (5.12) by $A_{\mathcal{B}}$ and (5.13) by $A_{\mathcal{N}}$ and add, we obtain
	 \begin{equation*}
	 (A_{\mathcal{B}}A_{\mathcal{B}}^{T}+A_{\mathcal{N}}A_{\mathcal{N}}^{T})\pi+A_{\mathcal{N}}v = AA^{T}\pi+A_{\mathcal{N}}v = -A_{\mathcal{B}}\Delta s_{\mathcal{B}}
	 \end{equation*} 
	 Since A has full rank for hypothesis, we can write
	 \begin{equation*}
	 \pi = -(AA^{T})^{-1}(A_{\mathcal{N}}v +A_{\mathcal{B}}\Delta s_{\mathcal{B}})
	 \end{equation*}
	 so the minimization problem can be formulated as
	 	\begin{equation}\label{(V)}
	 \min\limits_{v}\frac{1}{2}\lVert D_{\mathcal{N}}v\rVert^{2} \text{ subject to }
	 (I-A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{N}})v =A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\Delta s_{\mathcal{B}}.		 
	 \end{equation}
	 Since this problem  has strictly convex objective, unqueness of its solution $v=\Delta s_{\mathcal{N}}$ is guaranteed. To conclude, we can recover $\Delta \lambda=\pi$ as defined above. 
\end{proof}
\begin{thm}\label{(Z)}
	Given $(x, \lambda, s)\in\mathcal{N}_{- \infty}(\gamma)$ and $(\Delta x,\Delta \lambda, \Delta s)$ computed in ~\ref{(Q)}, there is a constant K such that
	\begin{equation*}
	\lVert (\Delta x, \Delta s)\rVert \leq K \mu.
	\end{equation*}
\end{thm}
\begin{proof}
	Since the diagonal of $D_{\mathcal{B}}$ is strictly positive, we can apply the lemma~\ref{(T)} directly to the convex quadratic problem~\ref{(U)}. Hence, there is a constant $\bar{C}$ depending on $A_{\mathcal{B}}$ such that
	\begin{equation}
	\lVert \Delta x_{\mathcal{B}}\rVert \leq \bar{C}\lVert A_{\mathcal{N}}\Delta x_{\mathcal{N}}\rVert\leq \bar{C}\lVert A_{\mathcal{N}}\rVert C\mu,
	\end{equation}
	Similarly, from~\ref{(V)}, there is a constant $\bar{K}$ depending on $A$ such that
		\begin{equation}
	\lVert \Delta s_{\mathcal{N}}\rVert \leq \bar{K}\lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert\lVert \Delta s_{\mathcal{B}}\rVert \leq\bar{K} \lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert C\mu,
	\end{equation}
	The result follows when we define K$\;=\bar{K} \lVert A_{\mathcal{N}}^{T}(A^{T}A)^{-1}A_{\mathcal{B}}\rVert C$.
\end{proof}
A result similar to the Theorem~\ref{(Z)} holds for steps of an infeasible interior-point algorithm. See~\cite{Wright}.

\subsection*{Analysis of LPF method}

\begin{lem}\label{lem1}
	Let u and v be any two vectors in $\mathbb{R}^{n}$ with $u^{T}v \geq 0$. Then, 
\begin{align*}
\lVert UVe \rVert_{2}\leq 2^{-3/2}\lVert u + v \rVert^{2}_{2}\\
\end{align*}
with $U = diag(u_{1}, u_{2}, ..., u_{n})$ and $V = diag(v_{1}, v_{2}, ..., v_{n})$. 
\end{lem}
\begin{proof}
	We can formulate $0 \leq u^{T}v = \sum\limits_{u_{i}v_{i} \geq 0}u_{i}v_{i} + \sum\limits_{u_{i}v_{i} \leq 0}u_{i}v_{i} = \sum\limits_{i \in \mathcal{P}}|u_{i}v_{i}| - \sum\limits_{i \in \mathcal{M}}|u_{i}v_{i}| $, with $\mathcal{P}= \{i | u_{i}v_{i} \geq 0\}$ and $\mathcal{M}= \{i | u_{i}v_{i} \leq 0\}$.

\begin{align*}
\lVert UVe \rVert_{2} &= ( \lVert[u_{i}v_{i}]_{i \in \mathcal{P}} \rVert^{2} +  \lVert[u_{i}v_{i}]_{i \in \mathcal{M}} \rVert^{2})^{1/2}\\
&\leq ( \lVert[u_{i}v_{i}]_{i \in \mathcal{P}} \rVert^{2}_{1} +  \lVert[u_{i}v_{i}]_{i \in \mathcal{M}} \rVert^{2}_{1})^{1/2},\; \text{since\;} \lVert\dot\rVert_{2} \leq \lVert\dot\rVert_{1}\\
&\leq\sqrt{2}\;\bigg\lVert\bigg[\frac{1}{4}(u_{i} + v_{i})^{2}\bigg]_{i\in \mathcal{P}}\bigg\rVert_{1}, \text{\;since\;} \sqrt{ab} \leq \frac{1}{2}|a+b|\\
& = 2^{-3/2} \sum\limits_{i \in \mathcal{P}}(u_{i} + v_{i})^{2}\\
& \leq 2^{-3/2} \sum\limits_{i = 0}^{n}(u_{i} + v_{i})^{2}\\
& \leq 2^{-3/2} \lVert u + v \rVert^{2}_{2}.
\end{align*}
\end{proof}	
This lemma is an important tool to proof the next statement.
\begin{lem}
	If $(x, \lambda, s) \in \mathcal{N}_{-\infty}(\gamma)$, then
	\begin{align*}
	\lVert\Delta X\Delta S e \rVert \leq 2^{-3/2}(1 + 1/ \gamma)n\mu.\\
	\end{align*}
\end{lem}
\begin{proof}
	$(x + \Delta x)^{T}(s +\Delta s) = SX + x \Delta s + s \Delta x + \Delta x \Delta s$ and $S \Delta x + X \Delta s + XS = 0$, by the last row of \ref{(5.1)}. These two equations show that $\Delta x\Delta s = 0$.\\
	Now, by multiplying the last block row by $(XS)^{-1/2}$ and recalling the definition of $D = X^{1/2}S^{-1/2}$, we obtain 
	\begin{equation}
	D^{-1}\Delta x + D \Delta s = (XS)^{-1/2}(-XSe + \sigma \mu e)
	\end{equation}
	Since $(D^{-1}\Delta x)^{T}(D \Delta s) = \Delta x^{T} \Delta{s} = 0$, applying the Lemma \ref{lem1} with $u= D^{-1}\Delta x$ and $v = D \Delta s$, we obtain
	\begin{align*}
		\lVert \Delta X \Delta S e\rVert &= \lVert(D^{-1}\Delta X)(D\Delta S)e \rVert \\
		&\leq 2^{-3/2}\lVert D^{-1}\Delta x + D \Delta s\rVert^{2}, \text{\;from the Lemma}\\
		&= 2^{-3/2}\lVert (XS)^{-1/2}(-XSe + \sigma \mu e)\rVert ^{2} \text{\; from (5.8)}\\
	\end{align*}
	Expanding the squared Euclidean norm and using such relationships as $x^{T}s = n\mu$ and $e^{T}e = n$, we obtain
	\begin{align*}
	\lVert \Delta X \Delta S e\rVert_{2} &\leq 2^{-3/2}\bigg[x^{T}s - 2\sigma \mu e^{T}e + \sigma^{2}\mu^{2}\sum\limits_{i = 1}^{n}\frac{1}{x_{i}s_{i}}\bigg]\\
	 &\leq s^{-3/2}\bigg[x^{T}s - 2\sigma \mu e^{T}e + \sigma^{2}\mu^{2}\frac{n}{\gamma \mu}\bigg], \text{\; since\;} s_{i}x_{i} \geq \gamma \mu\\
	  &\leq 2^{-3/2}\bigg[1 - 2\sigma + \frac{\sigma^{2}}{\mu}\bigg]n \mu\\
	  &\leq 2^{-3/2}(1 + 1/\gamma)n \mu.
	\end{align*}
\end{proof}

\begin{thm}
	Given the parameters $\gamma$, $\sigma_{min}$ and $\sigma_{max}$ in the long-step path following algorithm, there is a constant $\delta$ indipendent of n such that
	\begin{equation}\label{(5.10)}
	\mu_{k+1} \leq \bigg(1 - \frac{\delta}{n}\bigg)\mu_{k}\\
	\end{equation} 
\end{thm}
\begin{proof}
	First of all we prove that $(x_{k}, \lambda_{k}, s_{k})+\alpha(\Delta x_{k},\Delta \lambda_{k},\Delta s_{k})\in\mathcal{N}_{-\infty}(\gamma)$ for all \\$\sigma \in \bigg[0,2^{3/2}\gamma \frac{1 - \gamma}{1 +\ \gamma}\frac{\sigma_{k}}{n}\bigg]$.\\
	
	From the last $n$ equalities of \ref{(5.9)}, we have that 
	\begin{align}(x_{i}^{k}, \lambda_{i}^{k}, s_{i}^{k})+\alpha(\Delta x_{i}^{k},\Delta \lambda_{i}^{k},\Delta s_{i}^{k}) &=\\ 
	x_{i}^{k}s_{i}^{k} + \alpha(x_{i}^{k} \Delta s_{i}^{k} + s_{i}^{k} \Delta x_{i}^{k})+\alpha^{2}\Delta x_{i}^{k} \Delta s_{i}^{k} &=\\
	x_{i}^{k}s_{i}^{k}(1 - \alpha) + \alpha \sigma_{k}\mu_{k}-\alpha^{2}|\Delta x_{i}^{k} \Delta s_{i}^{k}| &\geq\label{(5.11)}\\
	\gamma(1 - \alpha)\mu_{k} + \alpha \sigma_{k}\mu_{k}-\alpha^{2}2^{-3/2}(1 + 1/\gamma)n\mu_{k} &\label{(5.12)}.
	\end{align}
	In the equation \ref{(5.11)} is added $\alpha x_{i}^{k}s_{i}$ in order to use the last equations of the matrix system 
	In the step \ref{(5.12)} it is used the inequality proved above $|\Delta x_{i}^{k}\Delta s_{i}^{k}|\leq2^{-3/2}(1 + 1/\gamma)n\mu_{k}$, for any $i = 1,2,...,n$. \\
	By summing the $n$ components of the equation $S^{k}\Delta x^{k} + X^{k} \Delta s^{k} = -X^{k}S^{k}e + \sigma_{k} \mu_{k}e$ and using the null product $\Delta x \Delta s$, we have
	\begin{align*}\mu_{k}(\alpha)\vcentcolon=(x_{i}^{k} + \alpha\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha\Delta s_{i}^{k})/n&=\\ 
	x_{i}^{k}s_{i}^{k}/n - \alpha \mu_{k}+\alpha \sigma_{k} \mu_{k} &=\\
	(1-\alpha(1-\sigma_{k}))\mu_{k}
	\end{align*}
	From these last two formulas, we can see that proximity condition:\\$(x_{i}^{k} + \alpha\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha\Delta s_{i}^{k}) \geq \gamma\mu_{k}(\alpha)$ is satisfied if \begin{equation*}
		\gamma(1-\alpha)\mu_{k} + \alpha\sigma_{k}\mu_{k} - \alpha^{2}2^{-3/2}(1 + 1/\gamma)n\mu_{k}\geq \gamma(1 - \alpha +\alpha\sigma_{k})\mu_{k}
		\end{equation*}
		Rearranging the expression in further two steps, we assert the upper bound of the interval of the parameter $\alpha$:
		\begin{align*}
		\alpha\sigma_{k}\mu_{k}(1-\gamma)\geq\alpha^{2}2^{-3/2}(1+1/\gamma)\\
		\alpha \leq \frac{2^{3/2}}{n} \sigma_{k}\gamma\frac{1-\gamma}{1+\gamma}.\\		
		\end{align*}
Now, we complete the prof of the theorem by estimating the reduction in $\mu$ on the $k$th step. Using the inequality above:
\begin{align*}
\mu_{k+1}& = (x_{i}^{k} + \alpha_{k}\Delta x_{i}^{k})^{T}(s_{i}^{k} + \alpha_{k}\Delta s_{i}^{k})/n\\
		 & = [(x^{k})^{T}s^{k} + \alpha_{k}\big((x^{k})^{T}\Delta s^{k} + (s^{k})^{T}\Delta x^{k}\big) +\alpha^{2}_{k}(\Delta x^{k})^{T}\Delta s^{k}]/n\\
		 & = (1 - \alpha_{k}(1-\sigma_{k}))\mu_{k}\\
		 & \leq \Big(1 - \frac{2^{3/2}}{n}\gamma\frac{1-\gamma}{1+\gamma}\sigma_{k}(1-\sigma_{k})\Big).\\
\end{align*}
Since the function $\sigma(1 - \sigma)$ is a concave quadratic function of $\sigma$, we have:
\begin{equation*}
\sigma_{k}(1-\sigma_{k})\geq \text{min}\{\sigma_{min}(1-\sigma_{min}),\sigma_{max}(1-\sigma_{max})\}, \text{\;for all\;}\sigma_{k}\in[\sigma_{min},\sigma_{max}].
\end{equation*}
We can use this estimate in the last inequality and setting
\begin{equation*}
\delta \vcentcolon=2^{3/2}\gamma\frac{1-\gamma}{1+\gamma}\text{min}\{\sigma_{min}(1-\sigma_{min}),\sigma_{max}(1-\sigma_{max})\}, \text{\;for all\;}\sigma_{k}\in[\sigma_{min},\sigma_{max}].
\end{equation*}
\end{proof}
We complete the analysis theory with the following theorem which shows that a reduction of a factor of $\epsilon$ in the duality measure $\mu$ can be obtained in $\mathcal{O}(n\log{1/\epsilon})$ iterations.
\begin{thm}
	Given $\epsilon\in(0,1)$ and $\gamma\in(0,1)$, suppose the starting point in the algorithm satisfies $(x^{o},\lambda^{o},s^{o})\in\mathcal{N}(\gamma)$. Then there is an index $\mathcal{K}$ with $\mathcal{K}=\mathcal{O}(n\log1/\epsilon)$ such hat $\mu_{k}\leq\epsilon\mu_{o}$.
\end{thm}
\begin{proof}
	By taking the logarithms of both sides in \ref{(5.10)},we obtain
	\begin{equation*}
	\log\mu_{k+1}\leq \log \bigg(1-\frac{\delta}{n}\bigg)+\log\mu_{k}\end{equation*}
	By applying this formula repeatedly
	\begin{equation*}
	\log\mu_{k+1}\leq \log \bigg(1-\frac{\delta}{n}\bigg)+\log\mu_{o}
	\end{equation*}
	\text{Using the log estimate} $\log(1+\beta)\leq\beta$, with $\beta>-1$.\\
	\begin{equation*}
	\log(\mu_{k}/\mu_{o})\leq k\bigg(-\frac{\delta}{n}\bigg)
	\end{equation*}.	
For every $k$ that satisfy
\begin{equation*}
k\geq\mathcal{K}:= \frac{\delta}{n}\log\frac{1}{\epsilon} = \frac{\delta}{n}|\log(\epsilon)|
\end{equation*}
we have 
\begin{equation*}
k\bigg(-\frac{\delta}{n}\bigg)\leq\log\epsilon
\end{equation*}	
that guarantees
\begin{equation*}
\mu_{k}/\mu_{o}\leq\epsilon.
\end{equation*}	
\end{proof}

\subsection*{MPC analysis}
In order to study the perform of the Mehrotra's algorithm, we introduce the trajectory-following methods from ODEs. These one define a trajectory from the current point, we say $(x,\lambda,s)$, to the solution set $\Omega$. There are infinitely many trajectories to choose from, but in this casse is obtained from a linear scaling of the function \ref{F}.\\ Denoting this trajectory by $\mathcal{H}$ and parametrizing it by $\tau\in[0,1)$, we find that each point $(x_{\tau},\lambda_{\tau},s_{\tau})\in\mathcal{H}$ is a solution of the following nonlinear system:
\begin{equation}\label{T}
	\begin{bmatrix}
	A^{T}\lambda+s-c \\Ax-b \\XSe
	\end{bmatrix}=\begin{bmatrix}
	(1-\tau)(A^{T}\lambda-c)\\(1-\tau)(Ax-b)\\(1-\tau)XSe
	\end{bmatrix}, (x,s)\geq0.
\end{equation}
We see that $(x_{\tau},\lambda_{\tau},s_{\tau})$ with $\tau = 0$ is exactly the initial point and that, if the limit exists, then $\lim\limits_{\tau\to\infty}(x_{\tau},\lambda_{\tau},s_{\tau}) = (x^{*},\lambda^{*},s^{*})$.\\
To move along the trajectory $\mathcal{H}$, we can form a Taylor series approximation to $(x_{\tau},\lambda_{\tau},s_{\tau})$ by expanding about the initial point  $(x,\lambda,s)$ as follows:
\begin{equation*}
(x_{\tau},\lambda_{\tau},s_{\tau})=(x_{0},\lambda_{0},s_{0})+\tau(x_{0}^{'},\lambda_{0}^{'},s_{0}^{'})+\frac{1}{2}\tau^{2}(x_{0}^{"},\lambda_{0}^{"},s_{0}^{"})+\dots = \sum_{j=0}^{\infty}\frac{\tau^{j}}{j!}(x_{0}^{j},\lambda_{0}^{j},s_{0}^{j})
\end{equation*}
Here, $(x_{0}^{j},\lambda_{0}^{j},s_{0}^{j})$ is the derivative of $(x_{\tau},\lambda_{\tau},s_{\tau})$ with respect to $\tau$, evaluated in $\tau = 0$. We can find these derivatives by implicity differenziating the equation \ref{T}. Setting $\tau=0$ we have:
\begin{equation}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
x_{0}^{'}\\\lambda_{0}^{'}\\s_{0}^{'}
\end{bmatrix}=-\begin{bmatrix}
A^{T}\lambda-c\\Ax-b\\XSe
\end{bmatrix},
\end{equation}
which is exactly the same system as affine-scaling step equation.\\
Hence, we can make the identification $(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})=(x^{'}_{0},\lambda^{'}_{0},s^{'}_{0})$. Differentiating again with respect to $\tau$, we obtain the second derivative solving
\begin{equation}
\begin{bmatrix}
0&A^{T}&I \\A&0&0\\X&0&S
\end{bmatrix}\begin{bmatrix}
x_{0}^{''}\\\lambda_{0}^{''}}\\s_{0}^{''}
\end{bmatrix}=-\begin{bmatrix}
0\\0\\2X^{'}_{0}S^{'}_{0}e
\end{bmatrix}
\end{equation}
and we see that $(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})=\frac{1}{2}(x^{''}_{0},\lambda^{''}_{0},s^{''}_{0})$. Now we truncate the Taylor series at two terms and use the last two results, in order to gìhave the following approximation:
\begin{equation}
(x_{\tau},\lambda_{\tau}, s_{\tau})\approx(x, \lambda, s)+ \tau(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+\tau^{2}(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})
\end{equation}
If we ignore the centering term  by setting $\sigma =0$ and, hence, constrain the primal and dual step lengths to be identical, then the algorithm searches the successive point along the line
\begin{equation}
(x_{\tau},\lambda_{\tau}, s_{\tau})\approx(x, \lambda, s)+ \tau(\Delta x^{\text{aff}},\Delta \lambda^{\text{aff}},\Delta s^{\text{aff}})+\tau(\Delta x^{\text{cor}},\Delta \lambda^{\text{cor}},\Delta s^{\text{cor}})
\end{equation} 
that is, the $\tau^{2}$ coefficient in the òast term is replaced by $\tau$. Instead when we account for the centering parameter, the correspondence between the derivatives of the trajectory and the MPC search direction no longer holds. \\
Then we introduce the modified trajectory $\mathcal{H}_{\sigma}$ for which the correspondence continues to hold even in the presence of $\sigma$. Also $\mathcal{H}_{\sigma}$ starts at $(x, \lambda, s)$ and aims at the solution set $\Omega$. All $(x_{\tau},\lambda_{\tau},s_{\tau})$ in this trajectory satisfy:
\begin{equation}\label{T}
\begin{bmatrix}
A^{T}\lambda+s-c \\Ax-b \\XSe
\end{bmatrix}=\begin{bmatrix}
(1-\tau)(A^{T}\lambda-c)\\(1-\tau)(Ax-b)\\(1-\tau)XSe+\tau^{2}(1-\tau)\sigma\mu e
\end{bmatrix},(x,s)\geq0.
\end{equation}
The tangent to this trajectory is the affine-scaling direction, as for $\mathcal{H}$, but the curvature can be identified with the combined centering-corrector step rather than the corrector component alone. The trajectory $\mathcal{H}_{\sigma}$ tends to bulge more toward the central path than $\mathcal{H}$. Despite the closer relationship between $\mathcal{H}_{\sigma}$  and MPC algorithm, we can not qualify it as a second-order trajectory-following algorithm because it still searches along a linear direction rather than a quadratic path.  
\section{Initialization and termination} 

There are several important issues concerning interior-point algorithms
for linear programs.\\The first one involves the initialization. All the theory explained above assumes that the initial point is strictly feasible, in order to show  a comprehensive convergence analysis. Even though, the most pratical algorithm does not require starting from  feasible initial-points. The search direction needs to be modified so that it moves closer to feasibility as well as to
centrality: in (5.1) the right hand side $F(x, \lambda, s)\neq0$. The implementation of the LFP method, computed and analyzed in this research, takes the ones-vector as initial point. [\textit{sviluppero` una descrizione e un'analisi al variare del punto iniziale dell'algoritmo implementato}]
\\
 The second limit involves termination. Unlike the simplex method,
which terminates with an exact solution, interior-point algorithms are continuous
optimization algorithms that generate a sequence of strictly feasible points $(x^{k}, \lambda^{k},s^{k})$ converging to
an optimal solution. If the data of a particular problem are integral or rational, then, after the worst-case time bound, an exact solution can be
rounded from the latest approximate solution. But under
the real number computation model we can not apply this argument.\\ 

[\textit{Dscrivero' il metodo di Ye, che converte l'iterata $(x^{k}, \lambda^{k},s^{k})$, sufficientemente vicina alla soluzione, alla soluzione esatta}]
\chapter{Sensitivity analysis}
With the simplex method and interior point metods we can compute optimal solution to linear models, but this does not suffice because the constant parameters from which they are derived, such items as costs, profits, supplies, demands, are almost neveer known certainty at the time the model is solved.\\
In this chapter we study the effects of changing the input variables with some perturbations.\\ The aim is to formulate a comparison between the simplex and IPM sensitivity and remark the sensitivity information inside the \textit{slack variables}.
\chapter{Pratical implementations}
In this chapter it is developed a comprehensive analysis of the results obtained by some practical implementations. It is presented three LP problems: the forest service allocation,...\\
Now we outline the geometric viewpoint of the simplex method and the primal-dual methods.\\
We already stated that the simplex method generates a sequence of basic feasible primal points of the solution set; hence, it creates a path along the boundary of the polytope, checking the cost value at each vertex.\\Instead, the primal-dual interior point methods approach the solution through the interior of the feasible polytope, generating the central path $\mathcal{C}$, rather than working around the boundary.\\ Path-following method follow $\mathcal{C}$ in the direction of decreasing $\tau$ in (4.7) ; ideed, they do not necessarily stay exactly on the path but within a loose and well-defined neighoborhood of $\mathcal{C}$ while steadily reducing the duality measure $\mu$ to zero. Each search direction is computed with a Newton's step toward a point for which the duality measure $\tau$ is equal to or smaller than the current duality measure $\mu$, as we know $\tau=\sigma\mu$. 
The affine-scaling method, based on standard Newton's steps, sets the central parameter $\sigma_{k}= 0$ in the system;
%In fact, the gap between neighborhood boundaries is wide enough to allow this step to make significant progress in reducing $\mu$. 
even if it makes significant progress, it also tends to worsen the centrality measure (condition of having all pairwise products $x_{i}s_{i}$ equal). It follows that the step length $\alpha_{k}$ is the maximum value such that the next points remain in the feasible set. We will see that we often can take only a small
step along the search direction before violating the condition; hence, the affine scaling direction, often does not allow us to make much progress toward a solution.\\ 
The long-path following method doesn't create a sequence that moves strongly to the solution, indeed, computes the search direction with $\sigma_{k}$ between two fixed limits $\sigma_{\text{min}}$ and $\sigma_{\text{max}}$, in order to improve the centrality measure. The lower bound $\sigma_{\text{min}}$ ensures that each search direction start by moving off the boundary of $\mathcal{N}_{-\infty}(\gamma)$ and into the interior of the neighborhood. Unit steps along the search direction takes the next point outside the neighborhood, since the error of approximating the nonlinear KKT system by the linear equations becomes more pronounced as $\alpha$ increases. Then, it selects $\alpha_{k}$ as large a possible subject to the next point remains $\mathcal{N}_{-\infty}(\gamma)$. The restriction of $\sigma_{k}\in(0,1)$ achieves the twin goals of improving centrality and reducing the duality measure into a single step.\\
Alternatively, the predictor-corrector methods consists on two types of steps: the predictor step, which start in the inner neighborhood and moves along the affine-scaling direction to the boundary of the outer neighborhood. Between these predictor steps, the algorithm takes corrector steps, computing $\sigma = 1$ and $\alpha= 1$, in order to come back inside the inner neighborhood to prepare for the next predictor corrector step.
These computations illustrate that the primal-dual IPMs are strong competitors to the simplex method on large problems.
\subsection*{Forest service allocation} 
The first model we illustrate is the \textit{Forest service allocation}. This example is part of allocation models class: the main issue is how to divide or allocate a valuable resource among competing needs and the resource may be for example land, capital, time or fuel.\\
The U.S Forest Service has used this model to address the sensitive task of managing 191 million acres of national forestland \cite{(Natural)}. The Forest Service must trade off timber, grazing, recreational, environmental, national preservation, and other demands of forestland\\
The models of a forest begin  by dividing land into homogeneous analysis area, then several prescriptions or land management policies are then proposed and evaluated for each. \\The optimization seeks the best possible allocation of land in the analysis areas to particular prescriptions, subject to forest-wide restrictions on land use.
We model, hypotetically, 788 thousand acre Wagonho National Forest, that is assumed to have 7 analysis areas, each subject to 3 different prescriptions. The first prescription encourages timbering, the second grazing and the third preserves the land as wilderness. Then we indices the variables as well:
\begin{itemize}
	\item \textit{i} is the analysis area number and \textit{j} is the prescription number
	\item $s_{i}$ is the size of area $i$ in thousands of acres
	\item $p_{i,j}$ is the net present value (PNV) per acre of all uses in area $i$ if managed under prescription $j$
	\item $t_{i,j}$ is the projected timber yield (in board feet per acre) of analysis area $i$ if managed under prescription $j$
	\item $g_{i,j}$ is the projected grazing capability (in animal unit months per acre) of analysis area $i$ if managed under prescription $j$
	\item $w_{i,j}$ is the wilderness index rating, from 0 to 100, of analysis area $i$ if manages under prescription $j$
\end{itemize}
We want to find an allocation that minimizes net present value while producing 40 million board feet of timber, 5 thousand animal unit months of grazing, and keeping average wilderness index at least 70.\\
The formulation of the model in a LP problem can be written as following:
\begin{align*}
\max&\sum_{i=1}^{7}\sum_{j=1}^{3} p_{i,j}x_{i,j}&(present value)\\
s.t& \sum_{i=1}^{3}x_{i,j}=s_{i}\;\;\;\;i = 1, \dots,7&(allocation)\\
&\sum_{i=1}^{7}\sum_{j=1}^{3} t_{i,j}x_{i,j}\geq 40000&(timber)\\
&\sum_{i=1}^{7}\sum_{j=1}^{3} g_{i,j}x_{i,j}\geq5&(grazing)\\
&\frac{1}{788}\sum_{i=1}^{7}\sum_{j=1}^{3} w_{i,j}x_{i,j}\geq 70&(wilderness)\\
&x_{i,j}\geq 0 \;\;\;\;i = 1,\dots,7;\;\;\;\;j = 1,\dots,3;
\end{align*}
Since the LP is not in standard form, we convert the inequalies to equalities adding slack valriables $y_{i,k}$ to the last three constraints, with $i, k = 1, \dots, 3$. The Forest Service Application Data used to test the methods are shown in the following table:\\

%\begin{array}{l | l | l | l | l | l | l | l | }
% &	\hline	\text{Analysis area\;}i & \text{Acres\;}j  & \text{Prescription} & \text{NPV} & \text{Timber} & \text{Grazing} & \text{Wilderness index} \\ \hline
% &	1& 75 & 1 & 503 & 310 & 0.01 & 40 \\ \hline
% &	1 & 75 & 2 & 140 & 50 & 0.04 & 80 \\ \hline
% &	1& 75 & 3 & 203 & 0 & 0 & 95 \\ \hline
 %&	2 & 90 & 1 & 675 & 198 & 0.03 & 55 \\ \hline
% &	2 & 90 & 2 & 100 & 46 & 0.06 & 60 \\ \hline
% &	2 & 90 & 3 & 45 & 0 & 0 & 65 \\ \hline
% &	3 & 140 & 1 & 630 & 210 & 0.04 & 45 \\ \hline
% &	3 & 140 & 2 & 105 & 57 & 0.07 & 55 \\ \hline
% &	3 & 140 & 3 & 40 & 0 & 0 & 60 \\ \hline
% &	4 & 60 & 1 & 330 & 112 & 0.01 & 30 \\ \hline
% &	4 & 60 & 2 & 40 & 30 & 0.02 & 35 \\ \hline
% &	4 & 60 & 3 & 295 & 0 & 0 & 90 \\ \hline
% &	5 & 212 & 1 & 105 & 40 & 0.05 & 60 \\ \hline
% &	5 & 212 & 2 & 460 & 32 & 0.08 & 60 \\ \hline
% &	5 & 212 & 3 & 120 & 0 & 0 & 70 \\ \hline
% &	6 & 98 & 1 & 490 & 105 & 0.02 & 35 \\ \hline
% &	6 & 98 & 2 & 55 & 25 & 0.03 & 50 \\ \hline
% &	6 & 98 & 3 & 180 & 0 & 0 & 75 \\ \hline
% &	7 & 113 & 1 & 705 & 213 & 0.02 & 40 \\ \hline
% &	7 & 113 & 2 & 60 & 40 & 0.04 & 45 \\ \hline
% &	7 & 113 & 3 & 400 & 0 & 0 & 95 \\ \hline
%\end{array}
\\
The minimum total net present value is $\$322515.00$ with the following optimal allocation:
\begin{align*}
x_{1,1}^{*} &=  0 & x_{1,2}^{*}&= 0 & x_{1,3}^{*} &= 75 & x_{2,1}^{*} &= 90 & x_{2,2}^{*} &= 0 & x_{2,3}^{*} &= 0\\
x_{3,1}^{*} &= 140 & x_{3,2}^{*}&= 0 & x_{3,3}^{*} &= 0 & x_{4,1}^{*} &= 0 & x_{4,2}^{*} &= 0 & x_{4,3}^{*} &= 60\\
x_{5,1}^{*} &= 0 & x_{5,2}^{*}&= 154 & x_{5,3}^{*} &= 58 & x_{6,1}^{*} &= 0 & x_{6,2}^{*} &= 0 & x_{6,3}^{*} &= 98\\
 x_{7,1}^{*}&=0 &x_{7,2}^{*} &= 0 & x_{7,3}^{*} &= 113 & & & &  & & \\
\end{align*}
\subsection*{Blending models}
As allocation models split a resource, blending models combine them. Various applications blend everything from chemicals, to diets, to metals, to animal food. This problems are formulated in a LP model in which you have to decide what mix of ingredients best fulfills specified output requirements. In this section we propose the Swedish steel problem \cite{SP}. [\textit{Attesa di conferma del professore di poter studiare questo esempio}] 
\chapter{Conclusion}

\begin{thebibliography}{9}
	
	\bibitem{W}Wright J. Stephen, Nocedal Jorge,\emph{\;Numerical Optimization}, Springer Science+Business Media, (2006).
	\bibitem{1}Dantzig, G. B.,\emph{\;Linear Programming and Extensions}, Princeton, University Press, Princeton, NJ, (1963).
	\bibitem{2} Andersen E. D, and Ye Y.,  \textit{Combining interior-point and pivoting algorithms for Linear Programming}, 1996.
	\bibitem{Lem} Lemke, . The dual method of solving the linear programming problem. Nav. Res. Log. Q, C.E 1954
	\bibitem{3}Victor Klee and George J. Minty.\emph{ How good is the simplex algorithm? Technical report}, Washington University Department of Mathematics, 1970.
	\bibitem{Kar} N. K. Karmarkar,\emph{ A new polynomial-time algorithm for linear programming}, Combinatorica, (1984).
	\bibitem{5} S. Mizuno, M.J. Todd, and Y. Ye,\emph{\;On adaptive-step primal-dual interior-point algorithms for linear programming}, Math. of OR, vol. 18, pp. 964-981, (1993). 
	\bibitem{5} G. B. Dantzig, A. Orden, P. Wolfe, \emph{ Notes on linear programming: Part I- The generalized simplex method for
	minimizing a linear form under linear inequality restrictions.} Pacific J Math pp: 183-195, (1955). 
	\bibitem{Lexico2}  Charnes A. \emph{ Optimality and degeneracy in linear programming}, 1952. pp: 160-170. 
	\bibitem {Wright} Wright J. Stephen, \emph{\;Primal-Dual Interior Point Methods.} SIAM: society for industrial and applied mathematics. Philadelphia, pag 134.
	\bibitem {LP} Vanderbei J. Robert, \emph{\;Linear programming:
		Foundations and Extensions}. Dept. of Operations Research and Financial Engineering
	Princeton University, Springer Science+ Business Media, 2001.
	\bibitem{MARE} R. D. C. Monteiro, I. Adler, and M. G. C. Resende, \emph{A polynomial-time primal-dual affine scaling algorithm for linear and convex quadratic programming and its power serier extension}, Math. of OR, 15, pp. 191-214, (1990).
	\bibitem{LMS} I. J. Lustig, E. Marsten, D. F. Shanno, \emph{Computational experience with a primal-dual interior point method for linear programming}, Linear algebra and its applications, pp. 191-222, (1991).
	\bibitem{MER} S. Mehrotra, \emph{ On the implementation of a primal-dual interior point method. } SIAM, 2 (1992), pp. 575-601.
	\bibitem{(Natural)} B. Kent, B. B. Bare, R. C. Field, G. A. Bradley, \textit{Natural Resource Land Management Planning Using Large-Scale Linear Programs: The USDA Forest Service Experience with FORPLAN}, OR, 39, (1991), pp: 13-27.
\bibitem{meg} N. Megiddo, \emph{ Pathways to the optimal set in linear programming, in Progress in
Mathematical Programming}, Springer-Verlag, New York, pp. 131-158, (1986).
\bibitem{SP} Carl-Henrik Westerberg, B. Bjorklund, E. Hultman, \emph{ An application of Mixed Integer Programming in a Swedish Steel Mill}, Interfaces, pp. 39-43, (1977). 
\end{thebibliography}



\end{document}
